{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e54053b",
   "metadata": {},
   "source": [
    "## Ê¶ÇË¶Å"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53236702",
   "metadata": {},
   "source": [
    "Open-Sora 2.0„ÅØ„ÄÅ3000‰∏áÂÜÜ„ÅßÂÆüÁèæÂèØËÉΩ„Å™ÂïÜÁî®„É¨„Éô„É´„ÅÆÂãïÁîªÁîüÊàê„É¢„Éá„É´\n",
    "\n",
    "Ë®ìÁ∑¥„Ç≥„Çπ„Éà„ÅØ„ÄÅÂêåÁ≠â„ÅÆ„É¢„Éá„É´ÔºàMovieGen„ÇÑStep-Video-T2VÔºâ„Çà„Çä„ÇÇ5~10ÂÄç‰Ωé„ÅÑ\n",
    "\n",
    "‰∫∫„ÅÆË©ï‰æ°„Å®VBench„ÅÆ„Çπ„Ç≥„Ç¢„Åß„ÅØ„ÄÅHuyyuan Video„ÇÑRunway Gen-3 Alpha„Å´ÂåπÊïµ:\n",
    "\n",
    "![](image/fig1.png)\n",
    "\n",
    "- Visual Quality: Ë¶ñË¶öÂìÅË≥™\n",
    "- Prompt Following: ÊåáÁ§∫ËøΩÂæìÊÄß\n",
    "- Motion Quality: Âãï„Åç„ÅÆÂìÅË≥™"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12386bd",
   "metadata": {},
   "source": [
    "## „Éá„Éº„Çø"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1780041",
   "metadata": {},
   "source": [
    "ÁõÆÁöÑ„ÅØ„ÄÅÂ≠¶Áøí„ÅÆÈÄ≤Êçó„Å´Âêà„Çè„Åõ„Åü„Éá„Éº„Çø„Éî„É©„Éü„ÉÉ„ÉâÔºàhierarchical data pyramidÔºâ„ÅÆÊßãÁØâ\n",
    "\n",
    "Êßò„ÄÖ„Å™Á®ÆÈ°û„ÅÆ„Éá„Éº„Çø„ÇíÊ§úÂá∫ÂèØËÉΩ„Å™„Å™„Éï„Ç£„É´„Çø„ÇíÈñãÁô∫\n",
    "\n",
    "Â≠¶Áøí„ÅÆÈÄ≤Êçó„Å´Âøú„Åò„Å¶„ÄÅ„Éï„Ç£„É´„Çø„É™„É≥„Ç∞„ÅÆÂº∑Â∫¶„ÇíÈ´ò„ÇÅ„ÄÅÁ¥îÂ∫¶„Å®ÂìÅË≥™„ÅÆÈ´ò„ÅÑÂ∞è„Åï„ÅÑ„Çµ„Éñ„Çª„ÉÉ„Éà„ÅßË®ìÁ∑¥\n",
    "\n",
    "„Éá„Éº„Çø„Éï„Ç£„É´„Çø„É™„É≥„Ç∞„ÅÆÂÖ®‰ΩìÂÉè:\n",
    "\n",
    "![](image/fig2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7093517c",
   "metadata": {},
   "source": [
    "- Á¥´: Áîü„ÅÆÂãïÁîª„ÅÆÂâçÂá¶ÁêÜ\n",
    "    1. „Éï„Ç£„É´„Çø„É™„É≥„Ç∞\n",
    "        - Á†¥Êêç„Åó„Åü„Éï„Ç°„Ç§„É´„ÅÆÈô§Âéª\n",
    "        - Ê•µÁ´Ø„Å™ÂãïÁîª„ÅÆÈô§Âéª\n",
    "            - ÂÜçÁîüÊôÇÈñì„Åå2ÁßíÊú™Ê∫Ä\n",
    "            - 1ÁîªÂÉè„ÅÇ„Åü„Çä„ÅÆ„Éá„Éº„ÇøÈáèÔºàBit per pixelÔºâ„Åå0.02Êú™Ê∫Ä\n",
    "            - „Éï„É¨„Éº„É†„É¨„Éº„ÉàÔºàfpsÔºâ„Åå16Êú™Ê∫Ä\n",
    "            - „Ç¢„Çπ„Éö„ÇØ„ÉàÊØî„ÅåÁØÑÂõ≤Â§ñÔºà1/3, 3Ôºâ\n",
    "            - ÁâπÂÆö„ÅÆ‰ΩéÂìÅË≥™„Å™„Ç®„É≥„Ç≥„Éº„ÉâË®≠ÂÆöÔºàConstrained Baseline profileÔºâ\n",
    "    2. ÈÄ£Á∂ö„Åó„ÅüÊò†ÂÉè„ÇíÊ§úÂá∫„Åó„ÄÅÁü≠„ÅÑ„ÇØ„É™„ÉÉ„Éó„Å´ÂàÜÂâ≤\n",
    "        - FFmpeg„ÅÆlibavfilter„Çí‰ΩøÁî®„Åó„ÄÅ„Ç∑„Éº„É≥„Çπ„Ç≥„Ç¢Ôºà„Éï„É¨„Éº„É†Èñì„ÅÆË¶ñË¶öÂ∑ÆÂàÜÔºâ„ÇíË®àÁÆó\n",
    "    3. ÂãïÁîª„ÅÆ„Éï„Ç©„Éº„Éû„ÉÉ„Éà\n",
    "        - „Éï„É¨„Éº„É†„É¨„Éº„Éà„ÅØ30fps‰ª•‰∏ã\n",
    "        - Èï∑Ëæ∫„ÅØ1080px‰ª•‰∏ã\n",
    "        - „Ç≥„Éº„Éá„ÉÉ„ÇØÔºàÂúßÁ∏ÆÂΩ¢ÂºèÔºâ„ÅØH.264\n",
    "        - ÂãïÁîª„ÅÆÈªíÂ∏Ø„ÇíÂâäÈô§\n",
    "        - 8Áßí„ÇíË∂Ö„Åà„Çã„Ç∑„Éß„ÉÉ„Éà„ÅØ„ÄÅ8Áßí„ÅÆ„ÇØ„É™„ÉÉ„Éó„Å´ÂàÜÂâ≤„Åó„ÄÅ2ÁßíÊú™Ê∫Ä„ÅØÁ†¥Ê£Ñ\n",
    "- Èùí: „ÇØ„É™„ÉÉ„ÉóÂãïÁîª„ÅÆ„Çπ„Ç≥„Ç¢„Éï„Ç£„É´„Çø„É™„É≥„Ç∞\n",
    "    - ÁæéÁöÑ„Çπ„Ç≥„Ç¢„Åß„ÅÆ„Éï„Ç£„É´„Çø„É™„É≥„Ç∞\n",
    "        - [CLIP„Å®MLP][1]„ÅßÁæéÁöÑ„Çπ„Ç≥„Ç¢„Çí‰∫àÊ∏¨\n",
    "            - ÊúÄÂàù„Éª‰∏≠Èñì„ÉªÊúÄÁµÇ„Éï„É¨„Éº„É†„ÇíÊäΩÂá∫„Åó„ÄÅ„Çπ„Ç≥„Ç¢„ÇíË®àÁÆó„Åó„ÄÅÂπ≥Âùá\n",
    "    - ÈÆÆÊòé„Åï„ÅÆ‰Ωé„ÅÑÂãïÁîª„ÅÆ„Éï„Ç£„É´„Çø„É™„É≥„Ç∞\n",
    "        - OpenCV„ÅÆ„É©„Éó„É©„Ç∑„Ç¢„É≥ÊºîÁÆóÂ≠ê„ÅßÁîªÂÉè„ÅÆÂàÜÊï£„Åå‰Ωé„ÅÑÔºà„Åº„ÇÑ„Åë„Å¶„ÅÑ„ÇãÔºâÂãïÁîª„ÇíÈô§Âéª\n",
    "    - Êâã„Éñ„É¨„ÅÆÂ§ö„ÅÑÂãïÁîª„ÅÆ„Éï„Ç£„É´„Çø„É™„É≥„Ç∞\n",
    "        - PySceneDetect„Çí‰ΩøÁî®„Åó„Å¶„ÄÅ„Éï„É¨„Éº„É†Èñì„ÅÆÂ§âÂåñ„ÅåÂ§ß„Åç„ÅÑÂãïÁîª„ÇíÈô§Âéª\n",
    "    - ÈáçË§á„ÇØ„É™„ÉÉ„Éó„ÅÆ„Éï„Ç£„É´„Çø„É™„É≥„Ç∞\n",
    "- Á∑ë: 256px„ÅÆ‰ΩéËß£ÂÉèÂ∫¶ÂãïÁîª\n",
    "    - Â§ö„Åè„ÅÆÊñáÁ´†„ÅåÂê´„Åæ„Çå„ÇãÂãïÁîª„ÅÆ„Éï„Ç£„É´„Çø„É™„É≥„Ç∞\n",
    "        - PaddleOCR„Çí‰ΩøÁî®„Åó„Å¶„ÄÅ„ÉÜ„Ç≠„Çπ„Éà„ÅÆ„Éê„Ç¶„É≥„Éá„Ç£„É≥„Ç∞„Éú„ÉÉ„ÇØ„Çπ„ÇíÊ§úÂá∫\n",
    "        - ‰ø°È†ºÂ∫¶„Çπ„Ç≥„Ç¢„Åå0.7„ÇíË∂Ö„Åà„Çã„Éú„ÉÉ„ÇØ„Çπ„ÅÆÁ∑èÈù¢Á©ç„ÅåÂ§ö„ÅÑÂãïÁîª„ÇíÈô§Âéª\n",
    "    - „É¢„Éº„Ç∑„Éß„É≥„Çπ„Ç≥„Ç¢„Åß„ÅÆ„Éï„Ç£„É´„Çø„É™„É≥„Ç∞\n",
    "        - libavfilter„ÅÆVMAF„Çí‰ΩøÁî®„Åó„Å¶ÂãïÁîª„ÅÆÂãï„Åç„ÅÆÊøÄ„Åó„Åï„ÇíÊ∏¨ÂÆö\n",
    "        - „É¢„Éº„Ç∑„Éß„É≥„Çπ„Ç≥„Ç¢„ÅåÊ•µÁ´Ø„Å´‰Ωé„ÅÑ„ÉªÈ´ò„ÅÑÂãïÁîª„ÇíÈô§Âéª\n",
    "- ÈªÑËâ≤: 768px„ÅÆÈ´òËß£ÂÉèÂ∫¶ÂãïÁîª\n",
    "\n",
    "[1]: https://github.com/christophschuhmann/improved-aesthetic-predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa995eea",
   "metadata": {},
   "source": [
    "ÂãïÁîª„ÅÆ„Ç≠„É£„Éó„Ç∑„Éß„É≥„Çí‰ΩúÊàê„Åô„Çã„Åü„ÇÅ„Å´„ÄÅË¶ñË¶öË®ÄË™û„É¢„Éá„É´„Çí‰ΩøÁî®:\n",
    "\n",
    "- 256pxÂãïÁîª„Å´„ÅØ„ÄÅLLaVA-Video\n",
    "- 778pxÂãïÁîª„Å´„ÅØ„ÄÅQwen 2.5 MaxÔºà„Éè„É´„Ç∑„Éç„Éº„Ç∑„Éß„É≥„ÅåÂ∞ë„Å™„ÅÑ„Éó„É≠„Éó„É©„Ç§„Ç®„Çø„É™„É¢„Éá„É´Ôºâ\n",
    "\n",
    "„Ç≠„É£„Éó„Ç∑„Éß„É≥ÁîüÊàê„ÅÆ„Éó„É≠„É≥„Éó„Éà„ÅÆÊßãÊàê:\n",
    "\n",
    "- ‰∏ª„Å™Ë¢´ÂÜô‰Ωì\n",
    "- Ë¢´ÂÜô‰Ωì„ÅÆÂãï„Åç\n",
    "- ËÉåÊôØ„ÇÑÁí∞Â¢É\n",
    "- Ë®ºÊòéÊù°‰ª∂„ÇÑÈõ∞Âõ≤Ê∞ó\n",
    "- „Ç´„É°„É©„ÉØ„Éº„ÇØ\n",
    "- „É™„Ç¢„É´„Éª„Ç∑„Éç„Éû„ÉÜ„Ç£„ÉÉ„ÇØ„Éª3D„Éª„Ç¢„Éã„É°„Å™„Å©„ÅÆÂãïÁîª„ÅÆ„Çπ„Çø„Ç§„É´\n",
    "\n",
    "ÁîüÊàêÊôÇ„Å´Âãï„Åç„ÅÆÂº∑Â∫¶„ÇíË™øÊï¥ÂèØËÉΩ„Å´„Åô„Çã„Åü„ÇÅ„ÄÅ„Ç≠„É£„Éó„Ç∑„Éß„É≥„ÅÆÊúÄÂæå„Å´„É¢„Éº„Ç∑„Éß„É≥„Çπ„Ç≥„Ç¢„ÇíËøΩË®ò"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7587fc55",
   "metadata": {},
   "source": [
    "„Éï„Ç£„É´„Çø„É™„É≥„Ç∞Âæå„ÅÆ„Éá„Éº„Çø„ÅÆÁµ±Ë®à:\n",
    "\n",
    "![](image/fig3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff7e82d",
   "metadata": {},
   "source": [
    "- ÁæéÁöÑ„Çπ„Ç≥„Ç¢„ÅØ4.5~5.5„Åß‰∏≠Á®ãÂ∫¶\n",
    "- ÂãïÁîª„ÅÆÈï∑„Åï„ÅØ2~8Áßí„Åß„ÄÅÂçäÂàÜËøë„Åè„Åå6~8Áßí\n",
    "- „Ç¢„Çπ„Éö„ÇØ„ÉàÊØî„ÅØ„ÄÅÂ§ßÈÉ®ÂàÜ„Åå0.5~0.75Ôºà16:9„ÅÆÊ®™Èï∑ÂãïÁîªÔºâ\n",
    "- „Ç≠„É£„Éó„Ç∑„Éß„É≥„ÅÆ70%„ÅØ75ÂçòË™û„ÇíË∂Ö„Åà„Å¶„ÅÑ„Å¶ÊÉÖÂ†±Èáè„ÅåÂ§ö„ÅÑ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1277b7",
   "metadata": {},
   "source": [
    "„Ç≠„É£„Éó„Ç∑„Éß„É≥„ÅÆ„ÉØ„Éº„Éâ„ÇØ„É©„Ç¶„Éâ:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab60e0b",
   "metadata": {},
   "source": [
    "![](image/fig4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1d547b",
   "metadata": {},
   "source": [
    "- ËÉåÊôØ„ÇÑÁÖßÊòéÊù°‰ª∂„ÇÇÂê´„Åæ„Çå„Å¶„ÅÑ„Å¶„ÄÅË¢´ÂÜô‰Ωì„ÅØ‰∫∫Áâ©„ÅåÂ§ö„ÅÑ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c25823",
   "metadata": {},
   "source": [
    "## „Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346c05aa",
   "metadata": {},
   "source": [
    "### 3Ê¨°ÂÖÉ„Ç™„Éº„Éà„Ç®„É≥„Ç≥„Éº„ÉÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a577fd",
   "metadata": {},
   "source": [
    "[Hunyuan Video VAE][1]„ÅÆ„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„ÇíÂäπÁéáÂåñ„Åó„ÅüVideo DC-AE„ÇíÈñãÁô∫\n",
    "\n",
    "DC-AE„ÅØ„ÄÅ[Deep Compression Autoencoder][2]„ÅÆÁï•\n",
    "\n",
    "ÂúßÁ∏ÆÁéá„ÅØ„ÄÅ$4\\times 32\\times 32$ÔºàÊôÇÈñì„ÅØ $\\frac{1}{4}$„ÄÅÁ∏¶„Å®Ê®™„ÅØ$\\frac{1}{32}$„Å´ÂúßÁ∏ÆÔºâ\n",
    "\n",
    "„Ç™„Éº„Éà„Ç®„É≥„Ç≥„Éº„ÉÄ„Éº„ÅÆÂ≠¶Áøí„Éá„Éº„Çø„ÅØ32„Éï„É¨„Éº„É†„ÄÅ256px„ÅÆ„Åü„ÇÅ„ÄÅÊΩúÂú®Ë°®Áèæ„ÅØ$8\\times 8\\times 8$\n",
    "\n",
    "[1]: https://arxiv.org/abs/2412.03603\n",
    "[2]: https://arxiv.org/abs/2410.10733"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef5fb66",
   "metadata": {},
   "source": [
    "Video DC-AE„ÅÆ„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£:\n",
    "\n",
    "![](image/fig5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346d9939",
   "metadata": {},
   "source": [
    "- „Ç®„É≥„Ç≥„Éº„ÉÄ\n",
    "    - 3Â±§„ÅÆResBlock„Å®3Â±§„ÅÆEfficientViT Block„ÅßÊßãÊàê„Åï„Çå„Çã\n",
    "    - ÊúÄÂàù„ÅÆ5„Å§„ÅÆ„Éñ„É≠„ÉÉ„ÇØ„ÅØ„ÄÅ„ÉÄ„Ç¶„É≥„Çµ„É≥„Éó„É™„É≥„Ç∞Áî®\n",
    "    - Â≠¶Áøí„ÇíÂèØËÉΩ„Å´„Åô„Çã„Åü„ÇÅ„ÄÅ„ÉÄ„Ç¶„É≥„Çµ„É≥„Éó„É´„Éñ„É≠„ÉÉ„ÇØ„Å´„ÅØ„ÄÅÊÆãÂ∑ÆÊé•Á∂ö„ÅåÂ∞éÂÖ•\n",
    "    - ÊÆãÂ∑ÆÊé•Á∂ö„ÅØ„Éî„ÇØ„Çª„É´„Ç¢„É≥„Ç∑„É£„ÉÉ„Éï„É™„É≥„Ç∞„Çí‰ΩøÁî®ÔºàSpace&Time->ChannelÔºâ\n",
    "- „Éá„Ç≥„Éº„ÉÄ\n",
    "    - 3Â±§„ÅÆEfficientViT Block„Å®3Â±§„ÅÆResBlock„ÅßÊßãÊàê„Åï„Çå„Çã\n",
    "    - ÊúÄÂæå„ÅÆ5„Å§„ÅÆ„Éñ„É≠„ÉÉ„ÇØ„ÅØ„ÄÅ„Ç¢„ÉÉ„Éó„Çµ„É≥„Éó„É™„É≥„Ç∞Áî®\n",
    "    - Â≠¶Áøí„ÇíÂèØËÉΩ„Å´„Åô„Çã„Åü„ÇÅ„ÄÅ„Ç¢„ÉÉ„Éó„Çµ„É≥„Éó„É´„Éñ„É≠„ÉÉ„ÇØ„Å´„ÅØ„ÄÅÊÆãÂ∑ÆÊé•Á∂ö„ÅåÂ∞éÂÖ•\n",
    "    - ÊÆãÂ∑ÆÊé•Á∂ö„ÅØ„Éî„ÇØ„Çª„É´„Ç∑„É£„ÉÉ„Éï„É™„É≥„Ç∞„Çí‰ΩøÁî®ÔºàChannel->Space&TimeÔºâ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb61f01",
   "metadata": {},
   "source": [
    "Video DC-AE„Çí„Çπ„ÇØ„É©„ÉÉ„ÉÅ„Åã„ÇâÂ≠¶Áøí„Åó„ÄÅÂÜçÊßãÊàêÂìÅË≥™„ÇíË©ï‰æ°:\n",
    "\n",
    "![](image/table1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df750de",
   "metadata": {},
   "source": [
    "- LPIPS: ‰∫∫Èñì„ÅÆÁü•Ë¶ö„Å´Ëøë„ÅÑÁîªË≥™Ë©ï‰æ°ÊåáÊ®ô"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adeda3cd",
   "metadata": {},
   "source": [
    "## DiT„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759c3421",
   "metadata": {},
   "source": [
    "Èõ¢„Çå„Åü„Éï„É¨„Éº„É†„ÇÑÁîªÁ¥†ÂêåÂ£´„ÅÆÈñ¢‰øÇ„ÇíÂäπÊûúÁöÑ„Å´Êçâ„Åà„Çã„Éï„É´„Ç¢„ÉÜ„É≥„Ç∑„Éß„É≥„ÇíÊé°Áî®\n",
    "\n",
    "ÂãïÁîª„ÅØVideo DC-AE„ÅßÂúßÁ∏ÆÂæå„ÄÅ„Éë„ÉÉ„ÉÅ„Çµ„Ç§„Ç∫1Ôºà=„Éë„ÉÉ„ÉÅÂåñÁÑ°„ÅóÔºâ„Åß„Éï„É©„ÉÉ„ÉàÂåñ\n",
    "\n",
    "Hunyuan Video„ÅÆ„Ç™„Éº„Éà„Ç®„É≥„Ç≥„Éº„ÉÄ„Éº„Çí‰ΩøÁî®„Åô„ÇãÂ†¥Âêà„ÅØ„ÄÅ„Éë„ÉÉ„ÉÅ„Çµ„Ç§„Ç∫2„ÅåÂøÖË¶Å"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df79314e",
   "metadata": {},
   "source": [
    "FLUX„ÅÆ[MMDiT][1]„ÇíÂèÇËÄÉ„Å´„ÄÅ„Éá„É•„Ç¢„É´„Çπ„Éà„É™„Éº„É†„Å®„Ç∑„É≥„Ç∞„É´„Çπ„Éà„É™„Éº„É†„Åã„Çâ„Å™„ÇãÊßãÈÄ†„ÇíÊé°Áî®:\n",
    "\n",
    "![](image/fig6.png)\n",
    "\n",
    "[1]: https://github.com/black-forest-labs/flux"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968e2d5c",
   "metadata": {},
   "source": [
    "- „Éá„É•„Ç¢„É´„Çπ„Éà„É™„Éº„É†„Éñ„É≠„ÉÉ„ÇØ„Åß„ÄÅÂãïÁîª„Å®„ÉÜ„Ç≠„Çπ„Éà„ÅåÂà•„ÄÖ„Å´ÁâπÂæ¥ÊäΩÂá∫„Åï„Çå„Çã\n",
    "- „Ç∑„É≥„Ç∞„É´„Çπ„Éà„É™„Éº„É†„Éñ„É≠„ÉÉ„ÇØ„Åß„ÄÅÁâπÂæ¥„ÇíÁµ±Âêà„Åô„Çã"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f3e053",
   "metadata": {},
   "source": [
    "Á©∫Èñì„Å®ÊôÇÈñìÊÉÖÂ†±„ÇíÊçâ„Åà„Çã„Åü„ÇÅ„Å´„ÄÅ3D RoPE„ÇíÊé°Áî®\n",
    "\n",
    "„ÉÜ„Ç≠„Çπ„Éà„Éé„Ç®„É≥„Ç≥„Éº„Éâ„ÅØ„ÄÅ2„Å§„ÅÆ‰∫ãÂâçÂ≠¶ÁøíÊ∏à„Åø„É¢„Éá„É´„ÇíÊé°Áî®:\n",
    "\n",
    "- T5-XXL: Ë§áÈõë„Å™„ÉÜ„Ç≠„Çπ„Éà„ÅÆÊÑèÂë≥„ÇíÊçâ„Åà„Çã\n",
    "- CLIP-Large: „ÉÜ„Ç≠„Çπ„Éà„Å®Ë¶ñË¶öÊ¶ÇÂøµ„ÅÆÊï¥ÂêàÊÄß„ÇíÊçâ„Åà„ÇãÔºà=ÊåáÁ§∫ËøΩÂæìÊÄß„ÇíÈ´ò„ÇÅ„ÇãÔºâ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6548ce9c",
   "metadata": {},
   "source": [
    "![](image/table2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3baaba03",
   "metadata": {},
   "source": [
    "## ÂÆüË£Ö"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf13bf8",
   "metadata": {},
   "source": [
    "- image.py: ÁîªÂÉè„ÅÆ„Åø„ÅßÂ≠¶Áøí„ÄÇ\n",
    "- stage1.py: 256pxËß£ÂÉèÂ∫¶„ÅÆÂãïÁîª„ÅßÂ≠¶Áøí„ÄÇ\n",
    "- stage2.py: 768pxËß£ÂÉèÂ∫¶„ÅÆÂãïÁîª„ÅßÂ≠¶ÁøíÔºà„Ç∑„Éº„Ç±„É≥„Çπ‰∏¶ÂàóÂåñ„Çí‰ΩøÁî®„ÄÅ„Éá„Éï„Ç©„É´„Éà„ÅØ4Ôºâ„ÄÇ\n",
    "- stage1_i2v.py: 256pxËß£ÂÉèÂ∫¶„ÅßT2VÔºà„ÉÜ„Ç≠„Çπ„Éà„Åã„ÇâÂãïÁîªÔºâ„Å®I2VÔºàÁîªÂÉè„Åã„ÇâÂãïÁîªÔºâ„ÇíÂ≠¶Áøí„ÄÇ\n",
    "- stage2_i2v.py: 768pxËß£ÂÉèÂ∫¶„ÅßT2V„Å®I2V„ÇíÂ≠¶Áøí„ÄÇ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e895226e",
   "metadata": {},
   "source": [
    "## Áí∞Â¢ÉÊßãÁØâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9f1318",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34edd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /workspaces/open-sora/Open-Sora\n",
    "%pip install -e . --no-deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52ec244",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import platform\n",
    "import subprocess\n",
    "\n",
    "if os.path.exists(\"debug.log\"):\n",
    "    os.remove(\"debug.log\")\n",
    "\n",
    "def custom_format(record):\n",
    "    match record.levelno:\n",
    "        case logging.DEBUG:\n",
    "            level = \"üü¶\"\n",
    "        case logging.INFO:\n",
    "            level = \"üü©\"\n",
    "        case logging.WARNING:\n",
    "            level = \"üü®\"\n",
    "        case logging.ERROR:\n",
    "            level = \"üü•\"\n",
    "        case logging.CRITICAL:\n",
    "            level = \"üõë\"\n",
    "    return f\"{level} {record.getMessage()}\"\n",
    "\n",
    "logger_ = logging.getLogger()\n",
    "\n",
    "for handler in logger_.handlers:\n",
    "    logger_.removeHandler(handler)\n",
    "\n",
    "formatter = logging.Formatter()\n",
    "formatter.format = custom_format\n",
    "\n",
    "file_handler = logging.FileHandler(\"debug.log\")\n",
    "file_handler.setFormatter(formatter)\n",
    "logger_.addHandler(file_handler)\n",
    "\n",
    "stream_handler = logging.StreamHandler()\n",
    "stream_handler.setFormatter(formatter)\n",
    "logger_.addHandler(stream_handler)\n",
    "logger_.setLevel(logging.DEBUG)\n",
    "\n",
    "PYTHON_VERSION = platform.python_version()\n",
    "logger_.info(f\"Python {PYTHON_VERSION}\")\n",
    "\n",
    "NVIDIA_SMI = subprocess.run(\"nvidia-smi\", capture_output=True, text=True).stdout\n",
    "logger_.info(f\"{NVIDIA_SMI}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1cb4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install torch==2.6.0 torchvision==0.21.0 torchaudio==2.6.0 --index-url https://download.pytorch.org/whl/cu124\n",
    "%pip install torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/cu124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57815940",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install \\\n",
    "    accelerate \\\n",
    "    av \\\n",
    "    colossalai \\\n",
    "    ftfy \\\n",
    "    liger-kernel \\\n",
    "    omegaconf \\\n",
    "    mmengine \\\n",
    "    openai \\\n",
    "    pandas \\\n",
    "    pandarallel \\\n",
    "    pyarrow \\\n",
    "    tensorboard \\\n",
    "    wandb \\\n",
    "    --extra-index-url https://download.pytorch.org/whl/cu124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4303893",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install flash-attn --no-build-isolation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489f2609",
   "metadata": {},
   "source": [
    "### „ÉÄ„Ç¶„É≥„É≠„Éº„Éâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3af23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 269.53GB„ÅÆÂãïÁîª„Éá„Éº„Çø„Çª„ÉÉ„Éà„Çí„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ\n",
    "# https://modelscope.cn/datasets/hpcai-tech/open-sora-pexels-45k\n",
    "\n",
    "if False:\n",
    "    !apt update && apt install git-lfs\n",
    "    !git-lfs install\n",
    "    !git clone \"https://www.modelscope.cn/datasets/hpcai-tech/open-sora-pexels-45k.git\"\n",
    "    !cd open-sora-pexels-45k && \\\n",
    "        cat tar/pexels_45k.tar.* > pexels_45k.tar && \\\n",
    "        mkdir ../datasets && \\\n",
    "        mv pexels_45k ../datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257aa955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Êï∞‰ª∂„ÅÆÂãïÁîª„ÇíÁõ¥Êé•„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ\n",
    "\n",
    "if False:\n",
    "    from multiprocessing import Pool\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    import re\n",
    "    import subprocess\n",
    "\n",
    "    os.makedirs(\"pexel_10\", exist_ok=True)\n",
    "    necessary_csv_path = \"/workspaces/open-sora/pexels_10/pexels_10_necessary.csv\"\n",
    "    df = pd.read_csv(necessary_csv_path)\n",
    "\n",
    "    video_urls = []\n",
    "\n",
    "    for path in df[\"path\"]:\n",
    "        match = re.search(r\"/(\\d+)_\", path)\n",
    "        video_id = match.group(1)\n",
    "        video_url = f\"https://www.pexels.com/download/video/{video_id}\"\n",
    "        df.loc[df[\"path\"] == path, \"url\"] = video_url\n",
    "\n",
    "    def download_video(args):\n",
    "        url, save_path = args\n",
    "\n",
    "        # ‰øùÂ≠òÂÖà„ÅÆ„Éá„Ç£„É¨„ÇØ„Éà„É™„Çí‰ΩúÊàêÔºàÂ≠òÂú®„Åó„Å™„ÅÑÂ†¥ÂêàÔºâ\n",
    "        directory = os.path.dirname(save_path)\n",
    "        if directory:\n",
    "            os.makedirs(directory, exist_ok=True)\n",
    "        \n",
    "        # „Éï„Ç°„Ç§„É´„ÅåÊó¢„Å´Â≠òÂú®„Åó„Å™„ÅÑÂ†¥Âêà„ÅÆ„Åø„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ„ÇíÂÆüË°å\n",
    "        if not os.path.exists(save_path):\n",
    "            try:\n",
    "                # -O: Âá∫Âäõ„Éï„Ç°„Ç§„É´Âêç„ÇíÊåáÂÆö\n",
    "                # -q: „É≠„Ç∞Âá∫Âäõ„ÇíÊäëÂà∂ÔºàÈÄ≤Êçó„ÅåË¶ã„Åü„ÅÑÂ†¥Âêà„ÅØÂ§ñ„Åó„Å¶„Åè„Å†„Åï„ÅÑÔºâ\n",
    "                command = [\"wget\", \"-q\", \"-O\", save_path, url]\n",
    "                subprocess.run(command, check=True)\n",
    "            except subprocess.CalledProcessError:\n",
    "                print(f\"Failed to download: {url}\")\n",
    "\n",
    "    # URL„Å®‰øùÂ≠ò„Éë„Çπ„ÅÆ„Éö„Ç¢„Çí‰ΩúÊàê\n",
    "    tasks = list(zip(df[\"url\"], df[\"path\"]))\n",
    "\n",
    "    with Pool(os.cpu_count()) as p:\n",
    "        p.map(download_video, tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa05d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‰∫ãÂâçÂ≠¶ÁøíÊ∏à„ÅøVAE„ÅÆ„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ\n",
    "\n",
    "os.makedirs(\"ckpts\", exist_ok=True)\n",
    "\n",
    "if not os.path.exists(\"ckpts/hunyuan_vae.safetensors\"):\n",
    "    !huggingface-cli download hpcai-tech/Open-Sora-v2 hunyuan_vae.safetensors --local-dir ckpts --local-dir-use-symlinks False\n",
    "else:\n",
    "    logger_.info(f\"Êó¢„Å´VAE„Çí„ÉÄ„Ç¶„É≥„É≠„Éº„ÉâÊ∏à„Åø\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2b27d3",
   "metadata": {},
   "source": [
    "## Ë®ìÁ∑¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d330e6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !torchrun --nproc_per_node=1 scripts/diffusion/train.py configs/diffusion/train/stage1.py --dataset.data-path /workspaces/open-sora/pexels_45k/pexels_45k_necessary.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754fc1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import math\n",
    "import os\n",
    "import subprocess\n",
    "import warnings\n",
    "from contextlib import nullcontext\n",
    "from copy import deepcopy\n",
    "from pprint import pformat\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "gc.disable()\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.nn.functional as F\n",
    "import wandb\n",
    "from colossalai.booster import Booster\n",
    "from colossalai.utils import set_seed\n",
    "from peft import LoraConfig\n",
    "from tqdm import tqdm\n",
    "\n",
    "from opensora.acceleration.checkpoint import (\n",
    "    GLOBAL_ACTIVATION_MANAGER,\n",
    "    set_grad_checkpoint,\n",
    ")\n",
    "from opensora.acceleration.parallel_states import get_data_parallel_group\n",
    "from opensora.datasets.aspect import bucket_to_shapes\n",
    "from opensora.datasets.dataloader import prepare_dataloader\n",
    "from opensora.datasets.pin_memory_cache import PinMemoryCache\n",
    "from opensora.models.mmdit.distributed import MMDiTPolicy\n",
    "from opensora.registry import DATASETS, MODELS, build_module\n",
    "from opensora.utils.ckpt import (\n",
    "    CheckpointIO,\n",
    "    model_sharding,\n",
    "    record_model_param_shape,\n",
    "    rm_checkpoints,\n",
    ")\n",
    "from opensora.utils.config import (\n",
    "    config_to_name,\n",
    "    create_experiment_workspace,\n",
    "    parse_configs,\n",
    ")\n",
    "from opensora.utils.logger import create_logger\n",
    "from opensora.utils.misc import (\n",
    "    NsysProfiler,\n",
    "    Timers,\n",
    "    all_reduce_mean,\n",
    "    create_tensorboard_writer,\n",
    "    is_log_process,\n",
    "    is_pipeline_enabled,\n",
    "    log_cuda_max_memory,\n",
    "    log_cuda_memory,\n",
    "    log_model_params,\n",
    "    print_mem,\n",
    "    to_torch_dtype,\n",
    ")\n",
    "from opensora.utils.optimizer import create_lr_scheduler, create_optimizer\n",
    "from opensora.utils.sampling import (\n",
    "    get_res_lin_function,\n",
    "    pack,\n",
    "    prepare,\n",
    "    prepare_ids,\n",
    "    time_shift,\n",
    ")\n",
    "from opensora.utils.train import (\n",
    "    create_colossalai_plugin,\n",
    "    dropout_condition,\n",
    "    get_batch_loss,\n",
    "    prepare_visual_condition_causal,\n",
    "    prepare_visual_condition_uncausal,\n",
    "    set_eps,\n",
    "    set_lr,\n",
    "    setup_device,\n",
    "    update_ema,\n",
    "    warmup_ae,\n",
    ")\n",
    "\n",
    "torch.backends.cudnn.benchmark = False  # True leads to slow down in conv3d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635a870b",
   "metadata": {},
   "source": [
    "### 1. Ë®≠ÂÆö„Å®Áí∞Â¢É„ÅÆÂàùÊúüÂåñ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260212ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# == parse configs ==\n",
    "# cfg = parse_configs()\n",
    "\n",
    "\n",
    "from opensora.utils.config import read_config, merge_args\n",
    "import argparse\n",
    "from mmengine.config import Config\n",
    "\n",
    "# !torchrun --nproc_per_node=1 scripts/diffusion/train.py configs/diffusion/train/stage1.py --dataset.data-path /workspaces/open-sora/pexels_45k/pexels_45k_necessary.csv\n",
    "\n",
    "def parse_args(args) -> tuple[str, argparse.Namespace]:\n",
    "    \"\"\"\n",
    "    This function parses the command line arguments.\n",
    "\n",
    "    Returns:\n",
    "        tuple[str, argparse.Namespace]: The path to the configuration file and the command line arguments.\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"config\", type=str, help=\"model config file path\")\n",
    "    args, unknown_args = parser.parse_known_args(args)\n",
    "    return args.config, unknown_args\n",
    "\n",
    "def parse_configs() -> Config:\n",
    "    \"\"\"\n",
    "    This function parses the configuration file and command line arguments.\n",
    "\n",
    "    Returns:\n",
    "        Config: The configuration object.\n",
    "    \"\"\"\n",
    "    config, args = parse_args([\"configs/diffusion/train/stage1.py\", \"--dataset.data-path\", \"/workspaces/open-sora/pexels_45k/pexels_45k_necessary.csv\"])\n",
    "    cfg = read_config(config)\n",
    "    cfg = merge_args(cfg, args)\n",
    "    cfg.config_path = config\n",
    "\n",
    "    # hard-coded for spatial compression\n",
    "    if cfg.get(\"ae_spatial_compression\", None) is not None:\n",
    "        os.environ[\"AE_SPATIAL_COMPRESSION\"] = str(cfg.ae_spatial_compression)\n",
    "    return cfg\n",
    "\n",
    "cfg = parse_configs()\n",
    "cfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23c575b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import warnings\n",
    "from collections import OrderedDict\n",
    "from datetime import timedelta\n",
    "\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.nn.functional as F\n",
    "from colossalai.booster.plugin import HybridParallelPlugin, LowLevelZeroPlugin\n",
    "from colossalai.cluster import DistCoordinator\n",
    "from colossalai.utils import get_current_device\n",
    "from einops import rearrange\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from tqdm import tqdm\n",
    "\n",
    "from opensora.acceleration.parallel_states import (\n",
    "    set_data_parallel_group,\n",
    "    set_sequence_parallel_group,\n",
    "    set_tensor_parallel_group,\n",
    ")\n",
    "from opensora.utils.optimizer import LinearWarmupLR\n",
    "\n",
    "\n",
    "\n",
    "# == get dtype & device ==\n",
    "dtype = to_torch_dtype(cfg.get(\"dtype\", \"bf16\"))\n",
    "\n",
    "os.environ['RANK'] = '0'\n",
    "os.environ['WORLD_SIZE'] = '1'\n",
    "os.environ['MASTER_ADDR'] = 'localhost'\n",
    "os.environ['MASTER_PORT'] = '12345'\n",
    "\n",
    "device, coordinator = setup_device()\n",
    "\n",
    "grad_ckpt_buffer_size = cfg.get(\"grad_ckpt_buffer_size\", 0)\n",
    "\n",
    "if grad_ckpt_buffer_size > 0:\n",
    "    GLOBAL_ACTIVATION_MANAGER.setup_buffer(grad_ckpt_buffer_size, dtype)\n",
    "\n",
    "checkpoint_io = CheckpointIO()\n",
    "\n",
    "set_seed(cfg.get(\"seed\", 1024))\n",
    "\n",
    "PinMemoryCache.force_dtype = dtype\n",
    "\n",
    "pin_memory_cache_pre_alloc_numels = cfg.get(\"pin_memory_cache_pre_alloc_numels\", None)\n",
    "\n",
    "PinMemoryCache.pre_alloc_numels = pin_memory_cache_pre_alloc_numels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364b7da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ColossalAI„ÅÆÂàùÊúüÂåñÔºàBooster„Å®pluginÔºâ\n",
    "# „Éá„Éº„Çø‰∏¶Âàó„ÄÅ„É¢„Éá„É´‰∏¶Âàó„Å™„Å©„ÅÆÂàÜÊï£Â≠¶Áøí„ÇíÂäπÁéáÂåñ„Åô„Çã\n",
    "\n",
    "plugin_type = cfg.get(\"plugin\", \"zero2\")\n",
    "\n",
    "plugin_config = cfg.get(\"plugin_config\", {})\n",
    "\n",
    "print(\"plugin config:\", plugin_config)\n",
    "\n",
    "plugin_kwargs = {}\n",
    "\n",
    "if plugin_type == \"hybrid\":\n",
    "    plugin_kwargs[\"custom_policy\"] = MMDiTPolicy\n",
    "\n",
    "plugin = create_colossalai_plugin(\n",
    "    plugin=plugin_type,\n",
    "    dtype=cfg.get(\"dtype\", \"bf16\"),\n",
    "    grad_clip=cfg.get(\"grad_clip\", 0),\n",
    "    **plugin_config,\n",
    "    **plugin_kwargs,\n",
    ")\n",
    "\n",
    "booster = Booster(plugin=plugin)\n",
    "\n",
    "seq_align = plugin_config.get(\"sp_size\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6514c365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÂÆüÈ®ì„Éá„Ç£„É¨„ÇØÊé™ÁΩÆ„ÇíÂàùÊúüÂåñ\n",
    "\n",
    "exp_name, exp_dir = create_experiment_workspace(\n",
    "    cfg.get(\"outputs\", \"./outputs\"),\n",
    "    model_name=config_to_name(cfg),\n",
    "    config=cfg.to_dict(),\n",
    "    exp_name=cfg.get(\"exp_name\", None),  # useful for automatic restart to specify the exp_name\n",
    ")\n",
    "logger_.info(f\"ÂÆüÈ®ìÂêç: {exp_name}\")\n",
    "logger_.info(f\"ÂÆüÈ®ì„Éá„Ç£„É¨„ÇØ„Éà„É™: {exp_dir}\")\n",
    "\n",
    "if is_log_process(plugin_type, plugin_config):\n",
    "    print(f\"changing {exp_dir} to share\")\n",
    "    os.system(f\"chgrp -R share {exp_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf0cd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# „É≠„Ç¨„Éº„ÇíÂàùÊúüÂåñÔºàÊ®ôÊ∫ñÂá∫Âäõ„ÉªTensorBoard„ÉªWandBÔºâ\n",
    "\n",
    "# logger = create_logger(exp_dir)\n",
    "\n",
    "logger_.info(\"Training configuration:\\n %s\", pformat(cfg.to_dict()))\n",
    "\n",
    "tb_writer = None\n",
    "\n",
    "if coordinator.is_master():\n",
    "    tb_writer = create_tensorboard_writer(exp_dir)\n",
    "    if cfg.get(\"wandb\", False):\n",
    "        logger_.info(f\"WandB„ÇíÂàùÊúüÂåñ\")\n",
    "        wandb.init(\n",
    "            project=cfg.get(\"wandb_project\", \"Open-Sora\"),\n",
    "            name=exp_name,\n",
    "            config=cfg.to_dict(),\n",
    "            dir=exp_dir,\n",
    "        )\n",
    "\n",
    "num_gpus = dist.get_world_size() if dist.is_initialized() else 1\n",
    "logger_.info(\"Number of GPUs: %s\", num_gpus)\n",
    "\n",
    "tp_size = cfg[\"plugin_config\"].get(\"tp_size\", 1)\n",
    "sp_size = cfg[\"plugin_config\"].get(\"sp_size\", 1)\n",
    "pp_size = cfg[\"plugin_config\"].get(\"pp_size\", 1)\n",
    "num_groups = num_gpus // (tp_size * sp_size * pp_size)\n",
    "logger_.info(\"Number of groups: %s\", num_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7f3a1c",
   "metadata": {},
   "source": [
    "### 2. „Éá„Éº„Çø„Çª„ÉÉ„Éà„Å®„Éá„Éº„Çø„É≠„Éº„ÉÄ„Éº„ÅÆÊßãÁØâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db28e0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# „Éá„Éº„Çø„Çª„ÉÉ„Éà„ÇíÊßãÁØâ\n",
    "dataset = build_module(cfg.dataset, DATASETS)\n",
    "logger_.info(f\"„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅÆ„Çµ„É≥„Éó„É´Êï∞: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3281d91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# „Çµ„É≥„Éó„É´„ÇíË°®Á§∫\n",
    "\n",
    "random_index = random.randint(0, len(dataset) - 1)\n",
    "\n",
    "sample = dataset[f\"{random_index}-1-256-256\"]\n",
    "\n",
    "sample[\"video\"].shape # (3, 1, 256, 256)\n",
    "first_frame = sample[\"video\"][:, 0]  # (3, 256, 256)\n",
    "\n",
    "# display\n",
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(first_frame.permute(1, 2, 0), cmap='gray')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277708d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# „Éá„Éº„Çø„É≠„Éº„ÉÄ„Éº„ÅÆ„Éì„É´„Éâ\n",
    "\n",
    "cache_pin_memory = pin_memory_cache_pre_alloc_numels is not None\n",
    "logger_.info(f\"Cache pin memory: {cache_pin_memory}\")\n",
    "\n",
    "dataloader_args = dict(\n",
    "    dataset=dataset,\n",
    "    batch_size=cfg.get(\"batch_size\", None),\n",
    "    num_workers=cfg.get(\"num_workers\", 4),\n",
    "    seed=cfg.get(\"seed\", 1024),\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    pin_memory=True,\n",
    "    process_group=get_data_parallel_group(),\n",
    "    prefetch_factor=cfg.get(\"prefetch_factor\", None),\n",
    "    cache_pin_memory=cache_pin_memory,\n",
    "    num_groups=num_groups,\n",
    ")\n",
    "logger_.info(f\"Dataloader arguments: {pformat(dataloader_args)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d263382",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader, sampler = prepare_dataloader(\n",
    "    bucket_config=cfg.get(\"bucket_config\", None),\n",
    "    num_bucket_build_workers=cfg.get(\"num_bucket_build_workers\", 1),\n",
    "    **dataloader_args,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cc2733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import DataLoader from torch\n",
    "# from torch.utils.data import DataLoader\n",
    "# from opensora.datasets.dataloader import DataloaderForVideo\n",
    "# dataloader = DataloaderForVideo(dataset, batch_size=1, collate_fn=collate_fn_default)\n",
    "# first_batch = next(iter(dataloader))\n",
    "# len(dataloader)\n",
    "# first_batch[\"video\"].shape  # (1, 3, 16, 256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed9cd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps_per_epoch = len(dataloader)\n",
    "logger_.info(f\"1„Ç®„Éù„ÉÉ„ÇØ„ÅÇ„Åü„Çä„ÅÆ„Çπ„ÉÜ„ÉÉ„ÉóÊï∞: {num_steps_per_epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c36a394",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_efficient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fe50bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_iter = iter(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93da31a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_batch = next(dataloader_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0917e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger_.info(f\"{first_batch.keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fe1b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925a1bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_batch[\"sampling_interval\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9617103d",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_batch[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25d4115",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_batch[\"index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d9f02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_batch[\"path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0893f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_batch[\"video\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d7e709",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_iter = iter(dataloader)\n",
    "sample_batch = next(dataset_iter)\n",
    "sample_batch.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077c00c1",
   "metadata": {},
   "source": [
    "### 3. „É¢„Éá„É´ÊßãÁØâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a91230",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger_.info(\"Building models...\")\n",
    "\n",
    "# == build model model ==\n",
    "model = build_module(cfg.model, MODELS, device_map=device, torch_dtype=dtype).train()\n",
    "\n",
    "if cfg.get(\"grad_checkpoint\", True):\n",
    "    logger_.info(f\"ÂãæÈÖç„ÉÅ„Çß„ÉÉ„ÇØ„Éù„Ç§„É≥„Éà„ÇíÊúâÂäπÂåñ\")\n",
    "    set_grad_checkpoint(model)\n",
    "\n",
    "log_cuda_memory(\"diffusion\")\n",
    "log_model_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23a5e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# == build EMA model ==\n",
    "use_lora = cfg.get(\"lora_config\", None) is not None\n",
    "\n",
    "if cfg.get(\"ema_decay\", None) is not None and not use_lora:\n",
    "    ema = deepcopy(model).cpu().eval().requires_grad_(False)\n",
    "    ema_shape_dict = record_model_param_shape(ema)\n",
    "    logger_.info(\"EMA model created.\")\n",
    "else:\n",
    "    ema = ema_shape_dict = None\n",
    "    logger_.info(\"No EMA model created.\")\n",
    "\n",
    "log_cuda_memory(\"EMA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277eed60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# == enable LoRA ==\n",
    "if use_lora:\n",
    "    lora_config = LoraConfig(**cfg.get(\"lora_config\", None))\n",
    "    model = booster.enable_lora(\n",
    "        model=model,\n",
    "        lora_config=lora_config,\n",
    "        pretrained_dir=cfg.get(\"lora_checkpoint\", None),\n",
    "    )\n",
    "    log_cuda_memory(\"lora\")\n",
    "    log_model_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f6e0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not cfg.get(\"cached_video\", False):\n",
    "    # == buildn autoencoder ==\n",
    "    model_ae = build_module(cfg.ae, MODELS, device_map=device, torch_dtype=dtype).eval().requires_grad_(False)\n",
    "    del model_ae.decoder\n",
    "    logger_.info(\"Autoencoder built.\")\n",
    "    log_model_params(model_ae)\n",
    "    model_ae.encode = torch.compile(model_ae.encoder, dynamic=True)\n",
    "\n",
    "model_ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaacd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not cfg.get(\"cached_text\", False):\n",
    "    # == build text encoder (t5) ==\n",
    "    model_t5 = build_module(cfg.t5, MODELS, device_map=device, torch_dtype=dtype).eval().requires_grad_(False)\n",
    "    log_cuda_memory(\"t5\")\n",
    "    log_model_params(model_t5)\n",
    "\n",
    "    # == build text encoder (clip) ==\n",
    "    model_clip = build_module(cfg.clip, MODELS, device_map=device, torch_dtype=dtype).eval().requires_grad_(False)\n",
    "    log_cuda_memory(\"clip\")\n",
    "    log_model_params(model_clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07350853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# == setup optimizer ==\n",
    "optimizer = create_optimizer(model, cfg.optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b69e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# == setup lr scheduler ==\n",
    "lr_scheduler = create_lr_scheduler(\n",
    "    optimizer=optimizer,\n",
    "    num_steps_per_epoch=num_steps_per_epoch,\n",
    "    epochs=cfg.get(\"epochs\", 1000),\n",
    "    warmup_steps=cfg.get(\"warmup_steps\", None),\n",
    "    use_cosine_scheduler=cfg.get(\"use_cosine_scheduler\", False),\n",
    ")\n",
    "log_cuda_memory(\"optimizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a0dd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# == prepare null vectors for dropout ==\n",
    "if cfg.get(\"cached_text\", False):\n",
    "    null_txt = torch.load(\"/mnt/ddn/sora/tmp_load/null_t5.pt\", map_location=device)\n",
    "    null_vec = torch.load(\"/mnt/ddn/sora/tmp_load/null_clip.pt\", map_location=device)\n",
    "else:\n",
    "    null_txt = model_t5(\"\")\n",
    "    null_vec = model_clip(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe8f3e4",
   "metadata": {},
   "source": [
    "### 4. Colossalai„Çí‰ΩøÁî®„Åó„ÅüÂàÜÊï£Â≠¶Áøí„ÅÆÊ∫ñÂÇô"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b623ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger_.info(\"Preparing for distributed training...\")\n",
    "\n",
    "# == boosting ==\n",
    "torch.set_default_dtype(dtype)\n",
    "\n",
    "model, optimizer, _, dataloader, lr_scheduler = booster.boost(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    lr_scheduler=lr_scheduler,\n",
    "    dataloader=dataloader,\n",
    ")\n",
    "\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "logger_.info(\"Boosted model for distributed training\")\n",
    "\n",
    "log_cuda_memory(\"boost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c9913b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# == global variables ==\n",
    "cfg_epochs = cfg.get(\"epochs\", 1000)\n",
    "\n",
    "log_step = acc_step = 0\n",
    "\n",
    "running_loss = 0.0\n",
    "\n",
    "timers = Timers(record_time=cfg.get(\"record_time\", False), record_barrier=cfg.get(\"record_barrier\", False))\n",
    "\n",
    "nsys = NsysProfiler(\n",
    "    warmup_steps=cfg.get(\"nsys_warmup_steps\", 2),\n",
    "    num_steps=cfg.get(\"nsys_num_steps\", 2),\n",
    "    enabled=cfg.get(\"nsys\", False),\n",
    ")\n",
    "\n",
    "logger_.info(\"Training for %s epochs with %s steps per epoch\", cfg_epochs, num_steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc22b245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# == resume ==\n",
    "\n",
    "load_master_weights = cfg.get(\"load_master_weights\", False)\n",
    "\n",
    "save_master_weights = cfg.get(\"save_master_weights\", False)\n",
    "\n",
    "start_epoch = cfg.get(\"start_epoch\", None)\n",
    "\n",
    "start_step = cfg.get(\"start_step\", None)\n",
    "\n",
    "if cfg.get(\"load\", None) is not None:\n",
    "    logger_.info(\"Loading checkpoint from %s\", cfg.load)\n",
    "\n",
    "    lr_scheduler_to_load = lr_scheduler\n",
    "\n",
    "    if cfg.get(\"update_warmup_steps\", False):\n",
    "        lr_scheduler_to_load = None\n",
    "\n",
    "    ret = checkpoint_io.load(\n",
    "        booster,\n",
    "        cfg.load,\n",
    "        model=model,\n",
    "        ema=ema,\n",
    "        optimizer=optimizer,\n",
    "        lr_scheduler=lr_scheduler_to_load,\n",
    "        sampler=(\n",
    "            None if start_step is not None else sampler\n",
    "        ),  # if specify start step, set last_micro_batch_access_index of a new sampler instead\n",
    "        include_master_weights=load_master_weights,\n",
    "    )\n",
    "\n",
    "    start_epoch = start_epoch if start_epoch is not None else ret[0]\n",
    "\n",
    "    start_step = start_step if start_step is not None else ret[1]\n",
    "\n",
    "    logger_.info(\"Loaded checkpoint %s at epoch %s step %s\", cfg.load, ret[0], ret[1])\n",
    "\n",
    "    # load optimizer and scheduler will overwrite some of the hyperparameters, so we need to reset them\n",
    "    set_lr(optimizer, lr_scheduler, cfg.optim.lr, cfg.get(\"initial_lr\", None))\n",
    "    set_eps(optimizer, cfg.optim.eps)\n",
    "\n",
    "    if cfg.get(\"update_warmup_steps\", False):\n",
    "        assert (\n",
    "            cfg.get(\"warmup_steps\", None) is not None\n",
    "        ), \"you need to set warmup_steps in order to pass --update-warmup-steps True\"\n",
    "        # set_warmup_steps(lr_scheduler, cfg.warmup_steps)\n",
    "        lr_scheduler.step(start_epoch * num_steps_per_epoch + start_step)\n",
    "        logger_.info(\"The learning rate starts from %s\", optimizer.param_groups[0][\"lr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287d3ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if start_step is not None:\n",
    "    # if start step exceeds data length, go to next epoch\n",
    "    if start_step > num_steps_per_epoch:\n",
    "        start_epoch = (\n",
    "            start_epoch + start_step // num_steps_per_epoch\n",
    "            if start_epoch is not None\n",
    "            else start_step // num_steps_per_epoch\n",
    "        )\n",
    "        start_step = start_step % num_steps_per_epoch\n",
    "else:\n",
    "    start_step = 0\n",
    "\n",
    "sampler.set_step(start_step)\n",
    "start_epoch = start_epoch if start_epoch is not None else 0\n",
    "logger_.info(\"Starting from epoch %s step %s\", start_epoch, start_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2056bcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# == sharding EMA model ==\n",
    "if ema is not None:\n",
    "    model_sharding(ema)\n",
    "    ema = ema.to(device)\n",
    "    log_cuda_memory(\"sharding EMA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133dcce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# == warmup autoencoder ==\n",
    "if cfg.get(\"warmup_ae\", False):\n",
    "    shapes = bucket_to_shapes(\n",
    "        cfg.get(\"bucket_config\", None),\n",
    "        batch_size=cfg.ae.batch_size\n",
    "    )\n",
    "\n",
    "    warmup_ae(model_ae, shapes, device, dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a682fd4b",
   "metadata": {},
   "source": [
    "### 5. Ë®ìÁ∑¥„ÅÆ„Ç§„ÉÜ„É¨„Éº„Ç∑„Éß„É≥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5080c3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_min = cfg.get(\"sigma_min\", 1e-5)\n",
    "\n",
    "accumulation_steps = cfg.get(\"accumulation_steps\", 1)\n",
    "\n",
    "ckpt_every = cfg.get(\"ckpt_every\", 0)\n",
    "\n",
    "if cfg.get(\"is_causal_vae\", False):\n",
    "    logger_.info(f\"Preparing visual condition for causal VAE\")\n",
    "    prepare_visual_condition = prepare_visual_condition_causal\n",
    "else:\n",
    "    logger_.info(f\"Preparing visual condition for uncausal VAE\")\n",
    "    prepare_visual_condition = prepare_visual_condition_uncausal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab27e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def prepare_inputs(batch):\n",
    "    logger_.info(f\"Ë®ìÁ∑¥„ÅÆÊ∫ñÂÇô„ÇíÈñãÂßã\")\n",
    "\n",
    "    inp = dict()\n",
    "\n",
    "    x = batch.pop(\"video\")\n",
    "\n",
    "    y = batch.pop(\"text\")\n",
    "\n",
    "    bs = x.shape[0]\n",
    "\n",
    "    # == encode video ==\n",
    "    logger_.info(f\"ÂãïÁîª„ÅÆ„Ç®„É≥„Ç≥„Éº„Éâ„ÇíÈñãÂßã\")\n",
    "    with nsys.range(\"encode_video\"), timers[\"encode_video\"]:\n",
    "        # == prepare condition ==\n",
    "        if cfg.get(\"condition_config\", None) is not None:\n",
    "            # condition for i2v & v2v\n",
    "            x_0, cond = prepare_visual_condition(x, cfg.condition_config, model_ae)\n",
    "            cond = pack(cond, patch_size=cfg.get(\"patch_size\", 2))\n",
    "            inp[\"cond\"] = cond\n",
    "        else:\n",
    "            if cfg.get(\"cached_video\", False):\n",
    "                x_0 = batch.pop(\"video_latents\").to(device=device, dtype=dtype)\n",
    "            else:\n",
    "                x_0 = model_ae.encode(x)\n",
    "\n",
    "    # == prepare timestep ==\n",
    "    logger_.info(f\"„Çø„Ç§„É†„Çπ„ÉÜ„ÉÉ„Éó„ÅÆÊ∫ñÂÇô„ÇíÈñãÂßã\")\n",
    "    # follow SD3 time shift, shift_alpha = 1 for 256px and shift_alpha = 3 for 1024px\n",
    "    shift_alpha = get_res_lin_function()((x_0.shape[-1] * x_0.shape[-2]) // 4)\n",
    "    # add temporal influence\n",
    "    shift_alpha *= math.sqrt(x_0.shape[-3])  # for image, T=1 so no effect\n",
    "    t = torch.sigmoid(torch.randn((bs), device=device))\n",
    "    t = time_shift(shift_alpha, t).to(dtype)\n",
    "\n",
    "    if cfg.get(\"cached_text\", False):\n",
    "        # == encode text ==\n",
    "        logger_.info(f\"„ÉÜ„Ç≠„Çπ„Éà„ÅÆ„Ç®„É≥„Ç≥„Éº„Éâ„ÇíÈñãÂßã(„Ç≠„É£„ÉÉ„Ç∑„É•‰ΩøÁî®)\")\n",
    "        t5_embedding = batch.pop(\"text_t5\").to(device=device, dtype=dtype)\n",
    "        clip_embedding = batch.pop(\"text_clip\").to(device=device, dtype=dtype)\n",
    "        with nsys.range(\"encode_text\"), timers[\"encode_text\"]:\n",
    "            inp_ = prepare_ids(x_0, t5_embedding, clip_embedding)\n",
    "            inp.update(inp_)\n",
    "            x_0 = pack(x_0, patch_size=cfg.get(\"patch_size\", 2))\n",
    "    else:\n",
    "        # == encode text ==\n",
    "        logger_.info(f\"„ÉÜ„Ç≠„Çπ„Éà„ÅÆ„Ç®„É≥„Ç≥„Éº„Éâ„ÇíÈñãÂßã\")\n",
    "        with nsys.range(\"encode_text\"), timers[\"encode_text\"]:\n",
    "            inp_ = prepare(\n",
    "                model_t5,\n",
    "                model_clip,\n",
    "                x_0,\n",
    "                prompt=y,\n",
    "                seq_align=seq_align,\n",
    "                patch_size=cfg.get(\"patch_size\", 2),\n",
    "            )\n",
    "            inp.update(inp_)\n",
    "            x_0 = pack(x_0, patch_size=cfg.get(\"patch_size\", 2))\n",
    "\n",
    "    # == dropout ==\n",
    "    if cfg.get(\"dropout_ratio\", None) is not None:\n",
    "        logger_.info(f\"„Éâ„É≠„ÉÉ„Éó„Ç¢„Ç¶„Éà„ÅÆÈÅ©Áî®„ÇíÈñãÂßã\")\n",
    "        cur_null_txt = null_txt\n",
    "        num_pad_null_txt = inp[\"txt\"].shape[1] - cur_null_txt.shape[1]\n",
    "        if num_pad_null_txt > 0:\n",
    "            cur_null_txt = torch.cat([cur_null_txt] + [cur_null_txt[:, -1:]] * num_pad_null_txt, dim=1)\n",
    "        inp[\"txt\"] = dropout_condition(\n",
    "            cfg.dropout_ratio.get(\"t5\", 0.0),\n",
    "            inp[\"txt\"],\n",
    "            cur_null_txt,\n",
    "        )\n",
    "        inp[\"y_vec\"] = dropout_condition(\n",
    "            cfg.dropout_ratio.get(\"clip\", 0.0),\n",
    "            inp[\"y_vec\"],\n",
    "            null_vec,\n",
    "        )\n",
    "\n",
    "    # == prepare noise vector ==\n",
    "    x_1 = torch.randn_like(x_0, dtype=torch.float32).to(device, dtype)\n",
    "    t_rev = 1 - t\n",
    "    x_t = t_rev[:, None, None] * x_0 + (1 - (1 - sigma_min) * t_rev[:, None, None]) * x_1\n",
    "    inp[\"img\"] = x_t\n",
    "    inp[\"timesteps\"] = t.to(dtype)\n",
    "    inp[\"guidance\"] = torch.full((x_t.shape[0],), cfg.get(\"guidance\", 4), device=x_t.device, dtype=x_t.dtype)\n",
    "\n",
    "    return inp, x_0, x_1\n",
    "\n",
    "sample_batch = next(dataset_iter)\n",
    "sample_batch.keys()\n",
    "pinned_video = sample_batch[\"video\"]\n",
    "sample_batch[\"video\"] = pinned_video.to(device, dtype, non_blocking=True)\n",
    "inp, x_0, x_1 = prepare_inputs(sample_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2303e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger_.debug(f\"inp: {inp.keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ffa2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger_.debug(f\"x_0.shape: {x_0.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904850cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger_.debug(f\"x_1.shape: {x_1.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ad9c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_iter(inp, x_0, x_1):\n",
    "    logger_.info(f\"1„Å§„ÅÆ„Ç§„ÉÜ„É¨„Éº„Ç∑„Éß„É≥„ÇíÂÆüË°å‰∏≠ {inp.keys()=} {x_0.shape=} {x_1.shape=}\")\n",
    "\n",
    "    if is_pipeline_enabled(plugin_type, plugin_config):\n",
    "        logger_.info(f\"„Éë„Ç§„Éó„É©„Ç§„É≥‰∏¶Âàó„Çí‰ΩøÁî®„Åó„Å¶„ÅÑ„Çã„Åü„ÇÅ„ÄÅforward-backward„Çí‰∏Ä‰ΩìÂåñ„Åó„Å¶ÂÆüË°å\")\n",
    "\n",
    "        inp[\"target\"] = (1 - sigma_min) * x_1 - x_0  # follow MovieGen, modify V_t accordingly\n",
    "        with nsys.range(\"forward-backward\"), timers[\"forward-backward\"]:\n",
    "            data_iter = iter([inp])\n",
    "            if cfg.get(\"no_i2v_ref_loss\", False):\n",
    "                loss_fn = (\n",
    "                    lambda out, input_: get_batch_loss(out, input_[\"target\"], input_.pop(\"masks\", None))\n",
    "                    / accumulation_steps\n",
    "                )\n",
    "            else:\n",
    "                loss_fn = (\n",
    "                    lambda out, input_: F.mse_loss(out.float(), input_[\"target\"].float(), reduction=\"mean\")\n",
    "                    / accumulation_steps\n",
    "                )\n",
    "            loss = booster.execute_pipeline(data_iter, model, loss_fn, optimizer)[\"loss\"]\n",
    "            loss = loss * accumulation_steps if loss is not None else loss\n",
    "            loss_item = all_reduce_mean(loss.data.clone().detach())\n",
    "    else:\n",
    "        logger_.info(f\"ÈÄöÂ∏∏„ÅÆÂàÜÊï£Â≠¶Áøí„É´„Éº„Éó„Åßforward„Å®backward„ÇíÂÆüË°å\")\n",
    "\n",
    "        # == forward ==\n",
    "        logger_.info(f\"„Éï„Ç©„ÉØ„Éº„Éâ„ÇíÂÆüË°å\")\n",
    "\n",
    "        with nsys.range(\"forward\"), timers[\"forward\"]:\n",
    "            model_pred = model(**inp)  # B, T, L\n",
    "            v_t = (1 - sigma_min) * x_1 - x_0\n",
    "            if cfg.get(\"no_i2v_ref_loss\", False):\n",
    "                loss = get_batch_loss(model_pred, v_t, inp.pop(\"masks\", None))\n",
    "            else:\n",
    "                loss = F.mse_loss(model_pred.float(), v_t.float(), reduction=\"mean\")\n",
    "\n",
    "        loss_item = all_reduce_mean(loss.data.clone().detach()).item()\n",
    "\n",
    "        # == backward & update ==\n",
    "        dist.barrier()\n",
    "        logger_.info(f\"„Éê„ÉÉ„ÇØ„ÉØ„Éº„Éâ„ÇíÂÆüË°å\")\n",
    "\n",
    "        with nsys.range(\"backward\"), timers[\"backward\"]:\n",
    "            ctx = (\n",
    "                booster.no_sync(model, optimizer)\n",
    "                if cfg.get(\"plugin\", \"zero2\") in (\"zero1\", \"zero1-seq\") and (step + 1) % accumulation_steps != 0\n",
    "                else nullcontext()\n",
    "            )\n",
    "            with ctx:\n",
    "                booster.backward(loss=(loss / accumulation_steps), optimizer=optimizer)\n",
    "\n",
    "    # == optim step ==\n",
    "    logger_.info(f\"„Ç™„Éó„ÉÜ„Ç£„Éû„Ç§„Ç∂„Éº„Çπ„ÉÜ„ÉÉ„Éó„ÇíÂÆüË°å\")\n",
    "\n",
    "    with nsys.range(\"optim\"), timers[\"optim\"]:\n",
    "        if (step + 1) % accumulation_steps == 0:\n",
    "            booster.checkpoint_io.synchronize()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        if lr_scheduler is not None:\n",
    "            lr_scheduler.step()\n",
    "\n",
    "    # == update EMA ==\n",
    "    if ema is not None:\n",
    "        logger_.info(f\"EMA„É¢„Éá„É´„ÅÆÊõ¥Êñ∞„ÇíÂÆüË°å\")\n",
    "        with nsys.range(\"update_ema\"), timers[\"update_ema\"]:\n",
    "            update_ema(\n",
    "                ema,\n",
    "                model.unwrap(),\n",
    "                optimizer=optimizer,\n",
    "                decay=cfg.get(\"ema_decay\", 0.9999),\n",
    "            )\n",
    "\n",
    "    return loss_item\n",
    "\n",
    "# step = 0\n",
    "# sample_loss = run_iter(inp, x_0, x_1)\n",
    "# logger_.info(f\"„Çµ„É≥„Éó„É´„Éê„ÉÉ„ÉÅ„ÅÆÊêçÂ§±: {sample_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b7b1b1",
   "metadata": {},
   "source": [
    "### 6. Ë®ìÁ∑¥„É´„Éº„Éó"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb06d6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    logger_.info(\"Ë®ìÁ∑¥ÈñãÂßã...\")\n",
    "\n",
    "    dist.barrier()\n",
    "    for epoch in range(start_epoch, cfg_epochs):\n",
    "        # == set dataloader to new epoch ==\n",
    "        sampler.set_epoch(epoch)\n",
    "        logger_.info(f\"„Çµ„É≥„Éó„É©„Éº„Çí„Ç®„Éù„ÉÉ„ÇØ {epoch} „Å´Ë®≠ÂÆö„Åó„Åæ„Åó„Åü\")\n",
    "\n",
    "        dataloader_iter = iter(dataloader)\n",
    "\n",
    "        logger_.info(\"„Ç®„Éù„ÉÉ„ÇØ %s „ÇíÈñãÂßã„Åó„Åæ„Åô...\", epoch)\n",
    "        # == training loop in an epoch ==\n",
    "        with tqdm(\n",
    "            enumerate(dataloader_iter, start=start_step),\n",
    "            desc=f\"Epoch {epoch}\",\n",
    "            disable=not is_log_process(plugin_type, plugin_config),\n",
    "            initial=start_step,\n",
    "            total=num_steps_per_epoch,\n",
    "        ) as pbar:\n",
    "            pbar_iter = iter(pbar)\n",
    "\n",
    "            # prefetch one for non-blocking data loading\n",
    "            def fetch_data():\n",
    "                step, batch = next(pbar_iter)\n",
    "                # print(f\"==debug== rank{dist.get_rank()} {dataloader_iter.get_cache_info()}\")\n",
    "                pinned_video = batch[\"video\"]\n",
    "                batch[\"video\"] = pinned_video.to(device, dtype, non_blocking=True)\n",
    "                return batch, step, pinned_video\n",
    "\n",
    "            batch_, step_, pinned_video_ = fetch_data()\n",
    "            logger_.info(f\"„Éá„Éº„Çø„Çí„Éó„É™„Éï„Çß„ÉÉ„ÉÅ„Åó„Åæ„Åó„Åü {step_}\")\n",
    "\n",
    "            for current_step in range(start_step, num_steps_per_epoch):\n",
    "                logger_.info(f\"ÈñãÂßã epoch {epoch} step {current_step}\")\n",
    "\n",
    "                nsys.step()\n",
    "\n",
    "                # == load data ===\n",
    "                logger_.debug(f\"„Éá„Éº„Çø„Çí„É≠„Éº„ÉâÈñãÂßã\")\n",
    "\n",
    "                with nsys.range(\"load_data\"), timers[\"load_data\"]:\n",
    "                    batch, step, pinned_video = batch_, step_, pinned_video_\n",
    "\n",
    "                    if step + 1 < num_steps_per_epoch:\n",
    "                        # only fetch new data if not last step\n",
    "                        batch_, step_, pinned_video_ = fetch_data()\n",
    "\n",
    "                # == run iter ==\n",
    "                logger_.debug(f\"„Ç§„ÉÜ„É¨„Éº„Ç∑„Éß„É≥„ÇíÂÆüË°åÈñãÂßã\")\n",
    "\n",
    "                with nsys.range(\"iter\"), timers[\"iter\"]:\n",
    "\n",
    "                    inp, x_0, x_1 = prepare_inputs(batch)\n",
    "\n",
    "                    # if cache_pin_memory:\n",
    "                    #     dataloader_iter.remove_cache(pinned_video)\n",
    "                    \n",
    "                    loss = run_iter(inp, x_0, x_1)\n",
    "\n",
    "                # == update log info ==\n",
    "                if loss is not None:\n",
    "                    logger_.debug(f\"ÊêçÂ§±„ÇíÊõ¥Êñ∞‰∏≠ {loss=}\")\n",
    "                    running_loss += loss\n",
    "\n",
    "                # == log config ==\n",
    "                logger_.debug(f\"„É≠„Ç∞ÊÉÖÂ†±„ÇíÊõ¥Êñ∞‰∏≠\")\n",
    "                global_step = epoch * num_steps_per_epoch + step\n",
    "                actual_update_step = (global_step + 1) // accumulation_steps\n",
    "                log_step += 1\n",
    "                acc_step += 1\n",
    "\n",
    "                # == logging ==\n",
    "                if (global_step + 1) % accumulation_steps == 0:\n",
    "                    if actual_update_step % cfg.get(\"log_every\", 1) == 0:\n",
    "                        if is_log_process(plugin_type, plugin_config):\n",
    "                            logger_.info(f\"„É≠„Ç∞„ÇíË®òÈå≤‰∏≠ at epoch {epoch} step {step} global_step {global_step} actual_update_step {actual_update_step}\")\n",
    "\n",
    "                            avg_loss = running_loss / log_step\n",
    "                            # progress bar\n",
    "                            pbar.set_postfix(\n",
    "                                {\n",
    "                                    \"loss\": avg_loss,\n",
    "                                    \"global_grad_norm\": optimizer.get_grad_norm(),\n",
    "                                    \"step\": step,\n",
    "                                    \"global_step\": global_step,\n",
    "                                    # \"actual_update_step\": actual_update_step,\n",
    "                                    \"lr\": optimizer.param_groups[0][\"lr\"],\n",
    "                                }\n",
    "                            )\n",
    "                            # tensorboard\n",
    "                            if tb_writer is not None:\n",
    "                                tb_writer.add_scalar(\"loss\", loss, actual_update_step)\n",
    "                            # wandb\n",
    "                            if cfg.get(\"wandb\", False):\n",
    "                                wandb_dict = {\n",
    "                                    \"iter\": global_step,\n",
    "                                    \"acc_step\": acc_step,\n",
    "                                    \"epoch\": epoch,\n",
    "                                    \"loss\": loss,\n",
    "                                    \"avg_loss\": avg_loss,\n",
    "                                    \"lr\": optimizer.param_groups[0][\"lr\"],\n",
    "                                    \"eps\": optimizer.param_groups[0][\"eps\"],\n",
    "                                    \"global_grad_norm\": optimizer.get_grad_norm(),  # test grad norm\n",
    "                                }\n",
    "                                if cfg.get(\"record_time\", False):\n",
    "                                    wandb_dict.update(timers.to_dict())\n",
    "                                wandb.log(wandb_dict, step=actual_update_step)\n",
    "\n",
    "                        running_loss = 0.0\n",
    "                        log_step = 0\n",
    "\n",
    "                # == checkpoint saving ==\n",
    "                logger_.debug(f\"„ÉÅ„Çß„ÉÉ„ÇØ„Éù„Ç§„É≥„Éà„ÅÆ‰øùÂ≠ò„ÇíÁ¢∫Ë™ç‰∏≠\")\n",
    "                # uncomment below 3 lines to forcely clean cache\n",
    "                with nsys.range(\"clean_cache\"), timers[\"clean_cache\"]:\n",
    "                    if ckpt_every > 0 and actual_update_step % ckpt_every == 0 and coordinator.is_master():\n",
    "                        subprocess.run(\"sudo drop_cache\", shell=True)\n",
    "\n",
    "                logger_.debug(f\"„ÉÅ„Çß„ÉÉ„ÇØ„Éù„Ç§„É≥„Éà„ÅÆ‰øùÂ≠ò„ÇíÂÆüË°å‰∏≠\")\n",
    "                with nsys.range(\"checkpoint\"), timers[\"checkpoint\"]:\n",
    "                    if ckpt_every > 0 and actual_update_step % ckpt_every == 0:\n",
    "                        # mannual garbage collection\n",
    "                        gc.collect()\n",
    "\n",
    "                        save_dir = checkpoint_io.save(\n",
    "                            booster,\n",
    "                            exp_dir,\n",
    "                            model=model,\n",
    "                            ema=ema,\n",
    "                            optimizer=optimizer,\n",
    "                            lr_scheduler=lr_scheduler,\n",
    "                            sampler=sampler,\n",
    "                            epoch=epoch,\n",
    "                            step=step + 1,\n",
    "                            global_step=global_step + 1,\n",
    "                            batch_size=cfg.get(\"batch_size\", None),\n",
    "                            lora=use_lora,\n",
    "                            actual_update_step=actual_update_step,\n",
    "                            ema_shape_dict=ema_shape_dict,\n",
    "                            async_io=cfg.get(\"async_io\", False),\n",
    "                            include_master_weights=save_master_weights,\n",
    "                        )\n",
    "\n",
    "                        if is_log_process(plugin_type, plugin_config):\n",
    "                            os.system(f\"chgrp -R share {save_dir}\")\n",
    "\n",
    "                        logger_.info(\n",
    "                            \"Saved checkpoint at epoch %s, step %s, global_step %s to %s\",\n",
    "                            epoch,\n",
    "                            step + 1,\n",
    "                            actual_update_step,\n",
    "                            save_dir,\n",
    "                        )\n",
    "\n",
    "                        # remove old checkpoints\n",
    "                        rm_checkpoints(exp_dir, keep_n_latest=cfg.get(\"keep_n_latest\", -1))\n",
    "                        logger_.info(\"Removed old checkpoints and kept %s latest ones.\", cfg.get(\"keep_n_latest\", -1))\n",
    "                # uncomment below 3 lines to benchmark checkpoint\n",
    "                # if ckpt_every > 0 and actual_update_step % ckpt_every == 0:\n",
    "                #     booster.checkpoint_io._sync_io()\n",
    "                #     checkpoint_io._sync_io()\n",
    "                # == terminal timer ==\n",
    "                if cfg.get(\"record_time\", False):\n",
    "                    print(timers.to_str(epoch, step))\n",
    "\n",
    "        sampler.reset()\n",
    "        start_step = 0\n",
    "    log_cuda_max_memory(\"final\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
