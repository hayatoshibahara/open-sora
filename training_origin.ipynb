{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e54053b",
   "metadata": {},
   "source": [
    "## Ê¶ÇË¶Å"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53236702",
   "metadata": {},
   "source": [
    "Open-Sora 2.0„ÅØ„ÄÅ3000‰∏áÂÜÜ„ÅßÂÆüÁèæÂèØËÉΩ„Å™ÂïÜÁî®„É¨„Éô„É´„ÅÆÂãïÁîªÁîüÊàê„É¢„Éá„É´\n",
    "\n",
    "Ë®ìÁ∑¥„Ç≥„Çπ„Éà„ÅØ„ÄÅÂêåÁ≠â„ÅÆ„É¢„Éá„É´ÔºàMovieGen„ÇÑStep-Video-T2VÔºâ„Çà„Çä„ÇÇ5~10ÂÄç‰Ωé„ÅÑ\n",
    "\n",
    "‰∫∫„ÅÆË©ï‰æ°„Å®VBench„ÅÆ„Çπ„Ç≥„Ç¢„Åß„ÅØ„ÄÅHuyyuan Video„ÇÑRunway Gen-3 Alpha„Å´ÂåπÊïµ:\n",
    "\n",
    "![](image/fig1.png)\n",
    "\n",
    "- Visual Quality: Ë¶ñË¶öÂìÅË≥™\n",
    "- Prompt Following: ÊåáÁ§∫ËøΩÂæìÊÄß\n",
    "- Motion Quality: Âãï„Åç„ÅÆÂìÅË≥™"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12386bd",
   "metadata": {},
   "source": [
    "## „Éá„Éº„Çø"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1780041",
   "metadata": {},
   "source": [
    "ÁõÆÁöÑ„ÅØ„ÄÅÂ≠¶Áøí„ÅÆÈÄ≤Êçó„Å´Âêà„Çè„Åõ„Åü„Éá„Éº„Çø„Éî„É©„Éü„ÉÉ„ÉâÔºàhierarchical data pyramidÔºâ„ÅÆÊßãÁØâ\n",
    "\n",
    "Êßò„ÄÖ„Å™Á®ÆÈ°û„ÅÆ„Éá„Éº„Çø„ÇíÊ§úÂá∫ÂèØËÉΩ„Å™„Å™„Éï„Ç£„É´„Çø„ÇíÈñãÁô∫\n",
    "\n",
    "Â≠¶Áøí„ÅÆÈÄ≤Êçó„Å´Âøú„Åò„Å¶„ÄÅ„Éï„Ç£„É´„Çø„É™„É≥„Ç∞„ÅÆÂº∑Â∫¶„ÇíÈ´ò„ÇÅ„ÄÅÁ¥îÂ∫¶„Å®ÂìÅË≥™„ÅÆÈ´ò„ÅÑÂ∞è„Åï„ÅÑ„Çµ„Éñ„Çª„ÉÉ„Éà„ÅßË®ìÁ∑¥\n",
    "\n",
    "„Éá„Éº„Çø„Éï„Ç£„É´„Çø„É™„É≥„Ç∞„ÅÆÂÖ®‰ΩìÂÉè:\n",
    "\n",
    "![](image/fig2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7093517c",
   "metadata": {},
   "source": [
    "- Á¥´: Áîü„ÅÆÂãïÁîª„ÅÆÂâçÂá¶ÁêÜ\n",
    "    1. „Éï„Ç£„É´„Çø„É™„É≥„Ç∞\n",
    "        - Á†¥Êêç„Åó„Åü„Éï„Ç°„Ç§„É´„ÅÆÈô§Âéª\n",
    "        - Ê•µÁ´Ø„Å™ÂãïÁîª„ÅÆÈô§Âéª\n",
    "            - ÂÜçÁîüÊôÇÈñì„Åå2ÁßíÊú™Ê∫Ä\n",
    "            - 1ÁîªÂÉè„ÅÇ„Åü„Çä„ÅÆ„Éá„Éº„ÇøÈáèÔºàBit per pixelÔºâ„Åå0.02Êú™Ê∫Ä\n",
    "            - „Éï„É¨„Éº„É†„É¨„Éº„ÉàÔºàfpsÔºâ„Åå16Êú™Ê∫Ä\n",
    "            - „Ç¢„Çπ„Éö„ÇØ„ÉàÊØî„ÅåÁØÑÂõ≤Â§ñÔºà1/3, 3Ôºâ\n",
    "            - ÁâπÂÆö„ÅÆ‰ΩéÂìÅË≥™„Å™„Ç®„É≥„Ç≥„Éº„ÉâË®≠ÂÆöÔºàConstrained Baseline profileÔºâ\n",
    "    2. ÈÄ£Á∂ö„Åó„ÅüÊò†ÂÉè„ÇíÊ§úÂá∫„Åó„ÄÅÁü≠„ÅÑ„ÇØ„É™„ÉÉ„Éó„Å´ÂàÜÂâ≤\n",
    "        - FFmpeg„ÅÆlibavfilter„Çí‰ΩøÁî®„Åó„ÄÅ„Ç∑„Éº„É≥„Çπ„Ç≥„Ç¢Ôºà„Éï„É¨„Éº„É†Èñì„ÅÆË¶ñË¶öÂ∑ÆÂàÜÔºâ„ÇíË®àÁÆó\n",
    "    3. ÂãïÁîª„ÅÆ„Éï„Ç©„Éº„Éû„ÉÉ„Éà\n",
    "        - „Éï„É¨„Éº„É†„É¨„Éº„Éà„ÅØ30fps‰ª•‰∏ã\n",
    "        - Èï∑Ëæ∫„ÅØ1080px‰ª•‰∏ã\n",
    "        - „Ç≥„Éº„Éá„ÉÉ„ÇØÔºàÂúßÁ∏ÆÂΩ¢ÂºèÔºâ„ÅØH.264\n",
    "        - ÂãïÁîª„ÅÆÈªíÂ∏Ø„ÇíÂâäÈô§\n",
    "        - 8Áßí„ÇíË∂Ö„Åà„Çã„Ç∑„Éß„ÉÉ„Éà„ÅØ„ÄÅ8Áßí„ÅÆ„ÇØ„É™„ÉÉ„Éó„Å´ÂàÜÂâ≤„Åó„ÄÅ2ÁßíÊú™Ê∫Ä„ÅØÁ†¥Ê£Ñ\n",
    "- Èùí: „ÇØ„É™„ÉÉ„ÉóÂãïÁîª„ÅÆ„Çπ„Ç≥„Ç¢„Éï„Ç£„É´„Çø„É™„É≥„Ç∞\n",
    "    - ÁæéÁöÑ„Çπ„Ç≥„Ç¢„Åß„ÅÆ„Éï„Ç£„É´„Çø„É™„É≥„Ç∞\n",
    "        - [CLIP„Å®MLP][1]„ÅßÁæéÁöÑ„Çπ„Ç≥„Ç¢„Çí‰∫àÊ∏¨\n",
    "            - ÊúÄÂàù„Éª‰∏≠Èñì„ÉªÊúÄÁµÇ„Éï„É¨„Éº„É†„ÇíÊäΩÂá∫„Åó„ÄÅ„Çπ„Ç≥„Ç¢„ÇíË®àÁÆó„Åó„ÄÅÂπ≥Âùá\n",
    "    - ÈÆÆÊòé„Åï„ÅÆ‰Ωé„ÅÑÂãïÁîª„ÅÆ„Éï„Ç£„É´„Çø„É™„É≥„Ç∞\n",
    "        - OpenCV„ÅÆ„É©„Éó„É©„Ç∑„Ç¢„É≥ÊºîÁÆóÂ≠ê„ÅßÁîªÂÉè„ÅÆÂàÜÊï£„Åå‰Ωé„ÅÑÔºà„Åº„ÇÑ„Åë„Å¶„ÅÑ„ÇãÔºâÂãïÁîª„ÇíÈô§Âéª\n",
    "    - Êâã„Éñ„É¨„ÅÆÂ§ö„ÅÑÂãïÁîª„ÅÆ„Éï„Ç£„É´„Çø„É™„É≥„Ç∞\n",
    "        - PySceneDetect„Çí‰ΩøÁî®„Åó„Å¶„ÄÅ„Éï„É¨„Éº„É†Èñì„ÅÆÂ§âÂåñ„ÅåÂ§ß„Åç„ÅÑÂãïÁîª„ÇíÈô§Âéª\n",
    "    - ÈáçË§á„ÇØ„É™„ÉÉ„Éó„ÅÆ„Éï„Ç£„É´„Çø„É™„É≥„Ç∞\n",
    "- Á∑ë: 256px„ÅÆ‰ΩéËß£ÂÉèÂ∫¶ÂãïÁîª\n",
    "    - Â§ö„Åè„ÅÆÊñáÁ´†„ÅåÂê´„Åæ„Çå„ÇãÂãïÁîª„ÅÆ„Éï„Ç£„É´„Çø„É™„É≥„Ç∞\n",
    "        - PaddleOCR„Çí‰ΩøÁî®„Åó„Å¶„ÄÅ„ÉÜ„Ç≠„Çπ„Éà„ÅÆ„Éê„Ç¶„É≥„Éá„Ç£„É≥„Ç∞„Éú„ÉÉ„ÇØ„Çπ„ÇíÊ§úÂá∫\n",
    "        - ‰ø°È†ºÂ∫¶„Çπ„Ç≥„Ç¢„Åå0.7„ÇíË∂Ö„Åà„Çã„Éú„ÉÉ„ÇØ„Çπ„ÅÆÁ∑èÈù¢Á©ç„ÅåÂ§ö„ÅÑÂãïÁîª„ÇíÈô§Âéª\n",
    "    - „É¢„Éº„Ç∑„Éß„É≥„Çπ„Ç≥„Ç¢„Åß„ÅÆ„Éï„Ç£„É´„Çø„É™„É≥„Ç∞\n",
    "        - libavfilter„ÅÆVMAF„Çí‰ΩøÁî®„Åó„Å¶ÂãïÁîª„ÅÆÂãï„Åç„ÅÆÊøÄ„Åó„Åï„ÇíÊ∏¨ÂÆö\n",
    "        - „É¢„Éº„Ç∑„Éß„É≥„Çπ„Ç≥„Ç¢„ÅåÊ•µÁ´Ø„Å´‰Ωé„ÅÑ„ÉªÈ´ò„ÅÑÂãïÁîª„ÇíÈô§Âéª\n",
    "- ÈªÑËâ≤: 768px„ÅÆÈ´òËß£ÂÉèÂ∫¶ÂãïÁîª\n",
    "\n",
    "[1]: https://github.com/christophschuhmann/improved-aesthetic-predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa995eea",
   "metadata": {},
   "source": [
    "ÂãïÁîª„ÅÆ„Ç≠„É£„Éó„Ç∑„Éß„É≥„Çí‰ΩúÊàê„Åô„Çã„Åü„ÇÅ„Å´„ÄÅË¶ñË¶öË®ÄË™û„É¢„Éá„É´„Çí‰ΩøÁî®:\n",
    "\n",
    "- 256pxÂãïÁîª„Å´„ÅØ„ÄÅLLaVA-Video\n",
    "- 778pxÂãïÁîª„Å´„ÅØ„ÄÅQwen 2.5 MaxÔºà„Éè„É´„Ç∑„Éç„Éº„Ç∑„Éß„É≥„ÅåÂ∞ë„Å™„ÅÑ„Éó„É≠„Éó„É©„Ç§„Ç®„Çø„É™„É¢„Éá„É´Ôºâ\n",
    "\n",
    "„Ç≠„É£„Éó„Ç∑„Éß„É≥ÁîüÊàê„ÅÆ„Éó„É≠„É≥„Éó„Éà„ÅÆÊßãÊàê:\n",
    "\n",
    "- ‰∏ª„Å™Ë¢´ÂÜô‰Ωì\n",
    "- Ë¢´ÂÜô‰Ωì„ÅÆÂãï„Åç\n",
    "- ËÉåÊôØ„ÇÑÁí∞Â¢É\n",
    "- Ë®ºÊòéÊù°‰ª∂„ÇÑÈõ∞Âõ≤Ê∞ó\n",
    "- „Ç´„É°„É©„ÉØ„Éº„ÇØ\n",
    "- „É™„Ç¢„É´„Éª„Ç∑„Éç„Éû„ÉÜ„Ç£„ÉÉ„ÇØ„Éª3D„Éª„Ç¢„Éã„É°„Å™„Å©„ÅÆÂãïÁîª„ÅÆ„Çπ„Çø„Ç§„É´\n",
    "\n",
    "ÁîüÊàêÊôÇ„Å´Âãï„Åç„ÅÆÂº∑Â∫¶„ÇíË™øÊï¥ÂèØËÉΩ„Å´„Åô„Çã„Åü„ÇÅ„ÄÅ„Ç≠„É£„Éó„Ç∑„Éß„É≥„ÅÆÊúÄÂæå„Å´„É¢„Éº„Ç∑„Éß„É≥„Çπ„Ç≥„Ç¢„ÇíËøΩË®ò"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7587fc55",
   "metadata": {},
   "source": [
    "„Éï„Ç£„É´„Çø„É™„É≥„Ç∞Âæå„ÅÆ„Éá„Éº„Çø„ÅÆÁµ±Ë®à:\n",
    "\n",
    "![](image/fig3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff7e82d",
   "metadata": {},
   "source": [
    "- ÁæéÁöÑ„Çπ„Ç≥„Ç¢„ÅØ4.5~5.5„Åß‰∏≠Á®ãÂ∫¶\n",
    "- ÂãïÁîª„ÅÆÈï∑„Åï„ÅØ2~8Áßí„Åß„ÄÅÂçäÂàÜËøë„Åè„Åå6~8Áßí\n",
    "- „Ç¢„Çπ„Éö„ÇØ„ÉàÊØî„ÅØ„ÄÅÂ§ßÈÉ®ÂàÜ„Åå0.5~0.75Ôºà16:9„ÅÆÊ®™Èï∑ÂãïÁîªÔºâ\n",
    "- „Ç≠„É£„Éó„Ç∑„Éß„É≥„ÅÆ70%„ÅØ75ÂçòË™û„ÇíË∂Ö„Åà„Å¶„ÅÑ„Å¶ÊÉÖÂ†±Èáè„ÅåÂ§ö„ÅÑ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1277b7",
   "metadata": {},
   "source": [
    "„Ç≠„É£„Éó„Ç∑„Éß„É≥„ÅÆ„ÉØ„Éº„Éâ„ÇØ„É©„Ç¶„Éâ:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab60e0b",
   "metadata": {},
   "source": [
    "![](image/fig4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1d547b",
   "metadata": {},
   "source": [
    "- ËÉåÊôØ„ÇÑÁÖßÊòéÊù°‰ª∂„ÇÇÂê´„Åæ„Çå„Å¶„ÅÑ„Å¶„ÄÅË¢´ÂÜô‰Ωì„ÅØ‰∫∫Áâ©„ÅåÂ§ö„ÅÑ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c25823",
   "metadata": {},
   "source": [
    "## „Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346c05aa",
   "metadata": {},
   "source": [
    "### 3Ê¨°ÂÖÉ„Ç™„Éº„Éà„Ç®„É≥„Ç≥„Éº„ÉÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a577fd",
   "metadata": {},
   "source": [
    "[Hunyuan Video VAE][1]„ÅÆ„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„ÇíÂäπÁéáÂåñ„Åó„ÅüVideo DC-AE„ÇíÈñãÁô∫\n",
    "\n",
    "DC-AE„ÅØ„ÄÅ[Deep Compression Autoencoder][2]„ÅÆÁï•\n",
    "\n",
    "ÂúßÁ∏ÆÁéá„ÅØ„ÄÅ$4\\times 32\\times 32$ÔºàÊôÇÈñì„ÅØ $\\frac{1}{4}$„ÄÅÁ∏¶„Å®Ê®™„ÅØ$\\frac{1}{32}$„Å´ÂúßÁ∏ÆÔºâ\n",
    "\n",
    "„Ç™„Éº„Éà„Ç®„É≥„Ç≥„Éº„ÉÄ„Éº„ÅÆÂ≠¶Áøí„Éá„Éº„Çø„ÅØ32„Éï„É¨„Éº„É†„ÄÅ256px„ÅÆ„Åü„ÇÅ„ÄÅÊΩúÂú®Ë°®Áèæ„ÅØ$8\\times 8\\times 8$\n",
    "\n",
    "[1]: https://arxiv.org/abs/2412.03603\n",
    "[2]: https://arxiv.org/abs/2410.10733"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef5fb66",
   "metadata": {},
   "source": [
    "Video DC-AE„ÅÆ„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£:\n",
    "\n",
    "![](image/fig5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346d9939",
   "metadata": {},
   "source": [
    "- „Ç®„É≥„Ç≥„Éº„ÉÄ\n",
    "    - 3Â±§„ÅÆResBlock„Å®3Â±§„ÅÆEfficientViT Block„ÅßÊßãÊàê„Åï„Çå„Çã\n",
    "    - ÊúÄÂàù„ÅÆ5„Å§„ÅÆ„Éñ„É≠„ÉÉ„ÇØ„ÅØ„ÄÅ„ÉÄ„Ç¶„É≥„Çµ„É≥„Éó„É™„É≥„Ç∞Áî®\n",
    "    - Â≠¶Áøí„ÇíÂèØËÉΩ„Å´„Åô„Çã„Åü„ÇÅ„ÄÅ„ÉÄ„Ç¶„É≥„Çµ„É≥„Éó„É´„Éñ„É≠„ÉÉ„ÇØ„Å´„ÅØ„ÄÅÊÆãÂ∑ÆÊé•Á∂ö„ÅåÂ∞éÂÖ•\n",
    "    - ÊÆãÂ∑ÆÊé•Á∂ö„ÅØ„Éî„ÇØ„Çª„É´„Ç¢„É≥„Ç∑„É£„ÉÉ„Éï„É™„É≥„Ç∞„Çí‰ΩøÁî®ÔºàSpace&Time->ChannelÔºâ\n",
    "- „Éá„Ç≥„Éº„ÉÄ\n",
    "    - 3Â±§„ÅÆEfficientViT Block„Å®3Â±§„ÅÆResBlock„ÅßÊßãÊàê„Åï„Çå„Çã\n",
    "    - ÊúÄÂæå„ÅÆ5„Å§„ÅÆ„Éñ„É≠„ÉÉ„ÇØ„ÅØ„ÄÅ„Ç¢„ÉÉ„Éó„Çµ„É≥„Éó„É™„É≥„Ç∞Áî®\n",
    "    - Â≠¶Áøí„ÇíÂèØËÉΩ„Å´„Åô„Çã„Åü„ÇÅ„ÄÅ„Ç¢„ÉÉ„Éó„Çµ„É≥„Éó„É´„Éñ„É≠„ÉÉ„ÇØ„Å´„ÅØ„ÄÅÊÆãÂ∑ÆÊé•Á∂ö„ÅåÂ∞éÂÖ•\n",
    "    - ÊÆãÂ∑ÆÊé•Á∂ö„ÅØ„Éî„ÇØ„Çª„É´„Ç∑„É£„ÉÉ„Éï„É™„É≥„Ç∞„Çí‰ΩøÁî®ÔºàChannel->Space&TimeÔºâ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb61f01",
   "metadata": {},
   "source": [
    "Video DC-AE„Çí„Çπ„ÇØ„É©„ÉÉ„ÉÅ„Åã„ÇâÂ≠¶Áøí„Åó„ÄÅÂÜçÊßãÊàêÂìÅË≥™„ÇíË©ï‰æ°:\n",
    "\n",
    "![](image/table1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df750de",
   "metadata": {},
   "source": [
    "- LPIPS: ‰∫∫Èñì„ÅÆÁü•Ë¶ö„Å´Ëøë„ÅÑÁîªË≥™Ë©ï‰æ°ÊåáÊ®ô"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adeda3cd",
   "metadata": {},
   "source": [
    "## DiT„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759c3421",
   "metadata": {},
   "source": [
    "Èõ¢„Çå„Åü„Éï„É¨„Éº„É†„ÇÑÁîªÁ¥†ÂêåÂ£´„ÅÆÈñ¢‰øÇ„ÇíÂäπÊûúÁöÑ„Å´Êçâ„Åà„Çã„Éï„É´„Ç¢„ÉÜ„É≥„Ç∑„Éß„É≥„ÇíÊé°Áî®\n",
    "\n",
    "ÂãïÁîª„ÅØVideo DC-AE„ÅßÂúßÁ∏ÆÂæå„ÄÅ„Éë„ÉÉ„ÉÅ„Çµ„Ç§„Ç∫1Ôºà=„Éë„ÉÉ„ÉÅÂåñÁÑ°„ÅóÔºâ„Åß„Éï„É©„ÉÉ„ÉàÂåñ\n",
    "\n",
    "Hunyuan Video„ÅÆ„Ç™„Éº„Éà„Ç®„É≥„Ç≥„Éº„ÉÄ„Éº„Çí‰ΩøÁî®„Åô„ÇãÂ†¥Âêà„ÅØ„ÄÅ„Éë„ÉÉ„ÉÅ„Çµ„Ç§„Ç∫2„ÅåÂøÖË¶Å"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df79314e",
   "metadata": {},
   "source": [
    "FLUX„ÅÆ[MMDiT][1]„ÇíÂèÇËÄÉ„Å´„ÄÅ„Éá„É•„Ç¢„É´„Çπ„Éà„É™„Éº„É†„Å®„Ç∑„É≥„Ç∞„É´„Çπ„Éà„É™„Éº„É†„Åã„Çâ„Å™„ÇãÊßãÈÄ†„ÇíÊé°Áî®:\n",
    "\n",
    "![](image/fig6.png)\n",
    "\n",
    "[1]: https://github.com/black-forest-labs/flux"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968e2d5c",
   "metadata": {},
   "source": [
    "- „Éá„É•„Ç¢„É´„Çπ„Éà„É™„Éº„É†„Éñ„É≠„ÉÉ„ÇØ„Åß„ÄÅÂãïÁîª„Å®„ÉÜ„Ç≠„Çπ„Éà„ÅåÂà•„ÄÖ„Å´ÁâπÂæ¥ÊäΩÂá∫„Åï„Çå„Çã\n",
    "- „Ç∑„É≥„Ç∞„É´„Çπ„Éà„É™„Éº„É†„Éñ„É≠„ÉÉ„ÇØ„Åß„ÄÅÁâπÂæ¥„ÇíÁµ±Âêà„Åô„Çã"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f3e053",
   "metadata": {},
   "source": [
    "Á©∫Èñì„Å®ÊôÇÈñìÊÉÖÂ†±„ÇíÊçâ„Åà„Çã„Åü„ÇÅ„Å´„ÄÅ3D RoPE„ÇíÊé°Áî®\n",
    "\n",
    "„ÉÜ„Ç≠„Çπ„Éà„Éé„Ç®„É≥„Ç≥„Éº„Éâ„ÅØ„ÄÅ2„Å§„ÅÆ‰∫ãÂâçÂ≠¶ÁøíÊ∏à„Åø„É¢„Éá„É´„ÇíÊé°Áî®:\n",
    "\n",
    "- T5-XXL: Ë§áÈõë„Å™„ÉÜ„Ç≠„Çπ„Éà„ÅÆÊÑèÂë≥„ÇíÊçâ„Åà„Çã\n",
    "- CLIP-Large: „ÉÜ„Ç≠„Çπ„Éà„Å®Ë¶ñË¶öÊ¶ÇÂøµ„ÅÆÊï¥ÂêàÊÄß„ÇíÊçâ„Åà„ÇãÔºà=ÊåáÁ§∫ËøΩÂæìÊÄß„ÇíÈ´ò„ÇÅ„ÇãÔºâ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6548ce9c",
   "metadata": {},
   "source": [
    "![](image/table2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3baaba03",
   "metadata": {},
   "source": [
    "## ÂÆüË£Ö"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf13bf8",
   "metadata": {},
   "source": [
    "- image.py: ÁîªÂÉè„ÅÆ„Åø„ÅßÂ≠¶Áøí„ÄÇ\n",
    "- stage1.py: 256pxËß£ÂÉèÂ∫¶„ÅÆÂãïÁîª„ÅßÂ≠¶Áøí„ÄÇ\n",
    "- stage2.py: 768pxËß£ÂÉèÂ∫¶„ÅÆÂãïÁîª„ÅßÂ≠¶ÁøíÔºà„Ç∑„Éº„Ç±„É≥„Çπ‰∏¶ÂàóÂåñ„Çí‰ΩøÁî®„ÄÅ„Éá„Éï„Ç©„É´„Éà„ÅØ4Ôºâ„ÄÇ\n",
    "- stage1_i2v.py: 256pxËß£ÂÉèÂ∫¶„ÅßT2VÔºà„ÉÜ„Ç≠„Çπ„Éà„Åã„ÇâÂãïÁîªÔºâ„Å®I2VÔºàÁîªÂÉè„Åã„ÇâÂãïÁîªÔºâ„ÇíÂ≠¶Áøí„ÄÇ\n",
    "- stage2_i2v.py: 768pxËß£ÂÉèÂ∫¶„ÅßT2V„Å®I2V„ÇíÂ≠¶Áøí„ÄÇ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e895226e",
   "metadata": {},
   "source": [
    "## Áí∞Â¢ÉÊßãÁØâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa9f1318",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f34edd62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/open-sora/Open-Sora\n",
      "Obtaining file:///workspaces/open-sora/Open-Sora\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hInstalling collected packages: opensora\n",
      "  Attempting uninstall: opensora\n",
      "    Found existing installation: opensora 2.0.0\n",
      "    Uninstalling opensora-2.0.0:\n",
      "      Successfully uninstalled opensora-2.0.0\n",
      "\u001b[33m  DEPRECATION: Legacy editable install of opensora==2.0.0 from file:///workspaces/open-sora/Open-Sora (setup.py develop) is deprecated. pip 25.3 will enforce this behaviour change. A possible replacement is to add a pyproject.toml or enable --use-pep517, and use setuptools >= 64. If the resulting installation is not behaving as expected, try using --config-settings editable_mode=compat. Please consult the setuptools documentation for more information. Discussion can be found at https://github.com/pypa/pip/issues/11457\u001b[0m\u001b[33m\n",
      "\u001b[0m  Running setup.py develop for opensora\n",
      "Successfully installed opensora-2.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%cd /workspaces/open-sora/Open-Sora\n",
    "%pip install -e . --no-deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e52ec244",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üü© Python 3.12.11\n",
      "üü© Thu Dec 25 18:38:29 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.163.01             Driver Version: 550.163.01     CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4090        Off |   00000000:01:00.0 Off |                  Off |\n",
      "|  0%   34C    P8              7W /  450W |     140MiB /  24564MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import platform\n",
    "import subprocess\n",
    "\n",
    "if os.path.exists(\"debug.log\"):\n",
    "    os.remove(\"debug.log\")\n",
    "\n",
    "def custom_format(record):\n",
    "    match record.levelno:\n",
    "        case logging.DEBUG:\n",
    "            level = \"üü¶\"\n",
    "        case logging.INFO:\n",
    "            level = \"üü©\"\n",
    "        case logging.WARNING:\n",
    "            level = \"üü®\"\n",
    "        case logging.ERROR:\n",
    "            level = \"üü•\"\n",
    "        case logging.CRITICAL:\n",
    "            level = \"üõë\"\n",
    "    return f\"{level} {record.getMessage()}\"\n",
    "\n",
    "logger_ = logging.getLogger()\n",
    "\n",
    "for handler in logger_.handlers:\n",
    "    logger_.removeHandler(handler)\n",
    "\n",
    "formatter = logging.Formatter()\n",
    "formatter.format = custom_format\n",
    "\n",
    "file_handler = logging.FileHandler(\"debug.log\")\n",
    "file_handler.setFormatter(formatter)\n",
    "logger_.addHandler(file_handler)\n",
    "\n",
    "stream_handler = logging.StreamHandler()\n",
    "stream_handler.setFormatter(formatter)\n",
    "logger_.addHandler(stream_handler)\n",
    "logger_.setLevel(logging.DEBUG)\n",
    "\n",
    "PYTHON_VERSION = platform.python_version()\n",
    "logger_.info(f\"Python {PYTHON_VERSION}\")\n",
    "\n",
    "NVIDIA_SMI = subprocess.run(\"nvidia-smi\", capture_output=True, text=True).stdout\n",
    "logger_.info(f\"{NVIDIA_SMI}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be1cb4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu124\n",
      "Requirement already satisfied: torch==2.5.1 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (2.5.1+cu124)\n",
      "Requirement already satisfied: torchvision==0.20.1 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (0.20.1+cu124)\n",
      "Requirement already satisfied: torchaudio==2.5.1 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (2.5.1+cu124)\n",
      "Requirement already satisfied: filelock in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from torch==2.5.1) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from torch==2.5.1) (4.15.0)\n",
      "Requirement already satisfied: networkx in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from torch==2.5.1) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from torch==2.5.1) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from torch==2.5.1) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from torch==2.5.1) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from torch==2.5.1) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from torch==2.5.1) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from torch==2.5.1) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from torch==2.5.1) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from torch==2.5.1) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from torch==2.5.1) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from torch==2.5.1) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from torch==2.5.1) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from torch==2.5.1) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from torch==2.5.1) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from torch==2.5.1) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from torch==2.5.1) (3.1.0)\n",
      "Requirement already satisfied: setuptools in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from torch==2.5.1) (78.1.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from torch==2.5.1) (1.13.1)\n",
      "Requirement already satisfied: numpy in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from torchvision==0.20.1) (2.1.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from torchvision==0.20.1) (11.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from sympy==1.13.1->torch==2.5.1) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from jinja2->torch==2.5.1) (2.1.5)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install torch==2.6.0 torchvision==0.21.0 torchaudio==2.6.0 --index-url https://download.pytorch.org/whl/cu124\n",
    "%pip install torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/cu124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57815940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu124\n",
      "Requirement already satisfied: accelerate in /opt/miniconda/envs/py312/lib/python3.12/site-packages (1.10.1)\n",
      "Requirement already satisfied: av in /opt/miniconda/envs/py312/lib/python3.12/site-packages (13.1.0)\n",
      "Requirement already satisfied: colossalai in /opt/miniconda/envs/py312/lib/python3.12/site-packages (0.5.0)\n",
      "Requirement already satisfied: ftfy in /opt/miniconda/envs/py312/lib/python3.12/site-packages (6.3.1)\n",
      "Requirement already satisfied: liger-kernel in /opt/miniconda/envs/py312/lib/python3.12/site-packages (0.6.4)\n",
      "Requirement already satisfied: omegaconf in /opt/miniconda/envs/py312/lib/python3.12/site-packages (2.3.0)\n",
      "Requirement already satisfied: mmengine in /opt/miniconda/envs/py312/lib/python3.12/site-packages (0.10.7)\n",
      "Requirement already satisfied: openai in /opt/miniconda/envs/py312/lib/python3.12/site-packages (2.11.0)\n",
      "Requirement already satisfied: pandas in /opt/miniconda/envs/py312/lib/python3.12/site-packages (2.3.3)\n",
      "Requirement already satisfied: pandarallel in /opt/miniconda/envs/py312/lib/python3.12/site-packages (1.6.5)\n",
      "Requirement already satisfied: pyarrow in /opt/miniconda/envs/py312/lib/python3.12/site-packages (21.0.0)\n",
      "Requirement already satisfied: tensorboard in /opt/miniconda/envs/py312/lib/python3.12/site-packages (2.20.0)\n",
      "Requirement already satisfied: wandb in /opt/miniconda/envs/py312/lib/python3.12/site-packages (0.23.1)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from accelerate) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from accelerate) (25.0)\n",
      "Requirement already satisfied: psutil in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from accelerate) (7.1.0)\n",
      "Requirement already satisfied: pyyaml in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from accelerate) (6.0.3)\n",
      "Requirement already satisfied: torch>=2.0.0 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from accelerate) (2.5.1+cu124)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from accelerate) (0.35.3)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from accelerate) (0.6.2)\n",
      "Requirement already satisfied: tqdm in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from colossalai) (4.67.1)\n",
      "Requirement already satisfied: pre-commit in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from colossalai) (4.5.0)\n",
      "Requirement already satisfied: rich in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from colossalai) (14.2.0)\n",
      "Requirement already satisfied: click in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from colossalai) (8.2.1)\n",
      "Requirement already satisfied: fabric in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from colossalai) (3.2.2)\n",
      "Requirement already satisfied: contexttimer in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from colossalai) (0.3.3)\n",
      "Requirement already satisfied: ninja in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from colossalai) (1.13.0)\n",
      "Requirement already satisfied: einops in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from colossalai) (0.8.1)\n",
      "Requirement already satisfied: pydantic in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from colossalai) (2.12.5)\n",
      "Requirement already satisfied: ray in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from colossalai) (2.52.1)\n",
      "Requirement already satisfied: sentencepiece in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from colossalai) (0.2.1)\n",
      "Requirement already satisfied: google in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from colossalai) (3.0.0)\n",
      "Requirement already satisfied: protobuf in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from colossalai) (6.33.2)\n",
      "Requirement already satisfied: transformers==4.51.3 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from colossalai) (4.51.3)\n",
      "Requirement already satisfied: peft<=0.13.2,>=0.7.1 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from colossalai) (0.13.2)\n",
      "Requirement already satisfied: bitsandbytes>=0.39.0 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from colossalai) (0.49.0)\n",
      "Requirement already satisfied: rpyc==6.0.0 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from colossalai) (6.0.0)\n",
      "Requirement already satisfied: fastapi in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from colossalai) (0.124.4)\n",
      "Requirement already satisfied: uvicorn==0.29.0 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from colossalai) (0.29.0)\n",
      "Requirement already satisfied: galore_torch in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from colossalai) (1.0)\n",
      "Requirement already satisfied: diffusers==0.29.0 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from colossalai) (0.29.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from diffusers==0.29.0->colossalai) (8.7.0)\n",
      "Requirement already satisfied: filelock in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from diffusers==0.29.0->colossalai) (3.13.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from diffusers==0.29.0->colossalai) (2025.9.18)\n",
      "Requirement already satisfied: requests in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from diffusers==0.29.0->colossalai) (2.32.5)\n",
      "Requirement already satisfied: Pillow in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from diffusers==0.29.0->colossalai) (11.0.0)\n",
      "Requirement already satisfied: plumbum in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from rpyc==6.0.0->colossalai) (1.10.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from transformers==4.51.3->colossalai) (0.21.4)\n",
      "Requirement already satisfied: h11>=0.8 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from uvicorn==0.29.0->colossalai) (0.16.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from huggingface_hub>=0.21.0->accelerate) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from huggingface_hub>=0.21.0->accelerate) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from huggingface_hub>=0.21.0->accelerate) (1.1.10)\n",
      "Requirement already satisfied: networkx in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.1.0)\n",
      "Requirement already satisfied: setuptools in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (78.1.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: wcwidth in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from ftfy) (0.2.14)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from omegaconf) (4.9.3)\n",
      "Requirement already satisfied: addict in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from mmengine) (2.4.0)\n",
      "Requirement already satisfied: matplotlib in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from mmengine) (3.10.6)\n",
      "Requirement already satisfied: termcolor in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from mmengine) (3.2.0)\n",
      "Requirement already satisfied: yapf in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from mmengine) (0.43.0)\n",
      "Requirement already satisfied: opencv-python>=3 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from mmengine) (4.12.0.88)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from openai) (4.12.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from openai) (0.12.0)\n",
      "Requirement already satisfied: sniffio in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from pydantic->colossalai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from pydantic->colossalai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from pydantic->colossalai) (0.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: dill>=0.3.1 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from pandarallel) (0.3.8)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from tensorboard) (2.3.1)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from tensorboard) (1.76.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from tensorboard) (3.10)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from tensorboard) (3.1.4)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from wandb) (3.1.45)\n",
      "Requirement already satisfied: platformdirs in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from wandb) (4.4.0)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from wandb) (2.47.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from requests->diffusers==0.29.0->colossalai) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from requests->diffusers==0.29.0->colossalai) (2.5.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\n",
      "Requirement already satisfied: invoke>=2.0 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from fabric->colossalai) (2.2.1)\n",
      "Requirement already satisfied: paramiko>=2.4 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from fabric->colossalai) (4.0.0)\n",
      "Requirement already satisfied: decorator>=5 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from fabric->colossalai) (5.2.1)\n",
      "Requirement already satisfied: deprecated>=1.2 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from fabric->colossalai) (1.3.1)\n",
      "Requirement already satisfied: wrapt<3,>=1.10 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from deprecated>=1.2->fabric->colossalai) (2.0.1)\n",
      "Requirement already satisfied: bcrypt>=3.2 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from paramiko>=2.4->fabric->colossalai) (5.0.0)\n",
      "Requirement already satisfied: cryptography>=3.3 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from paramiko>=2.4->fabric->colossalai) (46.0.3)\n",
      "Requirement already satisfied: pynacl>=1.5 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from paramiko>=2.4->fabric->colossalai) (1.6.1)\n",
      "Requirement already satisfied: cffi>=2.0.0 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from cryptography>=3.3->paramiko>=2.4->fabric->colossalai) (2.0.0)\n",
      "Requirement already satisfied: pycparser in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from cffi>=2.0.0->cryptography>=3.3->paramiko>=2.4->fabric->colossalai) (2.23)\n",
      "Requirement already satisfied: starlette<0.51.0,>=0.40.0 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from fastapi->colossalai) (0.50.0)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from fastapi->colossalai) (0.0.4)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from google->colossalai) (4.14.3)\n",
      "Requirement already satisfied: soupsieve>=1.6.1 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from beautifulsoup4->google->colossalai) (2.8)\n",
      "Requirement already satisfied: zipp>=3.20 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from importlib-metadata->diffusers==0.29.0->colossalai) (3.23.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from matplotlib->mmengine) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from matplotlib->mmengine) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from matplotlib->mmengine) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from matplotlib->mmengine) (1.4.9)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from matplotlib->mmengine) (3.2.5)\n",
      "Requirement already satisfied: cfgv>=2.0.0 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from pre-commit->colossalai) (3.5.0)\n",
      "Requirement already satisfied: identify>=1.0.0 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from pre-commit->colossalai) (2.6.15)\n",
      "Requirement already satisfied: nodeenv>=0.11.1 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from pre-commit->colossalai) (1.9.1)\n",
      "Requirement already satisfied: virtualenv>=20.10.0 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from pre-commit->colossalai) (20.35.4)\n",
      "Requirement already satisfied: distlib<1,>=0.3.7 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from virtualenv>=20.10.0->pre-commit->colossalai) (0.4.0)\n",
      "Requirement already satisfied: jsonschema in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from ray->colossalai) (4.25.1)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from ray->colossalai) (1.1.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from jsonschema->ray->colossalai) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from jsonschema->ray->colossalai) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from jsonschema->ray->colossalai) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from jsonschema->ray->colossalai) (0.30.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from rich->colossalai) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from rich->colossalai) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->colossalai) (0.1.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install \\\n",
    "    accelerate \\\n",
    "    av \\\n",
    "    colossalai \\\n",
    "    ftfy \\\n",
    "    liger-kernel \\\n",
    "    omegaconf \\\n",
    "    mmengine \\\n",
    "    openai \\\n",
    "    pandas \\\n",
    "    pandarallel \\\n",
    "    pyarrow \\\n",
    "    tensorboard \\\n",
    "    wandb \\\n",
    "    --extra-index-url https://download.pytorch.org/whl/cu124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4303893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flash-attn in /opt/miniconda/envs/py312/lib/python3.12/site-packages (2.8.3)\n",
      "Requirement already satisfied: torch in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from flash-attn) (2.5.1+cu124)\n",
      "Requirement already satisfied: einops in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from flash-attn) (0.8.1)\n",
      "Requirement already satisfied: filelock in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from torch->flash-attn) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from torch->flash-attn) (4.15.0)\n",
      "Requirement already satisfied: networkx in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from torch->flash-attn) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from torch->flash-attn) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from torch->flash-attn) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from torch->flash-attn) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from torch->flash-attn) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from torch->flash-attn) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from torch->flash-attn) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from torch->flash-attn) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from torch->flash-attn) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from torch->flash-attn) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from torch->flash-attn) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from torch->flash-attn) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from torch->flash-attn) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from torch->flash-attn) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from torch->flash-attn) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from torch->flash-attn) (3.1.0)\n",
      "Requirement already satisfied: setuptools in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from torch->flash-attn) (78.1.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from torch->flash-attn) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from sympy==1.13.1->torch->flash-attn) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/miniconda/envs/py312/lib/python3.12/site-packages (from jinja2->torch->flash-attn) (2.1.5)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install flash-attn --no-build-isolation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489f2609",
   "metadata": {},
   "source": [
    "### „ÉÄ„Ç¶„É≥„É≠„Éº„Éâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad3af23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 269.53GB„ÅÆÂãïÁîª„Éá„Éº„Çø„Çª„ÉÉ„Éà„Çí„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ\n",
    "# https://modelscope.cn/datasets/hpcai-tech/open-sora-pexels-45k\n",
    "\n",
    "if False:\n",
    "    !apt update && apt install git-lfs\n",
    "    !git-lfs install\n",
    "    !git clone \"https://www.modelscope.cn/datasets/hpcai-tech/open-sora-pexels-45k.git\"\n",
    "    !cd open-sora-pexels-45k && \\\n",
    "        cat tar/pexels_45k.tar.* > pexels_45k.tar && \\\n",
    "        mkdir ../datasets && \\\n",
    "        mv pexels_45k ../datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "257aa955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Êï∞‰ª∂„ÅÆÂãïÁîª„ÇíÁõ¥Êé•„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ\n",
    "\n",
    "if False:\n",
    "    from multiprocessing import Pool\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    import re\n",
    "    import subprocess\n",
    "\n",
    "    os.makedirs(\"pexel_10\", exist_ok=True)\n",
    "    necessary_csv_path = \"/workspaces/open-sora/pexels_10/pexels_10_necessary.csv\"\n",
    "    df = pd.read_csv(necessary_csv_path)\n",
    "\n",
    "    video_urls = []\n",
    "\n",
    "    for path in df[\"path\"]:\n",
    "        match = re.search(r\"/(\\d+)_\", path)\n",
    "        video_id = match.group(1)\n",
    "        video_url = f\"https://www.pexels.com/download/video/{video_id}\"\n",
    "        df.loc[df[\"path\"] == path, \"url\"] = video_url\n",
    "\n",
    "    def download_video(args):\n",
    "        url, save_path = args\n",
    "\n",
    "        # ‰øùÂ≠òÂÖà„ÅÆ„Éá„Ç£„É¨„ÇØ„Éà„É™„Çí‰ΩúÊàêÔºàÂ≠òÂú®„Åó„Å™„ÅÑÂ†¥ÂêàÔºâ\n",
    "        directory = os.path.dirname(save_path)\n",
    "        if directory:\n",
    "            os.makedirs(directory, exist_ok=True)\n",
    "        \n",
    "        # „Éï„Ç°„Ç§„É´„ÅåÊó¢„Å´Â≠òÂú®„Åó„Å™„ÅÑÂ†¥Âêà„ÅÆ„Åø„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ„ÇíÂÆüË°å\n",
    "        if not os.path.exists(save_path):\n",
    "            try:\n",
    "                # -O: Âá∫Âäõ„Éï„Ç°„Ç§„É´Âêç„ÇíÊåáÂÆö\n",
    "                # -q: „É≠„Ç∞Âá∫Âäõ„ÇíÊäëÂà∂ÔºàÈÄ≤Êçó„ÅåË¶ã„Åü„ÅÑÂ†¥Âêà„ÅØÂ§ñ„Åó„Å¶„Åè„Å†„Åï„ÅÑÔºâ\n",
    "                command = [\"wget\", \"-q\", \"-O\", save_path, url]\n",
    "                subprocess.run(command, check=True)\n",
    "            except subprocess.CalledProcessError:\n",
    "                print(f\"Failed to download: {url}\")\n",
    "\n",
    "    # URL„Å®‰øùÂ≠ò„Éë„Çπ„ÅÆ„Éö„Ç¢„Çí‰ΩúÊàê\n",
    "    tasks = list(zip(df[\"url\"], df[\"path\"]))\n",
    "\n",
    "    with Pool(os.cpu_count()) as p:\n",
    "        p.map(download_video, tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efa05d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üü© Êó¢„Å´VAE„Çí„ÉÄ„Ç¶„É≥„É≠„Éº„ÉâÊ∏à„Åø\n"
     ]
    }
   ],
   "source": [
    "# ‰∫ãÂâçÂ≠¶ÁøíÊ∏à„ÅøVAE„ÅÆ„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ\n",
    "\n",
    "os.makedirs(\"ckpts\", exist_ok=True)\n",
    "\n",
    "if not os.path.exists(\"ckpts/hunyuan_vae.safetensors\"):\n",
    "    !huggingface-cli download hpcai-tech/Open-Sora-v2 hunyuan_vae.safetensors --local-dir ckpts --local-dir-use-symlinks False\n",
    "else:\n",
    "    logger_.info(f\"Êó¢„Å´VAE„Çí„ÉÄ„Ç¶„É≥„É≠„Éº„ÉâÊ∏à„Åø\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2b27d3",
   "metadata": {},
   "source": [
    "## Ë®ìÁ∑¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d330e6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !torchrun --nproc_per_node=1 scripts/diffusion/train.py configs/diffusion/train/stage1.py --dataset.data-path /workspaces/open-sora/pexels_45k/pexels_45k_necessary.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "754fc1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üü¶ Loading bitsandbytes native library from: /opt/miniconda/envs/py312/lib/python3.12/site-packages/bitsandbytes/libbitsandbytes_cuda124.so\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import math\n",
    "import os\n",
    "import subprocess\n",
    "import warnings\n",
    "from contextlib import nullcontext\n",
    "from copy import deepcopy\n",
    "from pprint import pformat\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "gc.disable()\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.nn.functional as F\n",
    "import wandb\n",
    "from colossalai.booster import Booster\n",
    "from colossalai.utils import set_seed\n",
    "from peft import LoraConfig\n",
    "from tqdm import tqdm\n",
    "\n",
    "from opensora.acceleration.checkpoint import (\n",
    "    GLOBAL_ACTIVATION_MANAGER,\n",
    "    set_grad_checkpoint,\n",
    ")\n",
    "from opensora.acceleration.parallel_states import get_data_parallel_group\n",
    "from opensora.datasets.aspect import bucket_to_shapes\n",
    "from opensora.datasets.dataloader import prepare_dataloader\n",
    "from opensora.datasets.pin_memory_cache import PinMemoryCache\n",
    "from opensora.models.mmdit.distributed import MMDiTPolicy\n",
    "from opensora.registry import DATASETS, MODELS, build_module\n",
    "from opensora.utils.ckpt import (\n",
    "    CheckpointIO,\n",
    "    model_sharding,\n",
    "    record_model_param_shape,\n",
    "    rm_checkpoints,\n",
    ")\n",
    "from opensora.utils.config import (\n",
    "    config_to_name,\n",
    "    create_experiment_workspace,\n",
    "    parse_configs,\n",
    ")\n",
    "from opensora.utils.logger import create_logger\n",
    "from opensora.utils.misc import (\n",
    "    NsysProfiler,\n",
    "    Timers,\n",
    "    all_reduce_mean,\n",
    "    create_tensorboard_writer,\n",
    "    is_log_process,\n",
    "    is_pipeline_enabled,\n",
    "    log_cuda_max_memory,\n",
    "    log_cuda_memory,\n",
    "    log_model_params,\n",
    "    print_mem,\n",
    "    to_torch_dtype,\n",
    ")\n",
    "from opensora.utils.optimizer import create_lr_scheduler, create_optimizer\n",
    "from opensora.utils.sampling import (\n",
    "    get_res_lin_function,\n",
    "    pack,\n",
    "    prepare,\n",
    "    prepare_ids,\n",
    "    time_shift,\n",
    ")\n",
    "from opensora.utils.train import (\n",
    "    create_colossalai_plugin,\n",
    "    dropout_condition,\n",
    "    get_batch_loss,\n",
    "    prepare_visual_condition_causal,\n",
    "    prepare_visual_condition_uncausal,\n",
    "    set_eps,\n",
    "    set_lr,\n",
    "    setup_device,\n",
    "    update_ema,\n",
    "    warmup_ae,\n",
    ")\n",
    "\n",
    "torch.backends.cudnn.benchmark = False  # True leads to slow down in conv3d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635a870b",
   "metadata": {},
   "source": [
    "### 1. Ë®≠ÂÆö„Å®Áí∞Â¢É„ÅÆÂàùÊúüÂåñ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "260212ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Config (path: configs/diffusion/train/stage1.py): {'dataset': {'type': 'video_text', 'transform_name': 'resize_crop', 'fps_max': 24, 'vmaf': True, 'memory_efficient': False, 'data_path': '/workspaces/open-sora/pexels_45k/pexels_45k_necessary.csv'}, 'grad_ckpt_settings': (8, 100), 'bucket_config': {'256px': {1: (1.0, 1), 5: (1.0, 1), 9: (1.0, 1), 13: (1.0, 1), 17: (1.0, 1), 21: (1.0, 1), 25: (1.0, 1), 29: (1.0, 1), 33: (1.0, 1), 37: (1.0, 1), 41: (1.0, 1), 45: (1.0, 1), 49: (1.0, 1), 53: (1.0, 1), 57: (1.0, 1), 61: (1.0, 1), 65: (1.0, 1), 69: (1.0, 1), 73: (1.0, 1), 77: (1.0, 1), 81: (1.0, 1), 85: (1.0, 1), 89: (1.0, 1), 93: (1.0, 1), 97: (1.0, 1), 101: (1.0, 1), 105: (1.0, 1), 109: (0, 1), 113: (0, 1), 117: (0, 1), 121: (0, 1), 125: (0, 1), 129: (0, 1)}, '768px': {1: (0, 13)}, '1024px': {1: (0, 7)}}, 'model': {'type': 'flux', 'from_pretrained': None, 'strict_load': False, 'guidance_embed': False, 'fused_qkv': False, 'use_liger_rope': True, 'grad_ckpt_settings': (8, 100), 'in_channels': 64, 'vec_in_dim': 768, 'context_in_dim': 4096, 'hidden_size': 384, 'mlp_ratio': 4.0, 'num_heads': 3, 'depth': 1, 'depth_single_blocks': 38, 'axes_dim': [16, 56, 56], 'theta': 10000, 'qkv_bias': True}, 'dropout_ratio': {'t5': 0.31622777, 'clip': 0.31622777}, 'ae': {'type': 'hunyuan_vae', 'from_pretrained': './ckpts/hunyuan_vae.safetensors', 'in_channels': 3, 'out_channels': 3, 'layers_per_block': 2, 'latent_channels': 16, 'use_spatial_tiling': True, 'use_temporal_tiling': False}, 'is_causal_vae': True, 't5': {'type': 'text_embedder', 'from_pretrained': 'google/t5-v1_1-xxl', 'cache_dir': '/mnt/ddn/sora/tmp_load/huggingface/hub/', 'max_length': 512, 'shardformer': True}, 'clip': {'type': 'text_embedder', 'from_pretrained': 'openai/clip-vit-large-patch14', 'cache_dir': '/mnt/ddn/sora/tmp_load/huggingface/hub/', 'max_length': 77}, 'lr': 5e-05, 'eps': 1e-15, 'optim': {'cls': 'HybridAdam', 'lr': 5e-05, 'eps': 1e-15, 'weight_decay': 0.0, 'adamw_mode': True}, 'warmup_steps': 0, 'update_warmup_steps': True, 'grad_clip': 1.0, 'accumulation_steps': 1, 'ema_decay': None, 'prefetch_factor': None, 'num_workers': 0, 'num_bucket_build_workers': 64, 'dtype': 'bf16', 'plugin': 'zero2', 'grad_checkpoint': True, 'plugin_config': {'reduce_bucket_size_in_m': 128, 'overlap_allgather': False, 'cpu_offload': True}, 'pin_memory_cache_pre_alloc_numels': [293601280, 293601280, 293601280, 293601280, 293601280, 293601280, 293601280, 293601280, 293601280, 293601280, 293601280, 293601280, 293601280, 293601280, 293601280, 293601280, 293601280, 293601280, 293601280, 293601280, 293601280, 293601280, 293601280, 293601280, 56623104, 56623104, 56623104, 56623104], 'async_io': False, 'seed': 42, 'outputs': 'outputs', 'epochs': 1, 'log_every': 10, 'ckpt_every': 2000, 'keep_n_latest': 20, 'wandb_project': 'mmdit', 'save_master_weights': True, 'load_master_weights': True, 'grad_ckpt_buffer_size': 26843545600, 'config_path': 'configs/diffusion/train/stage1.py'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# == parse configs ==\n",
    "# cfg = parse_configs()\n",
    "\n",
    "\n",
    "from opensora.utils.config import read_config, merge_args\n",
    "import argparse\n",
    "from mmengine.config import Config\n",
    "\n",
    "# !torchrun --nproc_per_node=1 scripts/diffusion/train.py configs/diffusion/train/stage1.py --dataset.data-path /workspaces/open-sora/pexels_45k/pexels_45k_necessary.csv\n",
    "\n",
    "def parse_args(args) -> tuple[str, argparse.Namespace]:\n",
    "    \"\"\"\n",
    "    This function parses the command line arguments.\n",
    "\n",
    "    Returns:\n",
    "        tuple[str, argparse.Namespace]: The path to the configuration file and the command line arguments.\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"config\", type=str, help=\"model config file path\")\n",
    "    args, unknown_args = parser.parse_known_args(args)\n",
    "    return args.config, unknown_args\n",
    "\n",
    "def parse_configs() -> Config:\n",
    "    \"\"\"\n",
    "    This function parses the configuration file and command line arguments.\n",
    "\n",
    "    Returns:\n",
    "        Config: The configuration object.\n",
    "    \"\"\"\n",
    "    config, args = parse_args([\"configs/diffusion/train/stage1.py\", \"--dataset.data-path\", \"/workspaces/open-sora/pexels_45k/pexels_45k_necessary.csv\"])\n",
    "    cfg = read_config(config)\n",
    "    cfg = merge_args(cfg, args)\n",
    "    cfg.config_path = config\n",
    "\n",
    "    # hard-coded for spatial compression\n",
    "    if cfg.get(\"ae_spatial_compression\", None) is not None:\n",
    "        os.environ[\"AE_SPATIAL_COMPRESSION\"] = str(cfg.ae_spatial_compression)\n",
    "    return cfg\n",
    "\n",
    "cfg = parse_configs()\n",
    "cfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b23c575b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import warnings\n",
    "from collections import OrderedDict\n",
    "from datetime import timedelta\n",
    "\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.nn.functional as F\n",
    "from colossalai.booster.plugin import HybridParallelPlugin, LowLevelZeroPlugin\n",
    "from colossalai.cluster import DistCoordinator\n",
    "from colossalai.utils import get_current_device\n",
    "from einops import rearrange\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from tqdm import tqdm\n",
    "\n",
    "from opensora.acceleration.parallel_states import (\n",
    "    set_data_parallel_group,\n",
    "    set_sequence_parallel_group,\n",
    "    set_tensor_parallel_group,\n",
    ")\n",
    "from opensora.utils.optimizer import LinearWarmupLR\n",
    "\n",
    "\n",
    "\n",
    "# == get dtype & device ==\n",
    "dtype = to_torch_dtype(cfg.get(\"dtype\", \"bf16\"))\n",
    "\n",
    "os.environ['RANK'] = '0'\n",
    "os.environ['WORLD_SIZE'] = '1'\n",
    "os.environ['MASTER_ADDR'] = 'localhost'\n",
    "os.environ['MASTER_PORT'] = '12345'\n",
    "\n",
    "device, coordinator = setup_device()\n",
    "\n",
    "grad_ckpt_buffer_size = cfg.get(\"grad_ckpt_buffer_size\", 0)\n",
    "\n",
    "if grad_ckpt_buffer_size > 0:\n",
    "    GLOBAL_ACTIVATION_MANAGER.setup_buffer(grad_ckpt_buffer_size, dtype)\n",
    "\n",
    "checkpoint_io = CheckpointIO()\n",
    "\n",
    "set_seed(cfg.get(\"seed\", 1024))\n",
    "\n",
    "PinMemoryCache.force_dtype = dtype\n",
    "\n",
    "pin_memory_cache_pre_alloc_numels = cfg.get(\"pin_memory_cache_pre_alloc_numels\", None)\n",
    "\n",
    "PinMemoryCache.pre_alloc_numels = pin_memory_cache_pre_alloc_numels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "364b7da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plugin config: {'reduce_bucket_size_in_m': 128, 'overlap_allgather': False, 'cpu_offload': True}\n"
     ]
    }
   ],
   "source": [
    "# ColossalAI„ÅÆÂàùÊúüÂåñÔºàBooster„Å®pluginÔºâ\n",
    "# „Éá„Éº„Çø‰∏¶Âàó„ÄÅ„É¢„Éá„É´‰∏¶Âàó„Å™„Å©„ÅÆÂàÜÊï£Â≠¶Áøí„ÇíÂäπÁéáÂåñ„Åô„Çã\n",
    "\n",
    "plugin_type = cfg.get(\"plugin\", \"zero2\")\n",
    "\n",
    "plugin_config = cfg.get(\"plugin_config\", {})\n",
    "\n",
    "print(\"plugin config:\", plugin_config)\n",
    "\n",
    "plugin_kwargs = {}\n",
    "\n",
    "if plugin_type == \"hybrid\":\n",
    "    plugin_kwargs[\"custom_policy\"] = MMDiTPolicy\n",
    "\n",
    "plugin = create_colossalai_plugin(\n",
    "    plugin=plugin_type,\n",
    "    dtype=cfg.get(\"dtype\", \"bf16\"),\n",
    "    grad_clip=cfg.get(\"grad_clip\", 0),\n",
    "    **plugin_config,\n",
    "    **plugin_kwargs,\n",
    ")\n",
    "\n",
    "booster = Booster(plugin=plugin)\n",
    "\n",
    "seq_align = plugin_config.get(\"sp_size\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6514c365",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üü© ÂÆüÈ®ìÂêç: 251225_183847-diffusion_train_stage1\n",
      "üü© ÂÆüÈ®ì„Éá„Ç£„É¨„ÇØ„Éà„É™: outputs/251225_183847-diffusion_train_stage1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "changing outputs/251225_183847-diffusion_train_stage1 to share\n"
     ]
    }
   ],
   "source": [
    "# ÂÆüÈ®ì„Éá„Ç£„É¨„ÇØÊé™ÁΩÆ„ÇíÂàùÊúüÂåñ\n",
    "\n",
    "exp_name, exp_dir = create_experiment_workspace(\n",
    "    cfg.get(\"outputs\", \"./outputs\"),\n",
    "    model_name=config_to_name(cfg),\n",
    "    config=cfg.to_dict(),\n",
    "    exp_name=cfg.get(\"exp_name\", None),  # useful for automatic restart to specify the exp_name\n",
    ")\n",
    "logger_.info(f\"ÂÆüÈ®ìÂêç: {exp_name}\")\n",
    "logger_.info(f\"ÂÆüÈ®ì„Éá„Ç£„É¨„ÇØ„Éà„É™: {exp_dir}\")\n",
    "\n",
    "if is_log_process(plugin_type, plugin_config):\n",
    "    print(f\"changing {exp_dir} to share\")\n",
    "    os.system(f\"chgrp -R share {exp_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bbf0cd51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üü© Training configuration:\n",
      " {'accumulation_steps': 1,\n",
      " 'ae': {'from_pretrained': './ckpts/hunyuan_vae.safetensors',\n",
      "        'in_channels': 3,\n",
      "        'latent_channels': 16,\n",
      "        'layers_per_block': 2,\n",
      "        'out_channels': 3,\n",
      "        'type': 'hunyuan_vae',\n",
      "        'use_spatial_tiling': True,\n",
      "        'use_temporal_tiling': False},\n",
      " 'async_io': False,\n",
      " 'bucket_config': {'1024px': {1: (0, 7)},\n",
      "                   '256px': {1: (1.0, 1),\n",
      "                             5: (1.0, 1),\n",
      "                             9: (1.0, 1),\n",
      "                             13: (1.0, 1),\n",
      "                             17: (1.0, 1),\n",
      "                             21: (1.0, 1),\n",
      "                             25: (1.0, 1),\n",
      "                             29: (1.0, 1),\n",
      "                             33: (1.0, 1),\n",
      "                             37: (1.0, 1),\n",
      "                             41: (1.0, 1),\n",
      "                             45: (1.0, 1),\n",
      "                             49: (1.0, 1),\n",
      "                             53: (1.0, 1),\n",
      "                             57: (1.0, 1),\n",
      "                             61: (1.0, 1),\n",
      "                             65: (1.0, 1),\n",
      "                             69: (1.0, 1),\n",
      "                             73: (1.0, 1),\n",
      "                             77: (1.0, 1),\n",
      "                             81: (1.0, 1),\n",
      "                             85: (1.0, 1),\n",
      "                             89: (1.0, 1),\n",
      "                             93: (1.0, 1),\n",
      "                             97: (1.0, 1),\n",
      "                             101: (1.0, 1),\n",
      "                             105: (1.0, 1),\n",
      "                             109: (0, 1),\n",
      "                             113: (0, 1),\n",
      "                             117: (0, 1),\n",
      "                             121: (0, 1),\n",
      "                             125: (0, 1),\n",
      "                             129: (0, 1)},\n",
      "                   '768px': {1: (0, 13)}},\n",
      " 'ckpt_every': 2000,\n",
      " 'clip': {'cache_dir': '/mnt/ddn/sora/tmp_load/huggingface/hub/',\n",
      "          'from_pretrained': 'openai/clip-vit-large-patch14',\n",
      "          'max_length': 77,\n",
      "          'type': 'text_embedder'},\n",
      " 'config_path': 'configs/diffusion/train/stage1.py',\n",
      " 'dataset': {'data_path': '/workspaces/open-sora/pexels_45k/pexels_45k_necessary.csv',\n",
      "             'fps_max': 24,\n",
      "             'memory_efficient': False,\n",
      "             'transform_name': 'resize_crop',\n",
      "             'type': 'video_text',\n",
      "             'vmaf': True},\n",
      " 'dropout_ratio': {'clip': 0.31622777, 't5': 0.31622777},\n",
      " 'dtype': 'bf16',\n",
      " 'ema_decay': None,\n",
      " 'epochs': 1,\n",
      " 'eps': 1e-15,\n",
      " 'grad_checkpoint': True,\n",
      " 'grad_ckpt_buffer_size': 26843545600,\n",
      " 'grad_ckpt_settings': (8, 100),\n",
      " 'grad_clip': 1.0,\n",
      " 'is_causal_vae': True,\n",
      " 'keep_n_latest': 20,\n",
      " 'load_master_weights': True,\n",
      " 'log_every': 10,\n",
      " 'lr': 5e-05,\n",
      " 'model': {'axes_dim': [16, 56, 56],\n",
      "           'context_in_dim': 4096,\n",
      "           'depth': 1,\n",
      "           'depth_single_blocks': 38,\n",
      "           'from_pretrained': None,\n",
      "           'fused_qkv': False,\n",
      "           'grad_ckpt_settings': (8, 100),\n",
      "           'guidance_embed': False,\n",
      "           'hidden_size': 384,\n",
      "           'in_channels': 64,\n",
      "           'mlp_ratio': 4.0,\n",
      "           'num_heads': 3,\n",
      "           'qkv_bias': True,\n",
      "           'strict_load': False,\n",
      "           'theta': 10000,\n",
      "           'type': 'flux',\n",
      "           'use_liger_rope': True,\n",
      "           'vec_in_dim': 768},\n",
      " 'num_bucket_build_workers': 64,\n",
      " 'num_workers': 0,\n",
      " 'optim': {'adamw_mode': True,\n",
      "           'cls': 'HybridAdam',\n",
      "           'eps': 1e-15,\n",
      "           'lr': 5e-05,\n",
      "           'weight_decay': 0.0},\n",
      " 'outputs': 'outputs',\n",
      " 'pin_memory_cache_pre_alloc_numels': [293601280,\n",
      "                                       293601280,\n",
      "                                       293601280,\n",
      "                                       293601280,\n",
      "                                       293601280,\n",
      "                                       293601280,\n",
      "                                       293601280,\n",
      "                                       293601280,\n",
      "                                       293601280,\n",
      "                                       293601280,\n",
      "                                       293601280,\n",
      "                                       293601280,\n",
      "                                       293601280,\n",
      "                                       293601280,\n",
      "                                       293601280,\n",
      "                                       293601280,\n",
      "                                       293601280,\n",
      "                                       293601280,\n",
      "                                       293601280,\n",
      "                                       293601280,\n",
      "                                       293601280,\n",
      "                                       293601280,\n",
      "                                       293601280,\n",
      "                                       293601280,\n",
      "                                       56623104,\n",
      "                                       56623104,\n",
      "                                       56623104,\n",
      "                                       56623104],\n",
      " 'plugin': 'zero2',\n",
      " 'plugin_config': {'cpu_offload': True,\n",
      "                   'overlap_allgather': False,\n",
      "                   'reduce_bucket_size_in_m': 128},\n",
      " 'prefetch_factor': None,\n",
      " 'save_master_weights': True,\n",
      " 'seed': 42,\n",
      " 't5': {'cache_dir': '/mnt/ddn/sora/tmp_load/huggingface/hub/',\n",
      "        'from_pretrained': 'google/t5-v1_1-xxl',\n",
      "        'max_length': 512,\n",
      "        'shardformer': True,\n",
      "        'type': 'text_embedder'},\n",
      " 'update_warmup_steps': True,\n",
      " 'wandb_project': 'mmdit',\n",
      " 'warmup_steps': 0}\n",
      "üü© Number of GPUs: 1\n",
      "üü© Number of groups: 1\n"
     ]
    }
   ],
   "source": [
    "# „É≠„Ç¨„Éº„ÇíÂàùÊúüÂåñÔºàÊ®ôÊ∫ñÂá∫Âäõ„ÉªTensorBoard„ÉªWandBÔºâ\n",
    "\n",
    "# logger = create_logger(exp_dir)\n",
    "\n",
    "logger_.info(\"Training configuration:\\n %s\", pformat(cfg.to_dict()))\n",
    "\n",
    "tb_writer = None\n",
    "\n",
    "if coordinator.is_master():\n",
    "    tb_writer = create_tensorboard_writer(exp_dir)\n",
    "    if cfg.get(\"wandb\", False):\n",
    "        logger_.info(f\"WandB„ÇíÂàùÊúüÂåñ\")\n",
    "        wandb.init(\n",
    "            project=cfg.get(\"wandb_project\", \"Open-Sora\"),\n",
    "            name=exp_name,\n",
    "            config=cfg.to_dict(),\n",
    "            dir=exp_dir,\n",
    "        )\n",
    "\n",
    "num_gpus = dist.get_world_size() if dist.is_initialized() else 1\n",
    "logger_.info(\"Number of GPUs: %s\", num_gpus)\n",
    "\n",
    "tp_size = cfg[\"plugin_config\"].get(\"tp_size\", 1)\n",
    "sp_size = cfg[\"plugin_config\"].get(\"sp_size\", 1)\n",
    "pp_size = cfg[\"plugin_config\"].get(\"pp_size\", 1)\n",
    "num_groups = num_gpus // (tp_size * sp_size * pp_size)\n",
    "logger_.info(\"Number of groups: %s\", num_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7f3a1c",
   "metadata": {},
   "source": [
    "### 2. „Éá„Éº„Çø„Çª„ÉÉ„Éà„Å®„Éá„Éº„Çø„É≠„Éº„ÉÄ„Éº„ÅÆÊßãÁØâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db28e0b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/workspaces/open-sora/pexels_45k/pexels_45k_necessary.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# „Éá„Éº„Çø„Çª„ÉÉ„Éà„ÇíÊßãÁØâ\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m dataset = \u001b[43mbuild_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDATASETS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m logger_.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅÆ„Çµ„É≥„Éó„É´Êï∞: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(dataset)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/open-sora/Open-Sora/opensora/registry.py:24\u001b[39m, in \u001b[36mbuild_module\u001b[39m\u001b[34m(module, builder, **kwargs)\u001b[39m\n\u001b[32m     22\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items():\n\u001b[32m     23\u001b[39m         cfg[k] = v\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbuilder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(module, nn.Module):\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m module\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda/envs/py312/lib/python3.12/site-packages/mmengine/registry/registry.py:570\u001b[39m, in \u001b[36mRegistry.build\u001b[39m\u001b[34m(self, cfg, *args, **kwargs)\u001b[39m\n\u001b[32m    548\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbuild\u001b[39m(\u001b[38;5;28mself\u001b[39m, cfg: \u001b[38;5;28mdict\u001b[39m, *args, **kwargs) -> Any:\n\u001b[32m    549\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Build an instance.\u001b[39;00m\n\u001b[32m    550\u001b[39m \n\u001b[32m    551\u001b[39m \u001b[33;03m    Build an instance by calling :attr:`build_func`.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    568\u001b[39m \u001b[33;03m        >>> model = MODELS.build(cfg)\u001b[39;00m\n\u001b[32m    569\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m570\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbuild_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregistry\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda/envs/py312/lib/python3.12/site-packages/mmengine/registry/build_functions.py:121\u001b[39m, in \u001b[36mbuild_from_cfg\u001b[39m\u001b[34m(cfg, registry, default_args)\u001b[39m\n\u001b[32m    119\u001b[39m     obj = obj_cls.get_instance(**args)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    120\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m     obj = \u001b[43mobj_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (inspect.isclass(obj_cls) \u001b[38;5;129;01mor\u001b[39;00m inspect.isfunction(obj_cls)\n\u001b[32m    124\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m inspect.ismethod(obj_cls)):\n\u001b[32m    125\u001b[39m     print_log(\n\u001b[32m    126\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mAn `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj_cls.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` instance is built from \u001b[39m\u001b[33m'\u001b[39m  \u001b[38;5;66;03m# type: ignore # noqa: E501\u001b[39;00m\n\u001b[32m    127\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mregistry, and its implementation can be found in \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    128\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj_cls.\u001b[34m__module__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m,  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    129\u001b[39m         logger=\u001b[33m'\u001b[39m\u001b[33mcurrent\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    130\u001b[39m         level=logging.DEBUG)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/open-sora/Open-Sora/opensora/datasets/datasets.py:178\u001b[39m, in \u001b[36mVideoTextDataset.__init__\u001b[39m\u001b[34m(self, transform_name, bucket_class, rand_sample_interval, **kwargs)\u001b[39m\n\u001b[32m    171\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m    172\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    173\u001b[39m     transform_name: \u001b[38;5;28mstr\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    176\u001b[39m     **kwargs,\n\u001b[32m    177\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    179\u001b[39m     \u001b[38;5;28mself\u001b[39m.transform_name = transform_name\n\u001b[32m    180\u001b[39m     \u001b[38;5;28mself\u001b[39m.bucket_class = bucket_class\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/open-sora/Open-Sora/opensora/datasets/datasets.py:115\u001b[39m, in \u001b[36mTextDataset.__init__\u001b[39m\u001b[34m(self, data_path, tokenize_fn, fps_max, vmaf, memory_efficient, **kwargs)\u001b[39m\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m    106\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    107\u001b[39m     data_path: \u001b[38;5;28mstr\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    112\u001b[39m     **kwargs,\n\u001b[32m    113\u001b[39m ):\n\u001b[32m    114\u001b[39m     \u001b[38;5;28mself\u001b[39m.data_path = data_path\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     \u001b[38;5;28mself\u001b[39m.data = \u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_efficient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmemory_efficient\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    116\u001b[39m     \u001b[38;5;28mself\u001b[39m.memory_efficient = memory_efficient\n\u001b[32m    117\u001b[39m     \u001b[38;5;28mself\u001b[39m.tokenize_fn = tokenize_fn\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/open-sora/Open-Sora/opensora/datasets/utils.py:59\u001b[39m, in \u001b[36mread_file\u001b[39m\u001b[34m(input_path, memory_efficient)\u001b[39m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m input_path.endswith(\u001b[33m\"\u001b[39m\u001b[33m.csv\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     58\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m memory_efficient, \u001b[33m\"\u001b[39m\u001b[33mMemory efficient mode is not supported for CSV files\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m input_path.endswith(\u001b[33m\"\u001b[39m\u001b[33m.parquet\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     61\u001b[39m     columns = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda/envs/py312/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda/envs/py312/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda/envs/py312/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda/envs/py312/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda/envs/py312/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/workspaces/open-sora/pexels_45k/pexels_45k_necessary.csv'"
     ]
    }
   ],
   "source": [
    "# „Éá„Éº„Çø„Çª„ÉÉ„Éà„ÇíÊßãÁØâ\n",
    "dataset = build_module(cfg.dataset, DATASETS)\n",
    "logger_.info(f\"„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅÆ„Çµ„É≥„Éó„É´Êï∞: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3281d91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# „Çµ„É≥„Éó„É´„ÇíË°®Á§∫\n",
    "\n",
    "random_index = random.randint(0, len(dataset) - 1)\n",
    "\n",
    "sample = dataset[f\"{random_index}-1-256-256\"]\n",
    "\n",
    "sample[\"video\"].shape # (3, 1, 256, 256)\n",
    "first_frame = sample[\"video\"][:, 0]  # (3, 256, 256)\n",
    "\n",
    "# display\n",
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(first_frame.permute(1, 2, 0), cmap='gray')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277708d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# „Éá„Éº„Çø„É≠„Éº„ÉÄ„Éº„ÅÆ„Éì„É´„Éâ\n",
    "\n",
    "cache_pin_memory = pin_memory_cache_pre_alloc_numels is not None\n",
    "logger_.info(f\"Cache pin memory: {cache_pin_memory}\")\n",
    "\n",
    "dataloader_args = dict(\n",
    "    dataset=dataset,\n",
    "    batch_size=cfg.get(\"batch_size\", None),\n",
    "    num_workers=cfg.get(\"num_workers\", 4),\n",
    "    seed=cfg.get(\"seed\", 1024),\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    pin_memory=True,\n",
    "    process_group=get_data_parallel_group(),\n",
    "    prefetch_factor=cfg.get(\"prefetch_factor\", None),\n",
    "    cache_pin_memory=cache_pin_memory,\n",
    "    num_groups=num_groups,\n",
    ")\n",
    "logger_.info(f\"Dataloader arguments: {pformat(dataloader_args)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d263382",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader, sampler = prepare_dataloader(\n",
    "    bucket_config=cfg.get(\"bucket_config\", None),\n",
    "    num_bucket_build_workers=cfg.get(\"num_bucket_build_workers\", 1),\n",
    "    **dataloader_args,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cc2733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import DataLoader from torch\n",
    "# from torch.utils.data import DataLoader\n",
    "# from opensora.datasets.dataloader import DataloaderForVideo\n",
    "# dataloader = DataloaderForVideo(dataset, batch_size=1, collate_fn=collate_fn_default)\n",
    "# first_batch = next(iter(dataloader))\n",
    "# len(dataloader)\n",
    "# first_batch[\"video\"].shape  # (1, 3, 16, 256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed9cd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps_per_epoch = len(dataloader)\n",
    "logger_.info(f\"1„Ç®„Éù„ÉÉ„ÇØ„ÅÇ„Åü„Çä„ÅÆ„Çπ„ÉÜ„ÉÉ„ÉóÊï∞: {num_steps_per_epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c36a394",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_efficient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fe50bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_iter = iter(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93da31a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_batch = next(dataloader_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0917e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger_.info(f\"{first_batch.keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fe1b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925a1bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_batch[\"sampling_interval\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9617103d",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_batch[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25d4115",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_batch[\"index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d9f02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_batch[\"path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0893f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_batch[\"video\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d7e709",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_iter = iter(dataloader)\n",
    "sample_batch = next(dataset_iter)\n",
    "sample_batch.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077c00c1",
   "metadata": {},
   "source": [
    "### 3. „É¢„Éá„É´ÊßãÁØâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a91230",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger_.info(\"Building models...\")\n",
    "\n",
    "# == build model model ==\n",
    "model = build_module(cfg.model, MODELS, device_map=device, torch_dtype=dtype).train()\n",
    "\n",
    "if cfg.get(\"grad_checkpoint\", True):\n",
    "    logger_.info(f\"ÂãæÈÖç„ÉÅ„Çß„ÉÉ„ÇØ„Éù„Ç§„É≥„Éà„ÇíÊúâÂäπÂåñ\")\n",
    "    set_grad_checkpoint(model)\n",
    "\n",
    "log_cuda_memory(\"diffusion\")\n",
    "log_model_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23a5e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# == build EMA model ==\n",
    "use_lora = cfg.get(\"lora_config\", None) is not None\n",
    "\n",
    "if cfg.get(\"ema_decay\", None) is not None and not use_lora:\n",
    "    ema = deepcopy(model).cpu().eval().requires_grad_(False)\n",
    "    ema_shape_dict = record_model_param_shape(ema)\n",
    "    logger_.info(\"EMA model created.\")\n",
    "else:\n",
    "    ema = ema_shape_dict = None\n",
    "    logger_.info(\"No EMA model created.\")\n",
    "\n",
    "log_cuda_memory(\"EMA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277eed60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# == enable LoRA ==\n",
    "if use_lora:\n",
    "    lora_config = LoraConfig(**cfg.get(\"lora_config\", None))\n",
    "    model = booster.enable_lora(\n",
    "        model=model,\n",
    "        lora_config=lora_config,\n",
    "        pretrained_dir=cfg.get(\"lora_checkpoint\", None),\n",
    "    )\n",
    "    log_cuda_memory(\"lora\")\n",
    "    log_model_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f6e0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not cfg.get(\"cached_video\", False):\n",
    "    # == buildn autoencoder ==\n",
    "    model_ae = build_module(cfg.ae, MODELS, device_map=device, torch_dtype=dtype).eval().requires_grad_(False)\n",
    "    del model_ae.decoder\n",
    "    logger_.info(\"Autoencoder built.\")\n",
    "    log_model_params(model_ae)\n",
    "    model_ae.encode = torch.compile(model_ae.encoder, dynamic=True)\n",
    "\n",
    "model_ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaacd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not cfg.get(\"cached_text\", False):\n",
    "    # == build text encoder (t5) ==\n",
    "    model_t5 = build_module(cfg.t5, MODELS, device_map=device, torch_dtype=dtype).eval().requires_grad_(False)\n",
    "    log_cuda_memory(\"t5\")\n",
    "    log_model_params(model_t5)\n",
    "\n",
    "    # == build text encoder (clip) ==\n",
    "    model_clip = build_module(cfg.clip, MODELS, device_map=device, torch_dtype=dtype).eval().requires_grad_(False)\n",
    "    log_cuda_memory(\"clip\")\n",
    "    log_model_params(model_clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07350853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# == setup optimizer ==\n",
    "optimizer = create_optimizer(model, cfg.optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b69e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# == setup lr scheduler ==\n",
    "lr_scheduler = create_lr_scheduler(\n",
    "    optimizer=optimizer,\n",
    "    num_steps_per_epoch=num_steps_per_epoch,\n",
    "    epochs=cfg.get(\"epochs\", 1000),\n",
    "    warmup_steps=cfg.get(\"warmup_steps\", None),\n",
    "    use_cosine_scheduler=cfg.get(\"use_cosine_scheduler\", False),\n",
    ")\n",
    "log_cuda_memory(\"optimizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a0dd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# == prepare null vectors for dropout ==\n",
    "if cfg.get(\"cached_text\", False):\n",
    "    null_txt = torch.load(\"/mnt/ddn/sora/tmp_load/null_t5.pt\", map_location=device)\n",
    "    null_vec = torch.load(\"/mnt/ddn/sora/tmp_load/null_clip.pt\", map_location=device)\n",
    "else:\n",
    "    null_txt = model_t5(\"\")\n",
    "    null_vec = model_clip(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe8f3e4",
   "metadata": {},
   "source": [
    "### 4. Colossalai„Çí‰ΩøÁî®„Åó„ÅüÂàÜÊï£Â≠¶Áøí„ÅÆÊ∫ñÂÇô"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b623ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger_.info(\"Preparing for distributed training...\")\n",
    "\n",
    "# == boosting ==\n",
    "torch.set_default_dtype(dtype)\n",
    "\n",
    "model, optimizer, _, dataloader, lr_scheduler = booster.boost(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    lr_scheduler=lr_scheduler,\n",
    "    dataloader=dataloader,\n",
    ")\n",
    "\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "logger_.info(\"Boosted model for distributed training\")\n",
    "\n",
    "log_cuda_memory(\"boost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c9913b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# == global variables ==\n",
    "cfg_epochs = cfg.get(\"epochs\", 1000)\n",
    "\n",
    "log_step = acc_step = 0\n",
    "\n",
    "running_loss = 0.0\n",
    "\n",
    "timers = Timers(record_time=cfg.get(\"record_time\", False), record_barrier=cfg.get(\"record_barrier\", False))\n",
    "\n",
    "nsys = NsysProfiler(\n",
    "    warmup_steps=cfg.get(\"nsys_warmup_steps\", 2),\n",
    "    num_steps=cfg.get(\"nsys_num_steps\", 2),\n",
    "    enabled=cfg.get(\"nsys\", False),\n",
    ")\n",
    "\n",
    "logger_.info(\"Training for %s epochs with %s steps per epoch\", cfg_epochs, num_steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc22b245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# == resume ==\n",
    "\n",
    "load_master_weights = cfg.get(\"load_master_weights\", False)\n",
    "\n",
    "save_master_weights = cfg.get(\"save_master_weights\", False)\n",
    "\n",
    "start_epoch = cfg.get(\"start_epoch\", None)\n",
    "\n",
    "start_step = cfg.get(\"start_step\", None)\n",
    "\n",
    "if cfg.get(\"load\", None) is not None:\n",
    "    logger_.info(\"Loading checkpoint from %s\", cfg.load)\n",
    "\n",
    "    lr_scheduler_to_load = lr_scheduler\n",
    "\n",
    "    if cfg.get(\"update_warmup_steps\", False):\n",
    "        lr_scheduler_to_load = None\n",
    "\n",
    "    ret = checkpoint_io.load(\n",
    "        booster,\n",
    "        cfg.load,\n",
    "        model=model,\n",
    "        ema=ema,\n",
    "        optimizer=optimizer,\n",
    "        lr_scheduler=lr_scheduler_to_load,\n",
    "        sampler=(\n",
    "            None if start_step is not None else sampler\n",
    "        ),  # if specify start step, set last_micro_batch_access_index of a new sampler instead\n",
    "        include_master_weights=load_master_weights,\n",
    "    )\n",
    "\n",
    "    start_epoch = start_epoch if start_epoch is not None else ret[0]\n",
    "\n",
    "    start_step = start_step if start_step is not None else ret[1]\n",
    "\n",
    "    logger_.info(\"Loaded checkpoint %s at epoch %s step %s\", cfg.load, ret[0], ret[1])\n",
    "\n",
    "    # load optimizer and scheduler will overwrite some of the hyperparameters, so we need to reset them\n",
    "    set_lr(optimizer, lr_scheduler, cfg.optim.lr, cfg.get(\"initial_lr\", None))\n",
    "    set_eps(optimizer, cfg.optim.eps)\n",
    "\n",
    "    if cfg.get(\"update_warmup_steps\", False):\n",
    "        assert (\n",
    "            cfg.get(\"warmup_steps\", None) is not None\n",
    "        ), \"you need to set warmup_steps in order to pass --update-warmup-steps True\"\n",
    "        # set_warmup_steps(lr_scheduler, cfg.warmup_steps)\n",
    "        lr_scheduler.step(start_epoch * num_steps_per_epoch + start_step)\n",
    "        logger_.info(\"The learning rate starts from %s\", optimizer.param_groups[0][\"lr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287d3ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if start_step is not None:\n",
    "    # if start step exceeds data length, go to next epoch\n",
    "    if start_step > num_steps_per_epoch:\n",
    "        start_epoch = (\n",
    "            start_epoch + start_step // num_steps_per_epoch\n",
    "            if start_epoch is not None\n",
    "            else start_step // num_steps_per_epoch\n",
    "        )\n",
    "        start_step = start_step % num_steps_per_epoch\n",
    "else:\n",
    "    start_step = 0\n",
    "\n",
    "sampler.set_step(start_step)\n",
    "start_epoch = start_epoch if start_epoch is not None else 0\n",
    "logger_.info(\"Starting from epoch %s step %s\", start_epoch, start_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2056bcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# == sharding EMA model ==\n",
    "if ema is not None:\n",
    "    model_sharding(ema)\n",
    "    ema = ema.to(device)\n",
    "    log_cuda_memory(\"sharding EMA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133dcce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# == warmup autoencoder ==\n",
    "if cfg.get(\"warmup_ae\", False):\n",
    "    shapes = bucket_to_shapes(\n",
    "        cfg.get(\"bucket_config\", None),\n",
    "        batch_size=cfg.ae.batch_size\n",
    "    )\n",
    "\n",
    "    warmup_ae(model_ae, shapes, device, dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a682fd4b",
   "metadata": {},
   "source": [
    "### 5. Ë®ìÁ∑¥„ÅÆ„Ç§„ÉÜ„É¨„Éº„Ç∑„Éß„É≥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5080c3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_min = cfg.get(\"sigma_min\", 1e-5)\n",
    "\n",
    "accumulation_steps = cfg.get(\"accumulation_steps\", 1)\n",
    "\n",
    "ckpt_every = cfg.get(\"ckpt_every\", 0)\n",
    "\n",
    "if cfg.get(\"is_causal_vae\", False):\n",
    "    logger_.info(f\"Preparing visual condition for causal VAE\")\n",
    "    prepare_visual_condition = prepare_visual_condition_causal\n",
    "else:\n",
    "    logger_.info(f\"Preparing visual condition for uncausal VAE\")\n",
    "    prepare_visual_condition = prepare_visual_condition_uncausal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab27e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def prepare_inputs(batch):\n",
    "    logger_.info(f\"Ë®ìÁ∑¥„ÅÆÊ∫ñÂÇô„ÇíÈñãÂßã\")\n",
    "\n",
    "    inp = dict()\n",
    "\n",
    "    x = batch.pop(\"video\")\n",
    "\n",
    "    y = batch.pop(\"text\")\n",
    "\n",
    "    bs = x.shape[0]\n",
    "\n",
    "    # == encode video ==\n",
    "    logger_.info(f\"ÂãïÁîª„ÅÆ„Ç®„É≥„Ç≥„Éº„Éâ„ÇíÈñãÂßã\")\n",
    "    with nsys.range(\"encode_video\"), timers[\"encode_video\"]:\n",
    "        # == prepare condition ==\n",
    "        if cfg.get(\"condition_config\", None) is not None:\n",
    "            # condition for i2v & v2v\n",
    "            x_0, cond = prepare_visual_condition(x, cfg.condition_config, model_ae)\n",
    "            cond = pack(cond, patch_size=cfg.get(\"patch_size\", 2))\n",
    "            inp[\"cond\"] = cond\n",
    "        else:\n",
    "            if cfg.get(\"cached_video\", False):\n",
    "                x_0 = batch.pop(\"video_latents\").to(device=device, dtype=dtype)\n",
    "            else:\n",
    "                x_0 = model_ae.encode(x)\n",
    "\n",
    "    # == prepare timestep ==\n",
    "    logger_.info(f\"„Çø„Ç§„É†„Çπ„ÉÜ„ÉÉ„Éó„ÅÆÊ∫ñÂÇô„ÇíÈñãÂßã\")\n",
    "    # follow SD3 time shift, shift_alpha = 1 for 256px and shift_alpha = 3 for 1024px\n",
    "    shift_alpha = get_res_lin_function()((x_0.shape[-1] * x_0.shape[-2]) // 4)\n",
    "    # add temporal influence\n",
    "    shift_alpha *= math.sqrt(x_0.shape[-3])  # for image, T=1 so no effect\n",
    "    t = torch.sigmoid(torch.randn((bs), device=device))\n",
    "    t = time_shift(shift_alpha, t).to(dtype)\n",
    "\n",
    "    if cfg.get(\"cached_text\", False):\n",
    "        # == encode text ==\n",
    "        logger_.info(f\"„ÉÜ„Ç≠„Çπ„Éà„ÅÆ„Ç®„É≥„Ç≥„Éº„Éâ„ÇíÈñãÂßã(„Ç≠„É£„ÉÉ„Ç∑„É•‰ΩøÁî®)\")\n",
    "        t5_embedding = batch.pop(\"text_t5\").to(device=device, dtype=dtype)\n",
    "        clip_embedding = batch.pop(\"text_clip\").to(device=device, dtype=dtype)\n",
    "        with nsys.range(\"encode_text\"), timers[\"encode_text\"]:\n",
    "            inp_ = prepare_ids(x_0, t5_embedding, clip_embedding)\n",
    "            inp.update(inp_)\n",
    "            x_0 = pack(x_0, patch_size=cfg.get(\"patch_size\", 2))\n",
    "    else:\n",
    "        # == encode text ==\n",
    "        logger_.info(f\"„ÉÜ„Ç≠„Çπ„Éà„ÅÆ„Ç®„É≥„Ç≥„Éº„Éâ„ÇíÈñãÂßã\")\n",
    "        with nsys.range(\"encode_text\"), timers[\"encode_text\"]:\n",
    "            inp_ = prepare(\n",
    "                model_t5,\n",
    "                model_clip,\n",
    "                x_0,\n",
    "                prompt=y,\n",
    "                seq_align=seq_align,\n",
    "                patch_size=cfg.get(\"patch_size\", 2),\n",
    "            )\n",
    "            inp.update(inp_)\n",
    "            x_0 = pack(x_0, patch_size=cfg.get(\"patch_size\", 2))\n",
    "\n",
    "    # == dropout ==\n",
    "    if cfg.get(\"dropout_ratio\", None) is not None:\n",
    "        logger_.info(f\"„Éâ„É≠„ÉÉ„Éó„Ç¢„Ç¶„Éà„ÅÆÈÅ©Áî®„ÇíÈñãÂßã\")\n",
    "        cur_null_txt = null_txt\n",
    "        num_pad_null_txt = inp[\"txt\"].shape[1] - cur_null_txt.shape[1]\n",
    "        if num_pad_null_txt > 0:\n",
    "            cur_null_txt = torch.cat([cur_null_txt] + [cur_null_txt[:, -1:]] * num_pad_null_txt, dim=1)\n",
    "        inp[\"txt\"] = dropout_condition(\n",
    "            cfg.dropout_ratio.get(\"t5\", 0.0),\n",
    "            inp[\"txt\"],\n",
    "            cur_null_txt,\n",
    "        )\n",
    "        inp[\"y_vec\"] = dropout_condition(\n",
    "            cfg.dropout_ratio.get(\"clip\", 0.0),\n",
    "            inp[\"y_vec\"],\n",
    "            null_vec,\n",
    "        )\n",
    "\n",
    "    # == prepare noise vector ==\n",
    "    x_1 = torch.randn_like(x_0, dtype=torch.float32).to(device, dtype)\n",
    "    t_rev = 1 - t\n",
    "    x_t = t_rev[:, None, None] * x_0 + (1 - (1 - sigma_min) * t_rev[:, None, None]) * x_1\n",
    "    inp[\"img\"] = x_t\n",
    "    inp[\"timesteps\"] = t.to(dtype)\n",
    "    inp[\"guidance\"] = torch.full((x_t.shape[0],), cfg.get(\"guidance\", 4), device=x_t.device, dtype=x_t.dtype)\n",
    "\n",
    "    return inp, x_0, x_1\n",
    "\n",
    "sample_batch = next(dataset_iter)\n",
    "sample_batch.keys()\n",
    "pinned_video = sample_batch[\"video\"]\n",
    "sample_batch[\"video\"] = pinned_video.to(device, dtype, non_blocking=True)\n",
    "inp, x_0, x_1 = prepare_inputs(sample_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2303e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger_.debug(f\"inp: {inp.keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ffa2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger_.debug(f\"x_0.shape: {x_0.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904850cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger_.debug(f\"x_1.shape: {x_1.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ad9c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_iter(inp, x_0, x_1):\n",
    "    logger_.info(f\"1„Å§„ÅÆ„Ç§„ÉÜ„É¨„Éº„Ç∑„Éß„É≥„ÇíÂÆüË°å‰∏≠ {inp.keys()=} {x_0.shape=} {x_1.shape=}\")\n",
    "\n",
    "    if is_pipeline_enabled(plugin_type, plugin_config):\n",
    "        logger_.info(f\"„Éë„Ç§„Éó„É©„Ç§„É≥‰∏¶Âàó„Çí‰ΩøÁî®„Åó„Å¶„ÅÑ„Çã„Åü„ÇÅ„ÄÅforward-backward„Çí‰∏Ä‰ΩìÂåñ„Åó„Å¶ÂÆüË°å\")\n",
    "\n",
    "        inp[\"target\"] = (1 - sigma_min) * x_1 - x_0  # follow MovieGen, modify V_t accordingly\n",
    "        with nsys.range(\"forward-backward\"), timers[\"forward-backward\"]:\n",
    "            data_iter = iter([inp])\n",
    "            if cfg.get(\"no_i2v_ref_loss\", False):\n",
    "                loss_fn = (\n",
    "                    lambda out, input_: get_batch_loss(out, input_[\"target\"], input_.pop(\"masks\", None))\n",
    "                    / accumulation_steps\n",
    "                )\n",
    "            else:\n",
    "                loss_fn = (\n",
    "                    lambda out, input_: F.mse_loss(out.float(), input_[\"target\"].float(), reduction=\"mean\")\n",
    "                    / accumulation_steps\n",
    "                )\n",
    "            loss = booster.execute_pipeline(data_iter, model, loss_fn, optimizer)[\"loss\"]\n",
    "            loss = loss * accumulation_steps if loss is not None else loss\n",
    "            loss_item = all_reduce_mean(loss.data.clone().detach())\n",
    "    else:\n",
    "        logger_.info(f\"ÈÄöÂ∏∏„ÅÆÂàÜÊï£Â≠¶Áøí„É´„Éº„Éó„Åßforward„Å®backward„ÇíÂÆüË°å\")\n",
    "\n",
    "        # == forward ==\n",
    "        logger_.info(f\"„Éï„Ç©„ÉØ„Éº„Éâ„ÇíÂÆüË°å\")\n",
    "\n",
    "        with nsys.range(\"forward\"), timers[\"forward\"]:\n",
    "            model_pred = model(**inp)  # B, T, L\n",
    "            v_t = (1 - sigma_min) * x_1 - x_0\n",
    "            if cfg.get(\"no_i2v_ref_loss\", False):\n",
    "                loss = get_batch_loss(model_pred, v_t, inp.pop(\"masks\", None))\n",
    "            else:\n",
    "                loss = F.mse_loss(model_pred.float(), v_t.float(), reduction=\"mean\")\n",
    "\n",
    "        loss_item = all_reduce_mean(loss.data.clone().detach()).item()\n",
    "\n",
    "        # == backward & update ==\n",
    "        dist.barrier()\n",
    "        logger_.info(f\"„Éê„ÉÉ„ÇØ„ÉØ„Éº„Éâ„ÇíÂÆüË°å\")\n",
    "\n",
    "        with nsys.range(\"backward\"), timers[\"backward\"]:\n",
    "            ctx = (\n",
    "                booster.no_sync(model, optimizer)\n",
    "                if cfg.get(\"plugin\", \"zero2\") in (\"zero1\", \"zero1-seq\") and (step + 1) % accumulation_steps != 0\n",
    "                else nullcontext()\n",
    "            )\n",
    "            with ctx:\n",
    "                booster.backward(loss=(loss / accumulation_steps), optimizer=optimizer)\n",
    "\n",
    "    # == optim step ==\n",
    "    logger_.info(f\"„Ç™„Éó„ÉÜ„Ç£„Éû„Ç§„Ç∂„Éº„Çπ„ÉÜ„ÉÉ„Éó„ÇíÂÆüË°å\")\n",
    "\n",
    "    with nsys.range(\"optim\"), timers[\"optim\"]:\n",
    "        if (step + 1) % accumulation_steps == 0:\n",
    "            booster.checkpoint_io.synchronize()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        if lr_scheduler is not None:\n",
    "            lr_scheduler.step()\n",
    "\n",
    "    # == update EMA ==\n",
    "    if ema is not None:\n",
    "        logger_.info(f\"EMA„É¢„Éá„É´„ÅÆÊõ¥Êñ∞„ÇíÂÆüË°å\")\n",
    "        with nsys.range(\"update_ema\"), timers[\"update_ema\"]:\n",
    "            update_ema(\n",
    "                ema,\n",
    "                model.unwrap(),\n",
    "                optimizer=optimizer,\n",
    "                decay=cfg.get(\"ema_decay\", 0.9999),\n",
    "            )\n",
    "\n",
    "    return loss_item\n",
    "\n",
    "# step = 0\n",
    "# sample_loss = run_iter(inp, x_0, x_1)\n",
    "# logger_.info(f\"„Çµ„É≥„Éó„É´„Éê„ÉÉ„ÉÅ„ÅÆÊêçÂ§±: {sample_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b7b1b1",
   "metadata": {},
   "source": [
    "### 6. Ë®ìÁ∑¥„É´„Éº„Éó"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb06d6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    logger_.info(\"Ë®ìÁ∑¥ÈñãÂßã...\")\n",
    "\n",
    "    dist.barrier()\n",
    "    for epoch in range(start_epoch, cfg_epochs):\n",
    "        # == set dataloader to new epoch ==\n",
    "        sampler.set_epoch(epoch)\n",
    "        logger_.info(f\"„Çµ„É≥„Éó„É©„Éº„Çí„Ç®„Éù„ÉÉ„ÇØ {epoch} „Å´Ë®≠ÂÆö„Åó„Åæ„Åó„Åü\")\n",
    "\n",
    "        dataloader_iter = iter(dataloader)\n",
    "\n",
    "        logger_.info(\"„Ç®„Éù„ÉÉ„ÇØ %s „ÇíÈñãÂßã„Åó„Åæ„Åô...\", epoch)\n",
    "        # == training loop in an epoch ==\n",
    "        with tqdm(\n",
    "            enumerate(dataloader_iter, start=start_step),\n",
    "            desc=f\"Epoch {epoch}\",\n",
    "            disable=not is_log_process(plugin_type, plugin_config),\n",
    "            initial=start_step,\n",
    "            total=num_steps_per_epoch,\n",
    "        ) as pbar:\n",
    "            pbar_iter = iter(pbar)\n",
    "\n",
    "            # prefetch one for non-blocking data loading\n",
    "            def fetch_data():\n",
    "                step, batch = next(pbar_iter)\n",
    "                # print(f\"==debug== rank{dist.get_rank()} {dataloader_iter.get_cache_info()}\")\n",
    "                pinned_video = batch[\"video\"]\n",
    "                batch[\"video\"] = pinned_video.to(device, dtype, non_blocking=True)\n",
    "                return batch, step, pinned_video\n",
    "\n",
    "            batch_, step_, pinned_video_ = fetch_data()\n",
    "            logger_.info(f\"„Éá„Éº„Çø„Çí„Éó„É™„Éï„Çß„ÉÉ„ÉÅ„Åó„Åæ„Åó„Åü {step_}\")\n",
    "\n",
    "            for current_step in range(start_step, num_steps_per_epoch):\n",
    "                logger_.info(f\"ÈñãÂßã epoch {epoch} step {current_step}\")\n",
    "\n",
    "                nsys.step()\n",
    "\n",
    "                # == load data ===\n",
    "                logger_.debug(f\"„Éá„Éº„Çø„Çí„É≠„Éº„ÉâÈñãÂßã\")\n",
    "\n",
    "                with nsys.range(\"load_data\"), timers[\"load_data\"]:\n",
    "                    batch, step, pinned_video = batch_, step_, pinned_video_\n",
    "\n",
    "                    if step + 1 < num_steps_per_epoch:\n",
    "                        # only fetch new data if not last step\n",
    "                        batch_, step_, pinned_video_ = fetch_data()\n",
    "\n",
    "                # == run iter ==\n",
    "                logger_.debug(f\"„Ç§„ÉÜ„É¨„Éº„Ç∑„Éß„É≥„ÇíÂÆüË°åÈñãÂßã\")\n",
    "\n",
    "                with nsys.range(\"iter\"), timers[\"iter\"]:\n",
    "\n",
    "                    inp, x_0, x_1 = prepare_inputs(batch)\n",
    "\n",
    "                    # if cache_pin_memory:\n",
    "                    #     dataloader_iter.remove_cache(pinned_video)\n",
    "                    \n",
    "                    loss = run_iter(inp, x_0, x_1)\n",
    "\n",
    "                # == update log info ==\n",
    "                if loss is not None:\n",
    "                    logger_.debug(f\"ÊêçÂ§±„ÇíÊõ¥Êñ∞‰∏≠ {loss=}\")\n",
    "                    running_loss += loss\n",
    "\n",
    "                # == log config ==\n",
    "                logger_.debug(f\"„É≠„Ç∞ÊÉÖÂ†±„ÇíÊõ¥Êñ∞‰∏≠\")\n",
    "                global_step = epoch * num_steps_per_epoch + step\n",
    "                actual_update_step = (global_step + 1) // accumulation_steps\n",
    "                log_step += 1\n",
    "                acc_step += 1\n",
    "\n",
    "                # == logging ==\n",
    "                if (global_step + 1) % accumulation_steps == 0:\n",
    "                    if actual_update_step % cfg.get(\"log_every\", 1) == 0:\n",
    "                        if is_log_process(plugin_type, plugin_config):\n",
    "                            logger_.info(f\"„É≠„Ç∞„ÇíË®òÈå≤‰∏≠ at epoch {epoch} step {step} global_step {global_step} actual_update_step {actual_update_step}\")\n",
    "\n",
    "                            avg_loss = running_loss / log_step\n",
    "                            # progress bar\n",
    "                            pbar.set_postfix(\n",
    "                                {\n",
    "                                    \"loss\": avg_loss,\n",
    "                                    \"global_grad_norm\": optimizer.get_grad_norm(),\n",
    "                                    \"step\": step,\n",
    "                                    \"global_step\": global_step,\n",
    "                                    # \"actual_update_step\": actual_update_step,\n",
    "                                    \"lr\": optimizer.param_groups[0][\"lr\"],\n",
    "                                }\n",
    "                            )\n",
    "                            # tensorboard\n",
    "                            if tb_writer is not None:\n",
    "                                tb_writer.add_scalar(\"loss\", loss, actual_update_step)\n",
    "                            # wandb\n",
    "                            if cfg.get(\"wandb\", False):\n",
    "                                wandb_dict = {\n",
    "                                    \"iter\": global_step,\n",
    "                                    \"acc_step\": acc_step,\n",
    "                                    \"epoch\": epoch,\n",
    "                                    \"loss\": loss,\n",
    "                                    \"avg_loss\": avg_loss,\n",
    "                                    \"lr\": optimizer.param_groups[0][\"lr\"],\n",
    "                                    \"eps\": optimizer.param_groups[0][\"eps\"],\n",
    "                                    \"global_grad_norm\": optimizer.get_grad_norm(),  # test grad norm\n",
    "                                }\n",
    "                                if cfg.get(\"record_time\", False):\n",
    "                                    wandb_dict.update(timers.to_dict())\n",
    "                                wandb.log(wandb_dict, step=actual_update_step)\n",
    "\n",
    "                        running_loss = 0.0\n",
    "                        log_step = 0\n",
    "\n",
    "                # == checkpoint saving ==\n",
    "                logger_.debug(f\"„ÉÅ„Çß„ÉÉ„ÇØ„Éù„Ç§„É≥„Éà„ÅÆ‰øùÂ≠ò„ÇíÁ¢∫Ë™ç‰∏≠\")\n",
    "                # uncomment below 3 lines to forcely clean cache\n",
    "                with nsys.range(\"clean_cache\"), timers[\"clean_cache\"]:\n",
    "                    if ckpt_every > 0 and actual_update_step % ckpt_every == 0 and coordinator.is_master():\n",
    "                        subprocess.run(\"sudo drop_cache\", shell=True)\n",
    "\n",
    "                logger_.debug(f\"„ÉÅ„Çß„ÉÉ„ÇØ„Éù„Ç§„É≥„Éà„ÅÆ‰øùÂ≠ò„ÇíÂÆüË°å‰∏≠\")\n",
    "                with nsys.range(\"checkpoint\"), timers[\"checkpoint\"]:\n",
    "                    if ckpt_every > 0 and actual_update_step % ckpt_every == 0:\n",
    "                        # mannual garbage collection\n",
    "                        gc.collect()\n",
    "\n",
    "                        save_dir = checkpoint_io.save(\n",
    "                            booster,\n",
    "                            exp_dir,\n",
    "                            model=model,\n",
    "                            ema=ema,\n",
    "                            optimizer=optimizer,\n",
    "                            lr_scheduler=lr_scheduler,\n",
    "                            sampler=sampler,\n",
    "                            epoch=epoch,\n",
    "                            step=step + 1,\n",
    "                            global_step=global_step + 1,\n",
    "                            batch_size=cfg.get(\"batch_size\", None),\n",
    "                            lora=use_lora,\n",
    "                            actual_update_step=actual_update_step,\n",
    "                            ema_shape_dict=ema_shape_dict,\n",
    "                            async_io=cfg.get(\"async_io\", False),\n",
    "                            include_master_weights=save_master_weights,\n",
    "                        )\n",
    "\n",
    "                        if is_log_process(plugin_type, plugin_config):\n",
    "                            os.system(f\"chgrp -R share {save_dir}\")\n",
    "\n",
    "                        logger_.info(\n",
    "                            \"Saved checkpoint at epoch %s, step %s, global_step %s to %s\",\n",
    "                            epoch,\n",
    "                            step + 1,\n",
    "                            actual_update_step,\n",
    "                            save_dir,\n",
    "                        )\n",
    "\n",
    "                        # remove old checkpoints\n",
    "                        rm_checkpoints(exp_dir, keep_n_latest=cfg.get(\"keep_n_latest\", -1))\n",
    "                        logger_.info(\"Removed old checkpoints and kept %s latest ones.\", cfg.get(\"keep_n_latest\", -1))\n",
    "                # uncomment below 3 lines to benchmark checkpoint\n",
    "                # if ckpt_every > 0 and actual_update_step % ckpt_every == 0:\n",
    "                #     booster.checkpoint_io._sync_io()\n",
    "                #     checkpoint_io._sync_io()\n",
    "                # == terminal timer ==\n",
    "                if cfg.get(\"record_time\", False):\n",
    "                    print(timers.to_str(epoch, step))\n",
    "\n",
    "        sampler.reset()\n",
    "        start_step = 0\n",
    "    log_cuda_max_memory(\"final\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
