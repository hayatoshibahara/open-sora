{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e54053b",
   "metadata": {},
   "source": [
    "## æ¦‚è¦"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf13bf8",
   "metadata": {},
   "source": [
    "- image.py: ç”»åƒã®ã¿ã§å­¦ç¿’ã€‚\n",
    "- stage1.py: 256pxè§£åƒåº¦ã®å‹•ç”»ã§å­¦ç¿’ã€‚\n",
    "- stage2.py: 768pxè§£åƒåº¦ã®å‹•ç”»ã§å­¦ç¿’ï¼ˆã‚·ãƒ¼ã‚±ãƒ³ã‚¹ä¸¦åˆ—åŒ–ã‚’ä½¿ç”¨ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯4ï¼‰ã€‚\n",
    "- stage1_i2v.py: 256pxè§£åƒåº¦ã§T2Vï¼ˆãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰å‹•ç”»ï¼‰ã¨I2Vï¼ˆç”»åƒã‹ã‚‰å‹•ç”»ï¼‰ã‚’å­¦ç¿’ã€‚\n",
    "- stage2_i2v.py: 768pxè§£åƒåº¦ã§T2Vã¨I2Vã‚’å­¦ç¿’ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e895226e",
   "metadata": {},
   "source": [
    "## ç’°å¢ƒæ§‹ç¯‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9f1318",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34edd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /workspaces/open-sora/Open-Sora\n",
    "%pip install -e . --no-deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52ec244",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import platform\n",
    "import subprocess\n",
    "\n",
    "if os.path.exists(\"debug.log\"):\n",
    "    os.remove(\"debug.log\")\n",
    "\n",
    "def custom_format(record):\n",
    "    match record.levelno:\n",
    "        case logging.DEBUG:\n",
    "            level = \"ğŸŸ¦\"\n",
    "        case logging.INFO:\n",
    "            level = \"ğŸŸ©\"\n",
    "        case logging.WARNING:\n",
    "            level = \"ğŸŸ¨\"\n",
    "        case logging.ERROR:\n",
    "            level = \"ğŸŸ¥\"\n",
    "        case logging.CRITICAL:\n",
    "            level = \"ğŸ›‘\"\n",
    "    return f\"{level} {record.getMessage()}\"\n",
    "\n",
    "logger_ = logging.getLogger()\n",
    "\n",
    "for handler in logger_.handlers:\n",
    "    logger_.removeHandler(handler)\n",
    "\n",
    "formatter = logging.Formatter()\n",
    "formatter.format = custom_format\n",
    "\n",
    "file_handler = logging.FileHandler(\"debug.log\")\n",
    "file_handler.setFormatter(formatter)\n",
    "logger_.addHandler(file_handler)\n",
    "\n",
    "stream_handler = logging.StreamHandler()\n",
    "stream_handler.setFormatter(formatter)\n",
    "logger_.addHandler(stream_handler)\n",
    "logger_.setLevel(logging.DEBUG)\n",
    "\n",
    "PYTHON_VERSION = platform.python_version()\n",
    "logger_.info(f\"Python {PYTHON_VERSION}\")\n",
    "\n",
    "NVIDIA_SMI = subprocess.run(\"nvidia-smi\", capture_output=True, text=True).stdout\n",
    "logger_.info(f\"{NVIDIA_SMI}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1cb4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install torch==2.6.0 torchvision==0.21.0 torchaudio==2.6.0 --index-url https://download.pytorch.org/whl/cu124\n",
    "%pip install torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/cu124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57815940",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install \\\n",
    "    accelerate \\\n",
    "    av \\\n",
    "    colossalai \\\n",
    "    ftfy \\\n",
    "    liger-kernel \\\n",
    "    omegaconf \\\n",
    "    mmengine \\\n",
    "    openai \\\n",
    "    pandas \\\n",
    "    pandarallel \\\n",
    "    pyarrow \\\n",
    "    tensorboard \\\n",
    "    wandb \\\n",
    "    --extra-index-url https://download.pytorch.org/whl/cu124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4303893",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install flash-attn --no-build-isolation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489f2609",
   "metadata": {},
   "source": [
    "### ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3af23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 269.53GBã®å‹•ç”»ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
    "# https://modelscope.cn/datasets/hpcai-tech/open-sora-pexels-45k\n",
    "\n",
    "if False:\n",
    "    !apt update && apt install git-lfs\n",
    "    !git-lfs install\n",
    "    !git clone \"https://www.modelscope.cn/datasets/hpcai-tech/open-sora-pexels-45k.git\"\n",
    "    !cd open-sora-pexels-45k && \\\n",
    "        cat tar/pexels_45k.tar.* > pexels_45k.tar && \\\n",
    "        mkdir ../datasets && \\\n",
    "        mv pexels_45k ../datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257aa955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ•°ä»¶ã®å‹•ç”»ã‚’ç›´æ¥ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
    "\n",
    "if False:\n",
    "    from multiprocessing import Pool\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    import re\n",
    "    import subprocess\n",
    "\n",
    "    os.makedirs(\"pexel_10\", exist_ok=True)\n",
    "    necessary_csv_path = \"/workspaces/open-sora/pexels_10/pexels_10_necessary.csv\"\n",
    "    df = pd.read_csv(necessary_csv_path)\n",
    "\n",
    "    video_urls = []\n",
    "\n",
    "    for path in df[\"path\"]:\n",
    "        match = re.search(r\"/(\\d+)_\", path)\n",
    "        video_id = match.group(1)\n",
    "        video_url = f\"https://www.pexels.com/download/video/{video_id}\"\n",
    "        df.loc[df[\"path\"] == path, \"url\"] = video_url\n",
    "\n",
    "    def download_video(args):\n",
    "        url, save_path = args\n",
    "\n",
    "        # ä¿å­˜å…ˆã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆï¼ˆå­˜åœ¨ã—ãªã„å ´åˆï¼‰\n",
    "        directory = os.path.dirname(save_path)\n",
    "        if directory:\n",
    "            os.makedirs(directory, exist_ok=True)\n",
    "        \n",
    "        # ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ—¢ã«å­˜åœ¨ã—ãªã„å ´åˆã®ã¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œ\n",
    "        if not os.path.exists(save_path):\n",
    "            try:\n",
    "                # -O: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã‚’æŒ‡å®š\n",
    "                # -q: ãƒ­ã‚°å‡ºåŠ›ã‚’æŠ‘åˆ¶ï¼ˆé€²æ—ãŒè¦‹ãŸã„å ´åˆã¯å¤–ã—ã¦ãã ã•ã„ï¼‰\n",
    "                command = [\"wget\", \"-q\", \"-O\", save_path, url]\n",
    "                subprocess.run(command, check=True)\n",
    "            except subprocess.CalledProcessError:\n",
    "                print(f\"Failed to download: {url}\")\n",
    "\n",
    "    # URLã¨ä¿å­˜ãƒ‘ã‚¹ã®ãƒšã‚¢ã‚’ä½œæˆ\n",
    "    tasks = list(zip(df[\"url\"], df[\"path\"]))\n",
    "\n",
    "    with Pool(os.cpu_count()) as p:\n",
    "        p.map(download_video, tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa05d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# äº‹å‰å­¦ç¿’æ¸ˆã¿VAEã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
    "\n",
    "os.makedirs(\"ckpts\", exist_ok=True)\n",
    "\n",
    "if not os.path.exists(\"ckpts/hunyuan_vae.safetensors\"):\n",
    "    !huggingface-cli download hpcai-tech/Open-Sora-v2 hunyuan_vae.safetensors --local-dir ckpts --local-dir-use-symlinks False\n",
    "else:\n",
    "    logger_.info(f\"æ—¢ã«VAEã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2b27d3",
   "metadata": {},
   "source": [
    "## è¨“ç·´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d330e6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !torchrun --nproc_per_node=1 scripts/diffusion/train.py configs/diffusion/train/stage1.py --dataset.data-path /workspaces/open-sora/pexels_45k/pexels_45k_necessary.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754fc1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import math\n",
    "import os\n",
    "import subprocess\n",
    "import warnings\n",
    "from contextlib import nullcontext\n",
    "from copy import deepcopy\n",
    "from pprint import pformat\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "gc.disable()\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.nn.functional as F\n",
    "import wandb\n",
    "from colossalai.booster import Booster\n",
    "from colossalai.utils import set_seed\n",
    "from peft import LoraConfig\n",
    "from tqdm import tqdm\n",
    "\n",
    "from opensora.acceleration.checkpoint import (\n",
    "    GLOBAL_ACTIVATION_MANAGER,\n",
    "    set_grad_checkpoint,\n",
    ")\n",
    "from opensora.acceleration.parallel_states import get_data_parallel_group\n",
    "from opensora.datasets.aspect import bucket_to_shapes\n",
    "from opensora.datasets.dataloader import prepare_dataloader\n",
    "from opensora.datasets.pin_memory_cache import PinMemoryCache\n",
    "from opensora.models.mmdit.distributed import MMDiTPolicy\n",
    "from opensora.registry import DATASETS, MODELS, build_module\n",
    "from opensora.utils.ckpt import (\n",
    "    CheckpointIO,\n",
    "    model_sharding,\n",
    "    record_model_param_shape,\n",
    "    rm_checkpoints,\n",
    ")\n",
    "from opensora.utils.config import (\n",
    "    config_to_name,\n",
    "    create_experiment_workspace,\n",
    "    parse_configs,\n",
    ")\n",
    "from opensora.utils.logger import create_logger\n",
    "from opensora.utils.misc import (\n",
    "    NsysProfiler,\n",
    "    Timers,\n",
    "    all_reduce_mean,\n",
    "    create_tensorboard_writer,\n",
    "    is_log_process,\n",
    "    is_pipeline_enabled,\n",
    "    log_cuda_max_memory,\n",
    "    log_cuda_memory,\n",
    "    log_model_params,\n",
    "    print_mem,\n",
    "    to_torch_dtype,\n",
    ")\n",
    "from opensora.utils.optimizer import create_lr_scheduler, create_optimizer\n",
    "from opensora.utils.sampling import (\n",
    "    get_res_lin_function,\n",
    "    pack,\n",
    "    prepare,\n",
    "    prepare_ids,\n",
    "    time_shift,\n",
    ")\n",
    "from opensora.utils.train import (\n",
    "    create_colossalai_plugin,\n",
    "    dropout_condition,\n",
    "    get_batch_loss,\n",
    "    prepare_visual_condition_causal,\n",
    "    prepare_visual_condition_uncausal,\n",
    "    set_eps,\n",
    "    set_lr,\n",
    "    setup_device,\n",
    "    update_ema,\n",
    "    warmup_ae,\n",
    ")\n",
    "\n",
    "torch.backends.cudnn.benchmark = False  # True leads to slow down in conv3d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635a870b",
   "metadata": {},
   "source": [
    "### 1. è¨­å®šã¨ç’°å¢ƒã®åˆæœŸåŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260212ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# == parse configs ==\n",
    "# cfg = parse_configs()\n",
    "\n",
    "\n",
    "from opensora.utils.config import read_config, merge_args\n",
    "import argparse\n",
    "from mmengine.config import Config\n",
    "\n",
    "# !torchrun --nproc_per_node=1 scripts/diffusion/train.py configs/diffusion/train/stage1.py --dataset.data-path /workspaces/open-sora/pexels_45k/pexels_45k_necessary.csv\n",
    "\n",
    "def parse_args(args) -> tuple[str, argparse.Namespace]:\n",
    "    \"\"\"\n",
    "    This function parses the command line arguments.\n",
    "\n",
    "    Returns:\n",
    "        tuple[str, argparse.Namespace]: The path to the configuration file and the command line arguments.\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"config\", type=str, help=\"model config file path\")\n",
    "    args, unknown_args = parser.parse_known_args(args)\n",
    "    return args.config, unknown_args\n",
    "\n",
    "def parse_configs() -> Config:\n",
    "    \"\"\"\n",
    "    This function parses the configuration file and command line arguments.\n",
    "\n",
    "    Returns:\n",
    "        Config: The configuration object.\n",
    "    \"\"\"\n",
    "    config, args = parse_args([\"configs/diffusion/train/stage1.py\", \"--dataset.data-path\", \"/workspaces/open-sora/pexels_45k/pexels_45k_necessary.csv\"])\n",
    "    cfg = read_config(config)\n",
    "    cfg = merge_args(cfg, args)\n",
    "    cfg.config_path = config\n",
    "\n",
    "    # hard-coded for spatial compression\n",
    "    if cfg.get(\"ae_spatial_compression\", None) is not None:\n",
    "        os.environ[\"AE_SPATIAL_COMPRESSION\"] = str(cfg.ae_spatial_compression)\n",
    "    return cfg\n",
    "\n",
    "cfg = parse_configs()\n",
    "cfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23c575b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import warnings\n",
    "from collections import OrderedDict\n",
    "from datetime import timedelta\n",
    "\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.nn.functional as F\n",
    "from colossalai.booster.plugin import HybridParallelPlugin, LowLevelZeroPlugin\n",
    "from colossalai.cluster import DistCoordinator\n",
    "from colossalai.utils import get_current_device\n",
    "from einops import rearrange\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from tqdm import tqdm\n",
    "\n",
    "from opensora.acceleration.parallel_states import (\n",
    "    set_data_parallel_group,\n",
    "    set_sequence_parallel_group,\n",
    "    set_tensor_parallel_group,\n",
    ")\n",
    "from opensora.utils.optimizer import LinearWarmupLR\n",
    "\n",
    "\n",
    "\n",
    "# == get dtype & device ==\n",
    "dtype = to_torch_dtype(cfg.get(\"dtype\", \"bf16\"))\n",
    "\n",
    "os.environ['RANK'] = '0'\n",
    "os.environ['WORLD_SIZE'] = '1'\n",
    "os.environ['MASTER_ADDR'] = 'localhost'\n",
    "os.environ['MASTER_PORT'] = '12345'\n",
    "\n",
    "device, coordinator = setup_device()\n",
    "\n",
    "grad_ckpt_buffer_size = cfg.get(\"grad_ckpt_buffer_size\", 0)\n",
    "\n",
    "if grad_ckpt_buffer_size > 0:\n",
    "    GLOBAL_ACTIVATION_MANAGER.setup_buffer(grad_ckpt_buffer_size, dtype)\n",
    "\n",
    "checkpoint_io = CheckpointIO()\n",
    "\n",
    "set_seed(cfg.get(\"seed\", 1024))\n",
    "\n",
    "PinMemoryCache.force_dtype = dtype\n",
    "\n",
    "pin_memory_cache_pre_alloc_numels = cfg.get(\"pin_memory_cache_pre_alloc_numels\", None)\n",
    "\n",
    "PinMemoryCache.pre_alloc_numels = pin_memory_cache_pre_alloc_numels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364b7da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ColossalAIã®åˆæœŸåŒ–ï¼ˆBoosterã¨pluginï¼‰\n",
    "# ãƒ‡ãƒ¼ã‚¿ä¸¦åˆ—ã€ãƒ¢ãƒ‡ãƒ«ä¸¦åˆ—ãªã©ã®åˆ†æ•£å­¦ç¿’ã‚’åŠ¹ç‡åŒ–ã™ã‚‹\n",
    "\n",
    "plugin_type = cfg.get(\"plugin\", \"zero2\")\n",
    "\n",
    "plugin_config = cfg.get(\"plugin_config\", {})\n",
    "\n",
    "print(\"plugin config:\", plugin_config)\n",
    "\n",
    "plugin_kwargs = {}\n",
    "\n",
    "if plugin_type == \"hybrid\":\n",
    "    plugin_kwargs[\"custom_policy\"] = MMDiTPolicy\n",
    "\n",
    "plugin = create_colossalai_plugin(\n",
    "    plugin=plugin_type,\n",
    "    dtype=cfg.get(\"dtype\", \"bf16\"),\n",
    "    grad_clip=cfg.get(\"grad_clip\", 0),\n",
    "    **plugin_config,\n",
    "    **plugin_kwargs,\n",
    ")\n",
    "\n",
    "booster = Booster(plugin=plugin)\n",
    "\n",
    "seq_align = plugin_config.get(\"sp_size\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6514c365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®Ÿé¨“ãƒ‡ã‚£ãƒ¬ã‚¯æªç½®ã‚’åˆæœŸåŒ–\n",
    "\n",
    "exp_name, exp_dir = create_experiment_workspace(\n",
    "    cfg.get(\"outputs\", \"./outputs\"),\n",
    "    model_name=config_to_name(cfg),\n",
    "    config=cfg.to_dict(),\n",
    "    exp_name=cfg.get(\"exp_name\", None),  # useful for automatic restart to specify the exp_name\n",
    ")\n",
    "logger_.info(f\"å®Ÿé¨“å: {exp_name}\")\n",
    "logger_.info(f\"å®Ÿé¨“ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {exp_dir}\")\n",
    "\n",
    "if is_log_process(plugin_type, plugin_config):\n",
    "    print(f\"changing {exp_dir} to share\")\n",
    "    os.system(f\"chgrp -R share {exp_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf0cd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ­ã‚¬ãƒ¼ã‚’åˆæœŸåŒ–ï¼ˆæ¨™æº–å‡ºåŠ›ãƒ»TensorBoardãƒ»WandBï¼‰\n",
    "\n",
    "# logger = create_logger(exp_dir)\n",
    "\n",
    "logger_.info(\"Training configuration:\\n %s\", pformat(cfg.to_dict()))\n",
    "\n",
    "tb_writer = None\n",
    "\n",
    "if coordinator.is_master():\n",
    "    tb_writer = create_tensorboard_writer(exp_dir)\n",
    "    if cfg.get(\"wandb\", False):\n",
    "        logger_.info(f\"WandBã‚’åˆæœŸåŒ–\")\n",
    "        wandb.init(\n",
    "            project=cfg.get(\"wandb_project\", \"Open-Sora\"),\n",
    "            name=exp_name,\n",
    "            config=cfg.to_dict(),\n",
    "            dir=exp_dir,\n",
    "        )\n",
    "\n",
    "num_gpus = dist.get_world_size() if dist.is_initialized() else 1\n",
    "logger_.info(\"Number of GPUs: %s\", num_gpus)\n",
    "\n",
    "tp_size = cfg[\"plugin_config\"].get(\"tp_size\", 1)\n",
    "sp_size = cfg[\"plugin_config\"].get(\"sp_size\", 1)\n",
    "pp_size = cfg[\"plugin_config\"].get(\"pp_size\", 1)\n",
    "num_groups = num_gpus // (tp_size * sp_size * pp_size)\n",
    "logger_.info(\"Number of groups: %s\", num_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7f3a1c",
   "metadata": {},
   "source": [
    "### 2. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã®æ§‹ç¯‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db28e0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ§‹ç¯‰\n",
    "dataset = build_module(cfg.dataset, DATASETS)\n",
    "logger_.info(f\"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3281d91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚µãƒ³ãƒ—ãƒ«ã‚’è¡¨ç¤º\n",
    "\n",
    "random_index = random.randint(0, len(dataset) - 1)\n",
    "\n",
    "sample = dataset[f\"{random_index}-1-256-256\"]\n",
    "\n",
    "sample[\"video\"].shape # (3, 1, 256, 256)\n",
    "first_frame = sample[\"video\"][:, 0]  # (3, 256, 256)\n",
    "\n",
    "# display\n",
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(first_frame.permute(1, 2, 0), cmap='gray')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277708d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã®ãƒ“ãƒ«ãƒ‰\n",
    "\n",
    "cache_pin_memory = pin_memory_cache_pre_alloc_numels is not None\n",
    "logger_.info(f\"Cache pin memory: {cache_pin_memory}\")\n",
    "\n",
    "dataloader_args = dict(\n",
    "    dataset=dataset,\n",
    "    batch_size=cfg.get(\"batch_size\", None),\n",
    "    num_workers=cfg.get(\"num_workers\", 4),\n",
    "    seed=cfg.get(\"seed\", 1024),\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    pin_memory=True,\n",
    "    process_group=get_data_parallel_group(),\n",
    "    prefetch_factor=cfg.get(\"prefetch_factor\", None),\n",
    "    cache_pin_memory=cache_pin_memory,\n",
    "    num_groups=num_groups,\n",
    ")\n",
    "logger_.info(f\"Dataloader arguments: {pformat(dataloader_args)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d263382",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader, sampler = prepare_dataloader(\n",
    "    bucket_config=cfg.get(\"bucket_config\", None),\n",
    "    num_bucket_build_workers=cfg.get(\"num_bucket_build_workers\", 1),\n",
    "    **dataloader_args,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cc2733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import DataLoader from torch\n",
    "# from torch.utils.data import DataLoader\n",
    "# from opensora.datasets.dataloader import DataloaderForVideo\n",
    "# dataloader = DataloaderForVideo(dataset, batch_size=1, collate_fn=collate_fn_default)\n",
    "# first_batch = next(iter(dataloader))\n",
    "# len(dataloader)\n",
    "# first_batch[\"video\"].shape  # (1, 3, 16, 256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed9cd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps_per_epoch = len(dataloader)\n",
    "logger_.info(f\"1ã‚¨ãƒãƒƒã‚¯ã‚ãŸã‚Šã®ã‚¹ãƒ†ãƒƒãƒ—æ•°: {num_steps_per_epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c36a394",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_efficient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fe50bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_iter = iter(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93da31a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_batch = next(dataloader_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0917e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger_.info(f\"{first_batch.keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fe1b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925a1bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_batch[\"sampling_interval\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9617103d",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_batch[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25d4115",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_batch[\"index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d9f02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_batch[\"path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0893f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_batch[\"video\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d7e709",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_iter = iter(dataloader)\n",
    "sample_batch = next(dataset_iter)\n",
    "sample_batch.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077c00c1",
   "metadata": {},
   "source": [
    "### 3. ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a91230",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger_.info(\"Building models...\")\n",
    "\n",
    "# == build model model ==\n",
    "model = build_module(cfg.model, MODELS, device_map=device, torch_dtype=dtype).train()\n",
    "\n",
    "if cfg.get(\"grad_checkpoint\", True):\n",
    "    logger_.info(f\"å‹¾é…ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’æœ‰åŠ¹åŒ–\")\n",
    "    set_grad_checkpoint(model)\n",
    "\n",
    "log_cuda_memory(\"diffusion\")\n",
    "log_model_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23a5e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# == build EMA model ==\n",
    "use_lora = cfg.get(\"lora_config\", None) is not None\n",
    "\n",
    "if cfg.get(\"ema_decay\", None) is not None and not use_lora:\n",
    "    ema = deepcopy(model).cpu().eval().requires_grad_(False)\n",
    "    ema_shape_dict = record_model_param_shape(ema)\n",
    "    logger_.info(\"EMA model created.\")\n",
    "else:\n",
    "    ema = ema_shape_dict = None\n",
    "    logger_.info(\"No EMA model created.\")\n",
    "\n",
    "log_cuda_memory(\"EMA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277eed60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# == enable LoRA ==\n",
    "if use_lora:\n",
    "    lora_config = LoraConfig(**cfg.get(\"lora_config\", None))\n",
    "    model = booster.enable_lora(\n",
    "        model=model,\n",
    "        lora_config=lora_config,\n",
    "        pretrained_dir=cfg.get(\"lora_checkpoint\", None),\n",
    "    )\n",
    "    log_cuda_memory(\"lora\")\n",
    "    log_model_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f6e0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not cfg.get(\"cached_video\", False):\n",
    "    # == buildn autoencoder ==\n",
    "    model_ae = build_module(cfg.ae, MODELS, device_map=device, torch_dtype=dtype).eval().requires_grad_(False)\n",
    "    del model_ae.decoder\n",
    "    logger_.info(\"Autoencoder built.\")\n",
    "    log_model_params(model_ae)\n",
    "    model_ae.encode = torch.compile(model_ae.encoder, dynamic=True)\n",
    "\n",
    "model_ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaacd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not cfg.get(\"cached_text\", False):\n",
    "    # == build text encoder (t5) ==\n",
    "    model_t5 = build_module(cfg.t5, MODELS, device_map=device, torch_dtype=dtype).eval().requires_grad_(False)\n",
    "    log_cuda_memory(\"t5\")\n",
    "    log_model_params(model_t5)\n",
    "\n",
    "    # == build text encoder (clip) ==\n",
    "    model_clip = build_module(cfg.clip, MODELS, device_map=device, torch_dtype=dtype).eval().requires_grad_(False)\n",
    "    log_cuda_memory(\"clip\")\n",
    "    log_model_params(model_clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07350853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# == setup optimizer ==\n",
    "optimizer = create_optimizer(model, cfg.optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b69e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# == setup lr scheduler ==\n",
    "lr_scheduler = create_lr_scheduler(\n",
    "    optimizer=optimizer,\n",
    "    num_steps_per_epoch=num_steps_per_epoch,\n",
    "    epochs=cfg.get(\"epochs\", 1000),\n",
    "    warmup_steps=cfg.get(\"warmup_steps\", None),\n",
    "    use_cosine_scheduler=cfg.get(\"use_cosine_scheduler\", False),\n",
    ")\n",
    "log_cuda_memory(\"optimizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a0dd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# == prepare null vectors for dropout ==\n",
    "if cfg.get(\"cached_text\", False):\n",
    "    null_txt = torch.load(\"/mnt/ddn/sora/tmp_load/null_t5.pt\", map_location=device)\n",
    "    null_vec = torch.load(\"/mnt/ddn/sora/tmp_load/null_clip.pt\", map_location=device)\n",
    "else:\n",
    "    null_txt = model_t5(\"\")\n",
    "    null_vec = model_clip(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe8f3e4",
   "metadata": {},
   "source": [
    "### 4. Colossalaiã‚’ä½¿ç”¨ã—ãŸåˆ†æ•£å­¦ç¿’ã®æº–å‚™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b623ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger_.info(\"Preparing for distributed training...\")\n",
    "\n",
    "# == boosting ==\n",
    "torch.set_default_dtype(dtype)\n",
    "\n",
    "model, optimizer, _, dataloader, lr_scheduler = booster.boost(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    lr_scheduler=lr_scheduler,\n",
    "    dataloader=dataloader,\n",
    ")\n",
    "\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "logger_.info(\"Boosted model for distributed training\")\n",
    "\n",
    "log_cuda_memory(\"boost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c9913b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# == global variables ==\n",
    "cfg_epochs = cfg.get(\"epochs\", 1000)\n",
    "\n",
    "log_step = acc_step = 0\n",
    "\n",
    "running_loss = 0.0\n",
    "\n",
    "timers = Timers(record_time=cfg.get(\"record_time\", False), record_barrier=cfg.get(\"record_barrier\", False))\n",
    "\n",
    "nsys = NsysProfiler(\n",
    "    warmup_steps=cfg.get(\"nsys_warmup_steps\", 2),\n",
    "    num_steps=cfg.get(\"nsys_num_steps\", 2),\n",
    "    enabled=cfg.get(\"nsys\", False),\n",
    ")\n",
    "\n",
    "logger_.info(\"Training for %s epochs with %s steps per epoch\", cfg_epochs, num_steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc22b245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# == resume ==\n",
    "\n",
    "load_master_weights = cfg.get(\"load_master_weights\", False)\n",
    "\n",
    "save_master_weights = cfg.get(\"save_master_weights\", False)\n",
    "\n",
    "start_epoch = cfg.get(\"start_epoch\", None)\n",
    "\n",
    "start_step = cfg.get(\"start_step\", None)\n",
    "\n",
    "if cfg.get(\"load\", None) is not None:\n",
    "    logger_.info(\"Loading checkpoint from %s\", cfg.load)\n",
    "\n",
    "    lr_scheduler_to_load = lr_scheduler\n",
    "\n",
    "    if cfg.get(\"update_warmup_steps\", False):\n",
    "        lr_scheduler_to_load = None\n",
    "\n",
    "    ret = checkpoint_io.load(\n",
    "        booster,\n",
    "        cfg.load,\n",
    "        model=model,\n",
    "        ema=ema,\n",
    "        optimizer=optimizer,\n",
    "        lr_scheduler=lr_scheduler_to_load,\n",
    "        sampler=(\n",
    "            None if start_step is not None else sampler\n",
    "        ),  # if specify start step, set last_micro_batch_access_index of a new sampler instead\n",
    "        include_master_weights=load_master_weights,\n",
    "    )\n",
    "\n",
    "    start_epoch = start_epoch if start_epoch is not None else ret[0]\n",
    "\n",
    "    start_step = start_step if start_step is not None else ret[1]\n",
    "\n",
    "    logger_.info(\"Loaded checkpoint %s at epoch %s step %s\", cfg.load, ret[0], ret[1])\n",
    "\n",
    "    # load optimizer and scheduler will overwrite some of the hyperparameters, so we need to reset them\n",
    "    set_lr(optimizer, lr_scheduler, cfg.optim.lr, cfg.get(\"initial_lr\", None))\n",
    "    set_eps(optimizer, cfg.optim.eps)\n",
    "\n",
    "    if cfg.get(\"update_warmup_steps\", False):\n",
    "        assert (\n",
    "            cfg.get(\"warmup_steps\", None) is not None\n",
    "        ), \"you need to set warmup_steps in order to pass --update-warmup-steps True\"\n",
    "        # set_warmup_steps(lr_scheduler, cfg.warmup_steps)\n",
    "        lr_scheduler.step(start_epoch * num_steps_per_epoch + start_step)\n",
    "        logger_.info(\"The learning rate starts from %s\", optimizer.param_groups[0][\"lr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287d3ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if start_step is not None:\n",
    "    # if start step exceeds data length, go to next epoch\n",
    "    if start_step > num_steps_per_epoch:\n",
    "        start_epoch = (\n",
    "            start_epoch + start_step // num_steps_per_epoch\n",
    "            if start_epoch is not None\n",
    "            else start_step // num_steps_per_epoch\n",
    "        )\n",
    "        start_step = start_step % num_steps_per_epoch\n",
    "else:\n",
    "    start_step = 0\n",
    "\n",
    "sampler.set_step(start_step)\n",
    "start_epoch = start_epoch if start_epoch is not None else 0\n",
    "logger_.info(\"Starting from epoch %s step %s\", start_epoch, start_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2056bcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# == sharding EMA model ==\n",
    "if ema is not None:\n",
    "    model_sharding(ema)\n",
    "    ema = ema.to(device)\n",
    "    log_cuda_memory(\"sharding EMA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133dcce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# == warmup autoencoder ==\n",
    "if cfg.get(\"warmup_ae\", False):\n",
    "    shapes = bucket_to_shapes(\n",
    "        cfg.get(\"bucket_config\", None),\n",
    "        batch_size=cfg.ae.batch_size\n",
    "    )\n",
    "\n",
    "    warmup_ae(model_ae, shapes, device, dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a682fd4b",
   "metadata": {},
   "source": [
    "### 5. è¨“ç·´ã®ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5080c3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_min = cfg.get(\"sigma_min\", 1e-5)\n",
    "\n",
    "accumulation_steps = cfg.get(\"accumulation_steps\", 1)\n",
    "\n",
    "ckpt_every = cfg.get(\"ckpt_every\", 0)\n",
    "\n",
    "if cfg.get(\"is_causal_vae\", False):\n",
    "    logger_.info(f\"Preparing visual condition for causal VAE\")\n",
    "    prepare_visual_condition = prepare_visual_condition_causal\n",
    "else:\n",
    "    logger_.info(f\"Preparing visual condition for uncausal VAE\")\n",
    "    prepare_visual_condition = prepare_visual_condition_uncausal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab27e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def prepare_inputs(batch):\n",
    "    logger_.info(f\"è¨“ç·´ã®æº–å‚™ã‚’é–‹å§‹\")\n",
    "\n",
    "    inp = dict()\n",
    "\n",
    "    x = batch.pop(\"video\")\n",
    "\n",
    "    y = batch.pop(\"text\")\n",
    "\n",
    "    bs = x.shape[0]\n",
    "\n",
    "    # == encode video ==\n",
    "    logger_.info(f\"å‹•ç”»ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã‚’é–‹å§‹\")\n",
    "    with nsys.range(\"encode_video\"), timers[\"encode_video\"]:\n",
    "        # == prepare condition ==\n",
    "        if cfg.get(\"condition_config\", None) is not None:\n",
    "            # condition for i2v & v2v\n",
    "            x_0, cond = prepare_visual_condition(x, cfg.condition_config, model_ae)\n",
    "            cond = pack(cond, patch_size=cfg.get(\"patch_size\", 2))\n",
    "            inp[\"cond\"] = cond\n",
    "        else:\n",
    "            if cfg.get(\"cached_video\", False):\n",
    "                x_0 = batch.pop(\"video_latents\").to(device=device, dtype=dtype)\n",
    "            else:\n",
    "                x_0 = model_ae.encode(x)\n",
    "\n",
    "    # == prepare timestep ==\n",
    "    logger_.info(f\"ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—ã®æº–å‚™ã‚’é–‹å§‹\")\n",
    "    # follow SD3 time shift, shift_alpha = 1 for 256px and shift_alpha = 3 for 1024px\n",
    "    shift_alpha = get_res_lin_function()((x_0.shape[-1] * x_0.shape[-2]) // 4)\n",
    "    # add temporal influence\n",
    "    shift_alpha *= math.sqrt(x_0.shape[-3])  # for image, T=1 so no effect\n",
    "    t = torch.sigmoid(torch.randn((bs), device=device))\n",
    "    t = time_shift(shift_alpha, t).to(dtype)\n",
    "\n",
    "    if cfg.get(\"cached_text\", False):\n",
    "        # == encode text ==\n",
    "        logger_.info(f\"ãƒ†ã‚­ã‚¹ãƒˆã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã‚’é–‹å§‹(ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä½¿ç”¨)\")\n",
    "        t5_embedding = batch.pop(\"text_t5\").to(device=device, dtype=dtype)\n",
    "        clip_embedding = batch.pop(\"text_clip\").to(device=device, dtype=dtype)\n",
    "        with nsys.range(\"encode_text\"), timers[\"encode_text\"]:\n",
    "            inp_ = prepare_ids(x_0, t5_embedding, clip_embedding)\n",
    "            inp.update(inp_)\n",
    "            x_0 = pack(x_0, patch_size=cfg.get(\"patch_size\", 2))\n",
    "    else:\n",
    "        # == encode text ==\n",
    "        logger_.info(f\"ãƒ†ã‚­ã‚¹ãƒˆã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã‚’é–‹å§‹\")\n",
    "        with nsys.range(\"encode_text\"), timers[\"encode_text\"]:\n",
    "            inp_ = prepare(\n",
    "                model_t5,\n",
    "                model_clip,\n",
    "                x_0,\n",
    "                prompt=y,\n",
    "                seq_align=seq_align,\n",
    "                patch_size=cfg.get(\"patch_size\", 2),\n",
    "            )\n",
    "            inp.update(inp_)\n",
    "            x_0 = pack(x_0, patch_size=cfg.get(\"patch_size\", 2))\n",
    "\n",
    "    # == dropout ==\n",
    "    if cfg.get(\"dropout_ratio\", None) is not None:\n",
    "        logger_.info(f\"ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆã®é©ç”¨ã‚’é–‹å§‹\")\n",
    "        cur_null_txt = null_txt\n",
    "        num_pad_null_txt = inp[\"txt\"].shape[1] - cur_null_txt.shape[1]\n",
    "        if num_pad_null_txt > 0:\n",
    "            cur_null_txt = torch.cat([cur_null_txt] + [cur_null_txt[:, -1:]] * num_pad_null_txt, dim=1)\n",
    "        inp[\"txt\"] = dropout_condition(\n",
    "            cfg.dropout_ratio.get(\"t5\", 0.0),\n",
    "            inp[\"txt\"],\n",
    "            cur_null_txt,\n",
    "        )\n",
    "        inp[\"y_vec\"] = dropout_condition(\n",
    "            cfg.dropout_ratio.get(\"clip\", 0.0),\n",
    "            inp[\"y_vec\"],\n",
    "            null_vec,\n",
    "        )\n",
    "\n",
    "    # == prepare noise vector ==\n",
    "    x_1 = torch.randn_like(x_0, dtype=torch.float32).to(device, dtype)\n",
    "    t_rev = 1 - t\n",
    "    x_t = t_rev[:, None, None] * x_0 + (1 - (1 - sigma_min) * t_rev[:, None, None]) * x_1\n",
    "    inp[\"img\"] = x_t\n",
    "    inp[\"timesteps\"] = t.to(dtype)\n",
    "    inp[\"guidance\"] = torch.full((x_t.shape[0],), cfg.get(\"guidance\", 4), device=x_t.device, dtype=x_t.dtype)\n",
    "\n",
    "    return inp, x_0, x_1\n",
    "\n",
    "sample_batch = next(dataset_iter)\n",
    "sample_batch.keys()\n",
    "pinned_video = sample_batch[\"video\"]\n",
    "sample_batch[\"video\"] = pinned_video.to(device, dtype, non_blocking=True)\n",
    "inp, x_0, x_1 = prepare_inputs(sample_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2303e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger_.debug(f\"inp: {inp.keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ffa2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger_.debug(f\"x_0.shape: {x_0.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904850cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger_.debug(f\"x_1.shape: {x_1.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ad9c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_iter(inp, x_0, x_1):\n",
    "    logger_.info(f\"1ã¤ã®ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œä¸­ {inp.keys()=} {x_0.shape=} {x_1.shape=}\")\n",
    "\n",
    "    if is_pipeline_enabled(plugin_type, plugin_config):\n",
    "        logger_.info(f\"ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ä¸¦åˆ—ã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹ãŸã‚ã€forward-backwardã‚’ä¸€ä½“åŒ–ã—ã¦å®Ÿè¡Œ\")\n",
    "\n",
    "        inp[\"target\"] = (1 - sigma_min) * x_1 - x_0  # follow MovieGen, modify V_t accordingly\n",
    "        with nsys.range(\"forward-backward\"), timers[\"forward-backward\"]:\n",
    "            data_iter = iter([inp])\n",
    "            if cfg.get(\"no_i2v_ref_loss\", False):\n",
    "                loss_fn = (\n",
    "                    lambda out, input_: get_batch_loss(out, input_[\"target\"], input_.pop(\"masks\", None))\n",
    "                    / accumulation_steps\n",
    "                )\n",
    "            else:\n",
    "                loss_fn = (\n",
    "                    lambda out, input_: F.mse_loss(out.float(), input_[\"target\"].float(), reduction=\"mean\")\n",
    "                    / accumulation_steps\n",
    "                )\n",
    "            loss = booster.execute_pipeline(data_iter, model, loss_fn, optimizer)[\"loss\"]\n",
    "            loss = loss * accumulation_steps if loss is not None else loss\n",
    "            loss_item = all_reduce_mean(loss.data.clone().detach())\n",
    "    else:\n",
    "        logger_.info(f\"é€šå¸¸ã®åˆ†æ•£å­¦ç¿’ãƒ«ãƒ¼ãƒ—ã§forwardã¨backwardã‚’å®Ÿè¡Œ\")\n",
    "\n",
    "        # == forward ==\n",
    "        logger_.info(f\"ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œ\")\n",
    "\n",
    "        with nsys.range(\"forward\"), timers[\"forward\"]:\n",
    "            model_pred = model(**inp)  # B, T, L\n",
    "            v_t = (1 - sigma_min) * x_1 - x_0\n",
    "            if cfg.get(\"no_i2v_ref_loss\", False):\n",
    "                loss = get_batch_loss(model_pred, v_t, inp.pop(\"masks\", None))\n",
    "            else:\n",
    "                loss = F.mse_loss(model_pred.float(), v_t.float(), reduction=\"mean\")\n",
    "\n",
    "        loss_item = all_reduce_mean(loss.data.clone().detach()).item()\n",
    "\n",
    "        # == backward & update ==\n",
    "        dist.barrier()\n",
    "        logger_.info(f\"ãƒãƒƒã‚¯ãƒ¯ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œ\")\n",
    "\n",
    "        with nsys.range(\"backward\"), timers[\"backward\"]:\n",
    "            ctx = (\n",
    "                booster.no_sync(model, optimizer)\n",
    "                if cfg.get(\"plugin\", \"zero2\") in (\"zero1\", \"zero1-seq\") and (step + 1) % accumulation_steps != 0\n",
    "                else nullcontext()\n",
    "            )\n",
    "            with ctx:\n",
    "                booster.backward(loss=(loss / accumulation_steps), optimizer=optimizer)\n",
    "\n",
    "    # == optim step ==\n",
    "    logger_.info(f\"ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼ã‚¹ãƒ†ãƒƒãƒ—ã‚’å®Ÿè¡Œ\")\n",
    "\n",
    "    with nsys.range(\"optim\"), timers[\"optim\"]:\n",
    "        if (step + 1) % accumulation_steps == 0:\n",
    "            booster.checkpoint_io.synchronize()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        if lr_scheduler is not None:\n",
    "            lr_scheduler.step()\n",
    "\n",
    "    # == update EMA ==\n",
    "    if ema is not None:\n",
    "        logger_.info(f\"EMAãƒ¢ãƒ‡ãƒ«ã®æ›´æ–°ã‚’å®Ÿè¡Œ\")\n",
    "        with nsys.range(\"update_ema\"), timers[\"update_ema\"]:\n",
    "            update_ema(\n",
    "                ema,\n",
    "                model.unwrap(),\n",
    "                optimizer=optimizer,\n",
    "                decay=cfg.get(\"ema_decay\", 0.9999),\n",
    "            )\n",
    "\n",
    "    return loss_item\n",
    "\n",
    "# step = 0\n",
    "# sample_loss = run_iter(inp, x_0, x_1)\n",
    "# logger_.info(f\"ã‚µãƒ³ãƒ—ãƒ«ãƒãƒƒãƒã®æå¤±: {sample_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b7b1b1",
   "metadata": {},
   "source": [
    "### 6. è¨“ç·´ãƒ«ãƒ¼ãƒ—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb06d6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    logger_.info(\"è¨“ç·´é–‹å§‹...\")\n",
    "\n",
    "    dist.barrier()\n",
    "    for epoch in range(start_epoch, cfg_epochs):\n",
    "        # == set dataloader to new epoch ==\n",
    "        sampler.set_epoch(epoch)\n",
    "        logger_.info(f\"ã‚µãƒ³ãƒ—ãƒ©ãƒ¼ã‚’ã‚¨ãƒãƒƒã‚¯ {epoch} ã«è¨­å®šã—ã¾ã—ãŸ\")\n",
    "\n",
    "        dataloader_iter = iter(dataloader)\n",
    "\n",
    "        logger_.info(\"ã‚¨ãƒãƒƒã‚¯ %s ã‚’é–‹å§‹ã—ã¾ã™...\", epoch)\n",
    "        # == training loop in an epoch ==\n",
    "        with tqdm(\n",
    "            enumerate(dataloader_iter, start=start_step),\n",
    "            desc=f\"Epoch {epoch}\",\n",
    "            disable=not is_log_process(plugin_type, plugin_config),\n",
    "            initial=start_step,\n",
    "            total=num_steps_per_epoch,\n",
    "        ) as pbar:\n",
    "            pbar_iter = iter(pbar)\n",
    "\n",
    "            # prefetch one for non-blocking data loading\n",
    "            def fetch_data():\n",
    "                step, batch = next(pbar_iter)\n",
    "                # print(f\"==debug== rank{dist.get_rank()} {dataloader_iter.get_cache_info()}\")\n",
    "                pinned_video = batch[\"video\"]\n",
    "                batch[\"video\"] = pinned_video.to(device, dtype, non_blocking=True)\n",
    "                return batch, step, pinned_video\n",
    "\n",
    "            batch_, step_, pinned_video_ = fetch_data()\n",
    "            logger_.info(f\"ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒã—ã¾ã—ãŸ {step_}\")\n",
    "\n",
    "            for current_step in range(start_step, num_steps_per_epoch):\n",
    "                logger_.info(f\"é–‹å§‹ epoch {epoch} step {current_step}\")\n",
    "\n",
    "                nsys.step()\n",
    "\n",
    "                # == load data ===\n",
    "                logger_.debug(f\"ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰é–‹å§‹\")\n",
    "\n",
    "                with nsys.range(\"load_data\"), timers[\"load_data\"]:\n",
    "                    batch, step, pinned_video = batch_, step_, pinned_video_\n",
    "\n",
    "                    if step + 1 < num_steps_per_epoch:\n",
    "                        # only fetch new data if not last step\n",
    "                        batch_, step_, pinned_video_ = fetch_data()\n",
    "\n",
    "                # == run iter ==\n",
    "                logger_.debug(f\"ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œé–‹å§‹\")\n",
    "\n",
    "                with nsys.range(\"iter\"), timers[\"iter\"]:\n",
    "\n",
    "                    inp, x_0, x_1 = prepare_inputs(batch)\n",
    "\n",
    "                    # if cache_pin_memory:\n",
    "                    #     dataloader_iter.remove_cache(pinned_video)\n",
    "                    \n",
    "                    loss = run_iter(inp, x_0, x_1)\n",
    "\n",
    "                # == update log info ==\n",
    "                if loss is not None:\n",
    "                    logger_.debug(f\"æå¤±ã‚’æ›´æ–°ä¸­ {loss=}\")\n",
    "                    running_loss += loss\n",
    "\n",
    "                # == log config ==\n",
    "                logger_.debug(f\"ãƒ­ã‚°æƒ…å ±ã‚’æ›´æ–°ä¸­\")\n",
    "                global_step = epoch * num_steps_per_epoch + step\n",
    "                actual_update_step = (global_step + 1) // accumulation_steps\n",
    "                log_step += 1\n",
    "                acc_step += 1\n",
    "\n",
    "                # == logging ==\n",
    "                if (global_step + 1) % accumulation_steps == 0:\n",
    "                    if actual_update_step % cfg.get(\"log_every\", 1) == 0:\n",
    "                        if is_log_process(plugin_type, plugin_config):\n",
    "                            logger_.info(f\"ãƒ­ã‚°ã‚’è¨˜éŒ²ä¸­ at epoch {epoch} step {step} global_step {global_step} actual_update_step {actual_update_step}\")\n",
    "\n",
    "                            avg_loss = running_loss / log_step\n",
    "                            # progress bar\n",
    "                            pbar.set_postfix(\n",
    "                                {\n",
    "                                    \"loss\": avg_loss,\n",
    "                                    \"global_grad_norm\": optimizer.get_grad_norm(),\n",
    "                                    \"step\": step,\n",
    "                                    \"global_step\": global_step,\n",
    "                                    # \"actual_update_step\": actual_update_step,\n",
    "                                    \"lr\": optimizer.param_groups[0][\"lr\"],\n",
    "                                }\n",
    "                            )\n",
    "                            # tensorboard\n",
    "                            if tb_writer is not None:\n",
    "                                tb_writer.add_scalar(\"loss\", loss, actual_update_step)\n",
    "                            # wandb\n",
    "                            if cfg.get(\"wandb\", False):\n",
    "                                wandb_dict = {\n",
    "                                    \"iter\": global_step,\n",
    "                                    \"acc_step\": acc_step,\n",
    "                                    \"epoch\": epoch,\n",
    "                                    \"loss\": loss,\n",
    "                                    \"avg_loss\": avg_loss,\n",
    "                                    \"lr\": optimizer.param_groups[0][\"lr\"],\n",
    "                                    \"eps\": optimizer.param_groups[0][\"eps\"],\n",
    "                                    \"global_grad_norm\": optimizer.get_grad_norm(),  # test grad norm\n",
    "                                }\n",
    "                                if cfg.get(\"record_time\", False):\n",
    "                                    wandb_dict.update(timers.to_dict())\n",
    "                                wandb.log(wandb_dict, step=actual_update_step)\n",
    "\n",
    "                        running_loss = 0.0\n",
    "                        log_step = 0\n",
    "\n",
    "                # == checkpoint saving ==\n",
    "                logger_.debug(f\"ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®ä¿å­˜ã‚’ç¢ºèªä¸­\")\n",
    "                # uncomment below 3 lines to forcely clean cache\n",
    "                with nsys.range(\"clean_cache\"), timers[\"clean_cache\"]:\n",
    "                    if ckpt_every > 0 and actual_update_step % ckpt_every == 0 and coordinator.is_master():\n",
    "                        subprocess.run(\"sudo drop_cache\", shell=True)\n",
    "\n",
    "                logger_.debug(f\"ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®ä¿å­˜ã‚’å®Ÿè¡Œä¸­\")\n",
    "                with nsys.range(\"checkpoint\"), timers[\"checkpoint\"]:\n",
    "                    if ckpt_every > 0 and actual_update_step % ckpt_every == 0:\n",
    "                        # mannual garbage collection\n",
    "                        gc.collect()\n",
    "\n",
    "                        save_dir = checkpoint_io.save(\n",
    "                            booster,\n",
    "                            exp_dir,\n",
    "                            model=model,\n",
    "                            ema=ema,\n",
    "                            optimizer=optimizer,\n",
    "                            lr_scheduler=lr_scheduler,\n",
    "                            sampler=sampler,\n",
    "                            epoch=epoch,\n",
    "                            step=step + 1,\n",
    "                            global_step=global_step + 1,\n",
    "                            batch_size=cfg.get(\"batch_size\", None),\n",
    "                            lora=use_lora,\n",
    "                            actual_update_step=actual_update_step,\n",
    "                            ema_shape_dict=ema_shape_dict,\n",
    "                            async_io=cfg.get(\"async_io\", False),\n",
    "                            include_master_weights=save_master_weights,\n",
    "                        )\n",
    "\n",
    "                        if is_log_process(plugin_type, plugin_config):\n",
    "                            os.system(f\"chgrp -R share {save_dir}\")\n",
    "\n",
    "                        logger_.info(\n",
    "                            \"Saved checkpoint at epoch %s, step %s, global_step %s to %s\",\n",
    "                            epoch,\n",
    "                            step + 1,\n",
    "                            actual_update_step,\n",
    "                            save_dir,\n",
    "                        )\n",
    "\n",
    "                        # remove old checkpoints\n",
    "                        rm_checkpoints(exp_dir, keep_n_latest=cfg.get(\"keep_n_latest\", -1))\n",
    "                        logger_.info(\"Removed old checkpoints and kept %s latest ones.\", cfg.get(\"keep_n_latest\", -1))\n",
    "                # uncomment below 3 lines to benchmark checkpoint\n",
    "                # if ckpt_every > 0 and actual_update_step % ckpt_every == 0:\n",
    "                #     booster.checkpoint_io._sync_io()\n",
    "                #     checkpoint_io._sync_io()\n",
    "                # == terminal timer ==\n",
    "                if cfg.get(\"record_time\", False):\n",
    "                    print(timers.to_str(epoch, step))\n",
    "\n",
    "        sampler.reset()\n",
    "        start_step = 0\n",
    "    log_cuda_max_memory(\"final\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
