{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f68b9b2b",
   "metadata": {},
   "source": [
    "# Open-Sora 2.0 Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f47a17e",
   "metadata": {},
   "source": [
    "## ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646fd000",
   "metadata": {},
   "source": [
    "è¨“ç·´ã¯3ã¤ã®ã‚¹ãƒ†ãƒ¼ã‚¸ã§æ§‹æˆ:\n",
    "\n",
    "1. ä½Žè§£åƒåº¦å‹•ç”»ã«ã‚ˆã‚‹T2Vï¼ˆText to Videoï¼‰ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´\n",
    "1. ä½Žè§£åƒåº¦å‹•ç”»ã«ã‚ˆã‚‹I2Vï¼ˆImage to Videoï¼‰ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´\n",
    "1. é«˜è§£åƒåº¦å‹•ç”»ã«ã‚ˆã‚‹I2Vãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574c78b7",
   "metadata": {},
   "source": [
    "è¨“ç·´ã®ã‚³ã‚¹ãƒˆã®å†…è¨³ã¯ã€ã‚¹ãƒ†ãƒ¼ã‚¸1ã®ã‚³ã‚¹ãƒˆãŒ50%ã‚’å ã‚ã‚‹:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ef9cce",
   "metadata": {},
   "source": [
    "![](image/table3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1e9a74",
   "metadata": {},
   "source": [
    "è¨“ç·´ã®åŠ¹çŽ‡åŒ–ã®æˆ¦ç•¥:\n",
    "\n",
    "- 11Bï¼ˆ110å„„ï¼‰ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®Fluxã®è’¸ç•™ãƒ¢ãƒ‡ãƒ«ã§ã€T2Vãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–\n",
    "    - Fluxã¯ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹T2Iï¼ˆText to Imageï¼‰ãƒ¢ãƒ‡ãƒ«\n",
    "- é«˜å“è³ªãªå‹•ç”»ãƒ‡ãƒ¼ã‚¿ã§ã€è¨“ç·´åŠ¹çŽ‡ã‚’å‘ä¸Š\n",
    "    - PixArtã‹ã‚‰ç€æƒ³\n",
    "    - ã‚¹ãƒ†ãƒƒãƒ—1, 2ã§ã¯ã€å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‹ã‚‰é«˜å“è³ªãªã‚µãƒ–ã‚»ãƒƒãƒˆã‚’æŠ½å‡º\n",
    "    - ã‚¹ãƒ†ãƒƒãƒ—3ã§ã¯ã€ã‚ˆã‚ŠåŽ³ã—ã„ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã§ã‚µãƒ–ã‚»ãƒƒãƒˆã‚’æŠ½å‡º\n",
    "- ä½Žè§£åƒåº¦å‹•ç”»ã§ã®å‹•ãã®å­¦ç¿’\n",
    "    - é«˜è§£åƒåº¦å‹•ç”»ã®è¨“ç·´ã‚³ã‚¹ãƒˆã¯é«˜ã„ãŸã‚ã€å¤šæ§˜ãªå‹•ãã¯ä½Žè§£åƒåº¦å‹•ç”»ã‚’ä¸­å¿ƒã«è¨“ç·´\n",
    "        - 128ãƒ•ãƒ¬ãƒ¼ãƒ 768pxã®å‹•ç”»ã®è¨“ç·´ã¯ã€256pxã®å ´åˆã‚ˆã‚Šã‚‚40å€é…ã„\n",
    "        - ã‚»ãƒ«ãƒ•ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã®è¨ˆç®—è¤‡é›‘åº¦ãŒäºŒæ¬¡é–¢æ•°çš„ã«å¢—å¤§ã™ã‚‹ãŸã‚\n",
    "    - å‡ºåŠ›ãŒã¼ã‚„ã‘ã‚‹ãŸã‚ã€é«˜è§£åƒåº¦å‹•ç”»ã®è¨“ç·´ã§å“è³ªã‚’å‘ä¸Š\n",
    "- ã‚¹ãƒ†ãƒƒãƒ—2ã®ã‚¢ãƒƒãƒ—ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å­¦ç¿’ã¯ã€T2Vã§ã¯ãªãI2Vã‚’æŽ¡ç”¨ã—åŠ¹çŽ‡åŒ–:\n",
    "    - é™æ­¢ç”»ã‚’æ¡ä»¶ä»˜ã‘ã™ã‚‹ã“ã¨ã§ã€å‹•ãã®ç”Ÿæˆã«é›†ä¸­ã§ãã‚‹ãŸã‚\n",
    "- é«˜è§£åƒåº¦å‹•ç”»ã§ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’çŸ­ç¸®ã—ã€è¨“ç·´ã‚’åŠ¹çŽ‡åŒ–"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bee32fa",
   "metadata": {},
   "source": [
    "Open-Sora 2.0ã®è¨“ç·´ã‚³ã‚¹ãƒˆã¯ã€5~10å€ä½Žã„:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7a4a13",
   "metadata": {},
   "source": [
    "![](image/fig7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50432d84",
   "metadata": {},
   "source": [
    "è¨“ç·´è¨­å®šã¯ã€Open-Sora 1.2ã«åŸºã¥ã:\n",
    "\n",
    "- ç›®çš„é–¢æ•°ã¯Flow Matchingã‚’æŽ¡ç”¨\n",
    "- ã‚ªãƒ—ãƒ†ã‚£ãƒžã‚¤ã‚¶ã¯AdamWã‚’ä½¿ç”¨\n",
    "    - $\\beta$å€¤ã¯$(0.9, 0.999)$\n",
    "    - $\\epsilon$ã¯$1\\times 10^{-15}$\n",
    "    - é‡ã¿æ¸›è¡°ã¯ä½¿ç”¨ã—ãªã„\n",
    "    - å­¦ç¿’çŽ‡\n",
    "        - ã‚¹ãƒ†ãƒ¼ã‚¸1, 2\n",
    "            - æœ€åˆã®4ä¸‡ã‚¹ãƒ†ãƒƒãƒ—ã¯$5\\times 10^{-5}$\n",
    "            - æœ€å¾Œã®4.5ä¸‡ã‚¹ãƒ†ãƒƒãƒ—ã¯$3\\times 10^{-5}$\n",
    "        - ã‚¹ãƒ†ãƒ¼ã‚¸3\n",
    "            - $1\\times 10^{-5}$\n",
    "    - è³¼è²·ãƒŽãƒ«ãƒ ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°ã®é–¾å€¤ã¯$1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298a6ed7",
   "metadata": {},
   "source": [
    "Flow matchingã¯ã€Stable Diffusion 3ï¼ˆSD3ï¼‰ã¨é¡žä¼¼:\n",
    "\n",
    "$$\n",
    "\\mathcal{L} = \\mathbb{E}_{t,X_{0},X_{1}}[||f_{\\theta}(X_{t},t,y)-(X_{0}-X_{1})||]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16825ea",
   "metadata": {},
   "source": [
    "- $X_0$: å‹•ç”»ã®æ½œåœ¨è¡¨ç¾\n",
    "- $X_1 \\sim \\mathcal{N}(0,1)$: ã‚¬ã‚¦ã‚¹ãƒŽã‚¤ã‚º\n",
    "- $t$: ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—ï¼ˆãƒŽã‚¤ã‚ºå¼·åº¦ï¼‰\n",
    "- $X_t=(1-t)X_0 + tX_1$: è£œé–“ã•ã‚ŒãŸæ½œåœ¨è¡¨ç¾ï¼ˆãƒŽã‚¤ã‚ºã‚ã‚Šã®æ½œåœ¨è¡¨ç¾ï¼‰\n",
    "- $y$: ãƒ†ã‚­ã‚¹ãƒˆã‚„ç”»åƒãªã©ã®æ¡ä»¶\n",
    "- $(X_0 - X_1)$: æ­£è§£ã®é€Ÿåº¦ï¼ˆãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒŽã‚¤ã‚ºã¸ã®å¤‰åŒ–ã®æ–¹å‘ï¼‰\n",
    "- $\\mathbb{E}_{t, X_0, X_1}$: æ¡ä»¶ã‚’å¤‰ãˆãŸæ™‚ã®å¹³å‡"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cae6e92",
   "metadata": {},
   "source": [
    "$t$ã¯ã€å¯¾æ•°æ­£è¦åˆ†å¸ƒã‹ã‚‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã€$X_0$ã®å½¢çŠ¶ã«åˆã‚ã›ã¦ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼š\n",
    "\n",
    "$$\n",
    "t' = \\frac{at}{1 + (a-1)t}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cd5f9a",
   "metadata": {},
   "source": [
    "- $a$: $T\\times H\\times W$ã«æ¯”ä¾‹ã™ã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿\n",
    "- é«˜è§£åƒåº¦ã§ã®é•·æ™‚é–“ã®ç”»åƒã¯ãƒŽã‚¤ã‚ºã®å½±éŸ¿ã‚’å—ã‘ã‚„ã™ã„ãŸã‚\n",
    "- æŽ¨è«–æ™‚ã‚‚åŒæ§˜ã®æ–¹æ³•ãŒé©ç”¨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb03915",
   "metadata": {},
   "source": [
    "ãƒžãƒ«ãƒãƒã‚±ãƒƒãƒˆãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’æŽ¡ç”¨:\n",
    "\n",
    "- ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ãƒ»è§£åƒåº¦ãƒ»ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ãŒä¼¼ãŸå‹•ç”»ã‚’ãƒã‚±ãƒ„ã«åˆ†ã‘ã¦ã€ãƒã‚±ãƒ„ã”ã¨ã«ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’èª¿æ•´ã™ã‚‹æ‰‹æ³•\n",
    "    - ãƒ¡ãƒ¢ãƒªä¸è¶³ï¼ˆOOMï¼‰ã®å›žé¿\n",
    "    - ä¸¦åˆ—è¨ˆç®—æ™‚ã®è¨“ç·´æ™‚é–“ã®å‡ä¸€åŒ–"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580846f9",
   "metadata": {},
   "source": [
    "ã‚¹ãƒ†ãƒ¼ã‚¸1, 2ã®ãƒãƒƒãƒã‚µã‚¤ã‚ºã¨ãƒãƒƒãƒã‚µã‚¤ã‚ºã¨ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ:\n",
    "\n",
    "![](image/table4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece6997d",
   "metadata": {},
   "source": [
    "ã‚¹ãƒ†ãƒ¼ã‚¸3ã®ãƒãƒƒãƒã‚µã‚¤ã‚ºã¨ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆï¼ˆContext parallelism 4ï¼‰:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0decbf9",
   "metadata": {},
   "source": [
    "![](image/table5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f930f7dd",
   "metadata": {},
   "source": [
    "é«˜åœ§ç¸®ã‚ªãƒ¼ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ï¼ˆDC-AEï¼‰ã‚’ä½¿ç”¨ã—ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚³ã‚¹ãƒˆã‚’ã•ã‚‰ã«å‰Šæ¸›"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382509ce",
   "metadata": {},
   "source": [
    "DC-AEã‚’ä½¿ç”¨ã™ã‚‹ã¨ã€å‹•ç”»ç”Ÿæˆã«å¿…è¦ãªãƒˆãƒ¼ã‚¯ãƒ³æ•°ãŒå¤§å¹…ã«å‰Šæ¸›ã§ãã‚‹:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2af738",
   "metadata": {},
   "source": [
    "$$\n",
    "D_{token} = D_{T} \\times D_{H} \\times D_{W} \\times P_{T} \\times P_{H} \\times P_{W}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c126dd2e",
   "metadata": {},
   "source": [
    "- $D_{\\text{token}}$: ãƒˆãƒ¼ã‚¯ãƒ³ãƒ»ãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒ«æ¯”ï¼ˆã©ã®ãã‚‰ã„å°ã•ãåœ§ç¸®ã—ã¦ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã™ã‚‹ã‹ã®æ¯”çŽ‡ï¼‰\n",
    "- $D_T, D_H, H_W$: æ™‚é–“ãƒ»é«˜ã•ãƒ»å¹…ã®æ¬¡å…ƒã«ãŠã‘ã‚‹ã‚ªãƒ¼ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã®åœ§ç¸®çŽ‡\n",
    "- $P_T, P_H, P_W$: ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã«å…¥åŠ›ã™ã‚‹éš›ã®ãƒ‘ãƒƒãƒåˆ†å‰²ã‚µã‚¤ã‚º\n",
    "- Hunyuan Videoã®$D_{\\text{token}}$ã¯$4096$ã€DC-AEã®$D_{\\text{token}}$ã¯$1024$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d73b6eb",
   "metadata": {},
   "source": [
    "ã‚ªãƒ¼ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã®æ€§èƒ½ã¯ã€æƒ…å ±ãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ¯”ã§äºˆæ¸¬ã§ãã‚‹:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc2ad92",
   "metadata": {},
   "source": [
    "$$\n",
    "D_{info} = \\frac{D_{T} \\times D_{H} \\times D_{W} \\times C_{in}}{C_{out}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f77401f",
   "metadata": {},
   "source": [
    "- $D_{\\text{info}}$: å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ãŒæ½œåœ¨è¡¨ç¾ã«ãªã‚‹ã¨ãã«æƒ…å ±é‡ãŒåœ§ç¸®ã•ã‚ŒãŸæ¯”çŽ‡\n",
    "- $C_{\\text{in}}$: å…¥åŠ›ãƒãƒ£ãƒ³ãƒãƒ«æ•°ï¼ˆRGBã®å ´åˆ$3$ï¼‰\n",
    "- $C_{\\text{out}}$: å‡ºåŠ›ãƒãƒ£ãƒ³ãƒãƒ«æ•°ï¼ˆæ½œåœ¨è¡¨ç¾ã®ãƒãƒ£ãƒ³ãƒãƒ«æ•°ï¼‰\n",
    "- DC-AEã®ã‚ªãƒ¼ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã¯ã€Hunyuan Video VAEã¨StepVideo VAEã®$D_{\\text{info}}$ã¨ä¸€è‡´ã™ã‚‹ã‚ˆã†ã«è¨­è¨ˆ\n",
    "- å…·ä½“çš„ã«ã¯å‡ºåŠ›ãƒãƒ£ãƒ³ãƒãƒ«æ•°ã‚’å¢—ã‚„ã™"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82e52bc",
   "metadata": {},
   "source": [
    "DC-AEã®ãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒ«ãƒ–ãƒ­ãƒƒã‚¯ã¨ã‚¢ãƒƒãƒ—ã‚µãƒ³ãƒ—ãƒ«ãƒ–ãƒ­ãƒƒã‚¯ã«ã¯ã€å‹¾é…ä¼æ’­ã®å•é¡ŒãŒã‚ã‚‹:\n",
    "\n",
    "- ãƒ”ã‚¯ã‚»ãƒ«ã‚·ãƒ£ãƒƒãƒ•ãƒ«ã¨ãƒ”ã‚¯ã‚»ãƒ«ã‚¢ãƒ³ã‚·ãƒ£ãƒƒãƒ•ãƒ«ã‚’ä½¿ç”¨ã—ãŸæ®‹å·®æŽ¥ç¶šã‚’å°Žå…¥"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4b044c",
   "metadata": {},
   "source": [
    "DC-AEã§å‡ºåŠ›ã—ãŸé«˜åœ§ç¸®ã®æ½œåœ¨å¤‰æ•°ã§ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã™ã‚‹ã¨ã€å‹•ç”»ç”Ÿæˆã®å“è³ªãŒä½Žããªã‚‹:\n",
    "\n",
    "- ãƒãƒ£ãƒ³ãƒãƒ«æ•°ãŒå¤šã„ã¨ã€æ½œåœ¨ç©ºé–“æ§‹é€ ï¼ˆlatent space structureï¼‰ã®æœ€é©åŒ–ãŒé›£ã—ããªã‚‹ãŸã‚\n",
    "- DC-AEè¨“ç·´å¾Œã«ã€ç¬¬3å±¤ã®æ½œåœ¨è¡¨ç¾ã‚’DINOv2ã«åˆã‚ã›ã‚‹ãŸã‚ã®è’¸ç•™æå¤±ã‚’é©ç”¨ã—ã€æœ€é©åŒ–"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8639f8",
   "metadata": {},
   "source": [
    "DC-AEã‚’ä½¿ç”¨ã—ãŸå‹•ç”»ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´:\n",
    "\n",
    "1. 2000ä¸‡ä»¶ã®æœ€å¤§33ãƒ•ãƒ¬ãƒ¼ãƒ ã®å‹•ç”»ã‚’ã€1.7ä¸‡ã‚¹ãƒ†ãƒƒãƒ—ã§è¨“ç·´\n",
    "2. 200ä¸‡ä»¶ã®æœ€å¤§128ãƒ•ãƒ¬ãƒ¼ãƒ ã®å‹•ç”»ã‚’ã€8000ã‚¹ãƒ†ãƒƒãƒ—ã§è¨“ç·´"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1697a8a5",
   "metadata": {},
   "source": [
    "DC-AEã‚’ä½¿ç”¨ã—ãŸå‹•ç”»ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã¯ã€Hunyuan Video VAEã‚ˆã‚Šã‚‚ã€è¨“ç·´ã¨æŽ¨è«–ã§é«˜ã„åŠ¹çŽ‡æ€§:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46688e6",
   "metadata": {},
   "source": [
    "![](image/fig8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e26d444",
   "metadata": {},
   "source": [
    "DC-AEã¯ã€256ãƒãƒ£ãƒãƒ«ã¨128ãƒãƒ£ãƒãƒ«ã®2ã¤ã‚’æœ€åˆã‹ã‚‰è¨“ç·´:\n",
    "\n",
    "1. å†æ§‹æˆæå¤±$\\mathcal{L}_1$ã¨çŸ¥è¦šæå¤±$\\mathcal{L}_{\\text{LIPIS}}$ã‚’ä½¿ç”¨ã—ã¦ã€25ä¸‡ã‚¹ãƒ†ãƒƒãƒ—è¨“ç·´:\n",
    "    $$\n",
    "    \\mathcal{L} = \\mathcal{L}_{1} + 0.5\\mathcal{L}_{LPIPS}\n",
    "    $$\n",
    "2. æ•µå¯¾çš„æå¤±$\\mathcal{L}_{\\text{adv}}$ã‚’ä½¿ç”¨ã—ã¦ã€20ä¸‡ã‚¹ãƒ†ãƒƒãƒ—è¨“ç·´:\n",
    "    $$\n",
    "    \\mathcal{L} = \\mathcal{L_1} + 0.5\\mathcal{L_{LPIPS}} + 0.05\\mathcal{L_{\\text{adv}}}\n",
    "    $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73af25fc",
   "metadata": {},
   "source": [
    "DC-AEã®è¨“ç·´è¨­å®š:\n",
    "\n",
    "- ãƒ­ãƒ¼ã‚«ãƒ«ãƒãƒƒãƒã‚µã‚¤ã‚º$1$ã§$8$å€‹ã®GPUã‚’ä½¿ç”¨\n",
    "- ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”$1:1$ã€32ãƒ•ãƒ¬ãƒ¼ãƒ ã€256pxã®å‹•ç”»ã‚’ä½¿ç”¨\n",
    "- ã‚ªãƒ—ãƒ†ã‚£ãƒžã‚¤ã‚¶ã¯AdamWã‚’ä½¿ç”¨ï¼ˆ$\\beta=(0.9, 0.999)$, $\\epsilon=1\\times 10^{-15}$, é‡ã¿æ¸›è¡°ãªã—ï¼‰\n",
    "- ã‚ªãƒ¼ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã®å­¦ç¿’çŽ‡ã¯5e-5\n",
    "- ãƒ‡ã‚£ã‚¹ã‚¯ãƒªãƒŸãƒãƒ¼ã‚¿ã®å­¦ç¿’çŽ‡ã¯1e-4\n",
    "- å‹¾é…ãƒŽãƒ«ãƒ ã‚¯ãƒªãƒƒãƒ—ã¯é–¾å€¤1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd76e520",
   "metadata": {},
   "source": [
    "## æ¡ä»¶ä»˜ã‘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b965deb5",
   "metadata": {},
   "source": [
    "æ¡ä»¶ä»˜ã‘ã¯ã€æ½œåœ¨å¤‰æ•°ã«å¯¾ã—ã¦æ¡ä»¶ãƒ™ã‚¯ãƒˆãƒ«ã¨ã‚¿ã‚¹ã‚¯ã®ç¨®é¡žã‚’ç¤ºã™ãƒãƒ£ãƒ³ãƒãƒ«ã‚’é€£çµã—ã¦è¡Œã†:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2c960a",
   "metadata": {},
   "source": [
    "![](image/fig10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8651a48c",
   "metadata": {},
   "source": [
    "- å·¦: ç”»åƒã‹ã‚‰å‹•ç”»ã‚’ç”Ÿæˆã™ã‚‹ã‚¿ã‚¹ã‚¯\n",
    "- ä¸­: å‹•ç”»ã‚’å»¶é•·ã™ã‚‹ã‚¿ã‚¹ã‚¯\n",
    "- å³: æœ€åˆã¨æœ€å¾Œã®ç”»åƒã®é–“ã‚’è£œå®Œã™ã‚‹ã‚¿ã‚¹ã‚¯\n",
    "- é€£çµå¾Œã®ãƒãƒ£ãƒ³ãƒãƒ«æ•°ã¯$2k + 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4afc63",
   "metadata": {},
   "source": [
    "æ±ŽåŒ–æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã«ã€ãƒ†ã‚­ã‚¹ãƒˆæ¡ä»¶ã®ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆã‚„ç”»åƒæ¡ä»¶ã®ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆã‚’å°Žå…¥"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c229f9d",
   "metadata": {},
   "source": [
    "æŽ¨è«–ã«ã¯ã€Classifier-free Guidanceï¼ˆCFGï¼‰ã‚’æŽ¡ç”¨:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532dd227",
   "metadata": {},
   "source": [
    "$$\n",
    "v_{t} = v_{\\theta}(x_{t},t,\\emptyset,\\emptyset) + g_{img}\\cdot(v_{\\theta}(x_{t},t,\\emptyset,img)-v_{\\theta}(x_{t},t,\\emptyset,\\emptyset)) + g_{txt}\\cdot(v_{\\theta}(x_{t},t,txt,img)-v_{\\theta}(x_{t},t,\\emptyset,img))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cd2e12",
   "metadata": {},
   "source": [
    "- $g_{\\text{img}}$: ç”»åƒæ¡ä»¶ã®å¼·ã•ã‚’èª¿æ•´ã™ã‚‹ä¿‚æ•°\n",
    "- $g_{\\text{txt}}$: ãƒ†ã‚­ã‚¹ãƒˆæ¡ä»¶ã®å¼·ã•ã‚’èª¿æ•´ã™ã‚‹ä¿‚æ•°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a04814",
   "metadata": {},
   "source": [
    "ç”»åƒã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ã‚’å¼·ãã™ã‚‹ã¨ã€ç”Ÿæˆã•ã‚ŒãŸå‹•ç”»ã«ãƒãƒ©ã¤ãï¼ˆflickerï¼‰ãŒç”Ÿã˜ã‚‹:\n",
    "\n",
    "- Guidance Oscillationã‚’å°Žå…¥ã—ã¦å®‰å®šåŒ–\n",
    "    - ä¾‹ãˆã°ã€50ã‚¹ãƒ†ãƒƒãƒ—ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã®ã†ã¡ã€10ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã«$g_{\\text{img}}$ã‚’$1$ã«è½ã¨ã™"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b8f8b1",
   "metadata": {},
   "source": [
    "I2Vã§ã¯å‹•çš„ãªç”»åƒã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ï¼ˆdynamic image guidanceï¼‰ã‚’æŽ¡ç”¨ã—ã€å‹•ç”»ã®å¾ŒåŠã«ãªã‚‹ã«ã¤ã‚Œã¦æ¡ä»¶ä»˜ã‘ã‚’å¼·ãã™ã‚‹:\n",
    "\n",
    "![](image/fig11.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68ce8cd",
   "metadata": {},
   "source": [
    "- æ¨ªè»¸ã¯ãƒ•ãƒ¬ãƒ¼ãƒ æ•°\n",
    "- ç¸¦è»¸ã¯æŽ¨è«–ã‚¹ãƒ†ãƒƒãƒ—æ•°\n",
    "- ç”»åƒã®ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ã‚¹ã‚±ãƒ¼ãƒ«ã¯$1$ã‹ã‚‰$k$ã¾ã§ç·šå½¢ã«ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°\n",
    "- æŽ¨è«–ãŒçµ‚ã‚ã‚Šã«ãªã‚‹ã«ã¤ã‚Œã¦ã€ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãŒ$1$ã«ãªã‚‹ã‚ˆã†ã«æ¸›è¡°\n",
    "- ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã¯$g_{\\text{img}}=3$, $g_{\\text{txt}}=7.5$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d241562",
   "metadata": {},
   "source": [
    "å‹•ç”»ã®å‹•ãã®å¼·ã•ã¯ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ã‚¹ã‚³ã‚¢ã‚’ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã«è¿½åŠ ã™ã‚‹ã“ã¨ã§åˆ¶å¾¡:\n",
    "\n",
    "![](image/fig12.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0abfb4",
   "metadata": {},
   "source": [
    "## ã‚·ã‚¹ãƒ†ãƒ æœ€é©åŒ–"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f02982a",
   "metadata": {},
   "source": [
    "è¨“ç·´ã¯ã€ColossalAIã‚’ä½¿ç”¨:\n",
    "\n",
    "- 141GBã®ãƒ¡ãƒ¢ãƒªå®¹é‡ã‚’æŒã¤H200 GPUã‚’ä½¿ç”¨ã—ã€ãƒ‡ãƒ¼ã‚¿ä¸¦åˆ—ï¼ˆDP, Data Parallelismï¼‰ã‚’å°Žå…¥\n",
    "- é¸æŠžçš„ã‚¢ã‚¯ãƒ†ã‚£ãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒ†ã‚£ãƒ³ã‚°ï¼ˆSelective Activation Checkpointingï¼‰ã‚’å°Žå…¥\n",
    "    - ä¸€éƒ¨ã®é †ä¼æ’­ã®è¨ˆç®—çµæžœã‚’ç ´æ£„ã—ã€å¿…è¦ã«å¿œã˜ã¦å†è¨ˆç®—ã™ã‚‹æŠ€è¡“ã§ãƒ¡ãƒ¢ãƒªåŠ¹çŽ‡åŒ–\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6636c0c3",
   "metadata": {},
   "source": [
    "é«˜è§£åƒåº¦ã®å‹•ç”»ã‚’åŠ¹çŽ‡çš„ã«å‡¦ç†ã™ã‚‹ãŸã‚ã«ã€è¤‡æ•°ã®ä¸¦åˆ—åŒ–æŠ€è¡“ã‚’æŽ¡ç”¨:\n",
    "\n",
    "- AEã§ã¯ã€ãƒ†ãƒ³ã‚½ãƒ«ä¸¦åˆ—åŒ–ï¼ˆTP, Tensor Parallelismï¼‰ã‚’ç•³ã¿è¾¼ã¿å±¤ã«é©ç”¨\n",
    "    - å…¥åŠ›ã¾ãŸã¯å‡ºåŠ›ã®ãƒãƒ£ãƒãƒ«æ¬¡å…ƒã§é‡ã¿ã‚’åˆ†å‰²ã™ã‚‹\n",
    "- MMDiTã§ã¯ã€Zero Redundancy Opitimizerï¼ˆZeroDPï¼‰ã¨ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä¸¦åˆ—ï¼ˆCP, Context Parallelismï¼‰ã‚’é©ç”¨\n",
    "    - ZeroDPã¯ã€DeepSpeedã®ZeRO2ã«ã‚ˆã‚Šå‹¾é…ã‚’åˆ†å‰²ã—ã€é‡è¤‡ãªãGPUãŒä¿æŒã™ã‚‹æŠ€è¡“\n",
    "    - CPã¯ã€å‹•ç”»ã¨ãƒ†ã‚­ã‚¹ãƒˆã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’åˆ†å‰²ã—ã€å„GPUãŒç‹¬ç«‹ã—ã¦ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³è¨ˆç®—ã™ã‚‹æŠ€è¡“"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f902c3e9",
   "metadata": {},
   "source": [
    "ã‚¢ã‚¯ãƒ†ã‚£ãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒ†ã‚£ãƒ³ã‚°ã¯ã€ãƒ–ãƒ­ãƒƒã‚¯ã®å…¥åŠ›ã®ã¿ã‚’ä¿æŒã—ã€ãã‚Œä»¥å¤–ã¯å†è¨ˆç®—ã™ã‚‹:\n",
    "\n",
    "- ã‚¹ãƒ†ãƒ¼ã‚¸1, 2ã§ã¯ã€ãƒ‡ãƒ¥ã‚¢ãƒ«ãƒ–ãƒ­ãƒƒã‚¯ã®8å±¤ã¨ã™ã¹ã¦ã®ã‚·ãƒ³ã‚°ãƒ«ãƒ–ãƒ­ãƒƒã‚¯ã«é©ç”¨\n",
    "- ã‚¹ãƒ†ãƒ¼ã‚¸3ã§ã¯ã€ã™ã¹ã¦ã®ãƒ–ãƒ­ãƒƒã‚¯ã§æœ‰åŠ¹åŒ–ã—ã€CPUã¸ã®ã‚ªãƒ•ãƒ­ãƒ¼ãƒ‰ã‚‚ä½¿ç”¨\n",
    "    - ã‚ªãƒ•ãƒ­ãƒ¼ãƒ‰ã§ã¯ã€Pinned Memoryã¨éžåŒæœŸãƒ‡ãƒ¼ã‚¿è»¢é€ã‚’ä½¿ç”¨ã—ã€ã•ã‚‰ã«åŠ¹çŽ‡åŒ–"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6969e364",
   "metadata": {},
   "source": [
    "åˆ†æ•£è¨“ç·´ã®å ´åˆã€ç‰©ç†éšœå®³ãŒç™ºç”Ÿã—ã‚„ã™ã„ã®ã§è‡ªå‹•å¾©æ—§æ©Ÿèƒ½ï¼ˆAuto Recoveryï¼‰ã‚’å°Žå…¥\n",
    "\n",
    "- InfiniBandã®éšœå®³ã€ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚·ã‚¹ãƒ†ãƒ ã®ã‚¯ãƒ©ãƒƒã‚·ãƒ¥ã€NCCLã‚¨ãƒ©ãƒ¼\n",
    "- è¨“ç·´ã®çŠ¶æ…‹ã‚’ç›£è¦–ã—ã€é€Ÿåº¦ä½Žä¸‹ãƒ»æå¤±ã®æ€¥æ¿€ãªæ‚ªåŒ–ãƒ»ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒãªã„ã‹ã‚’æ¤œè¨¼\n",
    "- å•é¡ŒãŒæ¤œå‡ºã•ã‚ŒãŸå ´åˆã¯ã€ã™ã¹ã¦ã®ãƒ—ãƒ­ã‚»ã‚¹ã‚’åœæ­¢ã—ã€ãƒŽãƒ¼ãƒ‰ã‚’è¨ºæ–­\n",
    "- å¿…è¦ã«å¿œã˜ã¦äºˆå‚™ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤ã—ã€æœ€çµ‚ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰è‡ªå‹•çš„ã«è¨“ç·´ã‚’å†é–‹ã™ã‚‹\n",
    "- GPUç¨¼åƒçŽ‡99%ã§ã€ãƒ€ã‚¦ãƒ³ã‚¿ã‚¤ãƒ ã‚’æœ€å°é™ã«æŠ‘ãˆãŸ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58002756",
   "metadata": {},
   "source": [
    "CPUã¨GPUé–“ã®ãƒ‡ãƒ¼ã‚¿è»¢é€ã‚’é«˜é€ŸåŒ–ã™ã‚‹ãŸã‚ã«PyTorchã®ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’æœ€é©åŒ–:\n",
    "\n",
    "- PyTorchãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®Pinned Memoryã¯ã€CUDAã‚«ãƒ¼ãƒãƒ«å®Ÿè¡Œã‚’ãƒ–ãƒ­ãƒƒã‚¯ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹\n",
    "- ãƒ¡ãƒ¢ãƒªãƒãƒƒãƒ•ã‚¡ï¼ˆpre-allocated pinned memory bufferï¼‰ã‚’ä½¿ç”¨ã—ã€ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ã‚’å‰Šæ¸›\n",
    "- ãƒ‡ãƒ¼ã‚¿è»¢é€ã¨è¨ˆç®—ã‚’ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—ã•ã›ã¦åŠ¹çŽ‡åŒ–\n",
    "- ã‚°ãƒ­ãƒ¼ãƒãƒ«ãªGCï¼ˆã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ï¼‰ã¯ã€åˆ†æ•£è¨“ç·´ã§ã¯ãƒã‚°ãŒå¤šã„ãŸã‚æ‰‹å‹•ã§ãƒ¡ãƒ¢ãƒªã‹ã‚“ã‚Š"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55af23f0",
   "metadata": {},
   "source": [
    "ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®ä¿å­˜ã¯ã€ãƒ”ãƒ³ç•™ã‚ã•ã‚ŒãŸãƒ¡ãƒ¢ãƒªãƒãƒƒãƒ•ã‚¡ã«å¯¾ã—ã¦ç›´æŽ¥ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ã“ã¨ã§é«˜é€ŸåŒ–:\n",
    "\n",
    "- ãƒ‡ã‚£ã‚¹ã‚¯ã¸ã®æ›¸ãè¾¼ã¿ã¯ã€C++ã«ã‚ˆã‚‹éžåŒæœŸãƒ‡ã‚£ã‚¹ã‚¯æ›¸ãè¾¼ã¿ã«ã‚ˆã‚Šè¨“ç·´ãƒ—ãƒ­ã‚»ã‚¹ã‚’ãƒ–ãƒ­ãƒƒã‚¯ã›ãšã«åŠ¹çŽ‡åŒ–"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629e8584",
   "metadata": {},
   "source": [
    "## å®Ÿè£…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaff96bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    !git clone https://github.com/hpcaitech/Open-Sora.git\n",
    "    WORK_DIR = \"/content/Open-Sora\"\n",
    "    %cd $WORK_DIR\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    WORK_DIR = \"/workspaces/open-sora/Open-Sora\"\n",
    "    %cd $WORK_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298268ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import platform\n",
    "import subprocess\n",
    "\n",
    "DEBUG_LOG_PATH = os.path.join(WORK_DIR, \"debug.log\")\n",
    "\n",
    "if os.path.exists(DEBUG_LOG_PATH):\n",
    "    os.remove(DEBUG_LOG_PATH)\n",
    "\n",
    "def custom_format(record):\n",
    "    match record.levelno:\n",
    "        case logging.DEBUG:\n",
    "            level = \"ðŸŸ¦\"\n",
    "        case logging.INFO:\n",
    "            level = \"ðŸŸ©\"\n",
    "        case logging.WARNING:\n",
    "            level = \"ðŸŸ¨\"\n",
    "        case logging.ERROR:\n",
    "            level = \"ðŸŸ¥\"\n",
    "        case logging.CRITICAL:\n",
    "            level = \"ðŸ›‘\"\n",
    "    return f\"{level} {record.getMessage()}\"\n",
    "\n",
    "logger = logging.getLogger()\n",
    "\n",
    "for handler in logger.handlers:\n",
    "    logger.removeHandler(handler)\n",
    "\n",
    "formatter = logging.Formatter()\n",
    "formatter.format = custom_format\n",
    "\n",
    "file_handler = logging.FileHandler(DEBUG_LOG_PATH)\n",
    "file_handler.setFormatter(formatter)\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "stream_handler = logging.StreamHandler()\n",
    "stream_handler.setFormatter(formatter)\n",
    "logger.addHandler(stream_handler)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "PYTHON_VERSION = platform.python_version()\n",
    "logger.info(f\"Python {PYTHON_VERSION}\")\n",
    "\n",
    "NVIDIA_SMI = subprocess.run(\"nvidia-smi\", capture_output=True, text=True).stdout\n",
    "logger.info(f\"{NVIDIA_SMI}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bab8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    %pip install torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/cu124\n",
    "\n",
    "    %pip install \\\n",
    "        accelerate \\\n",
    "        av==13.1.0 \\\n",
    "        colossalai \\\n",
    "        ftfy \\\n",
    "        liger-kernel \\\n",
    "        omegaconf \\\n",
    "        mmengine \\\n",
    "        openai \\\n",
    "        pandas \\\n",
    "        pandarallel \\\n",
    "        pyarrow \\\n",
    "        tensorboard \\\n",
    "        wandb \\\n",
    "        --extra-index-url https://download.pytorch.org/whl/cu124\n",
    "\n",
    "    %pip install flash-attn --no-build-isolation\n",
    "\n",
    "    %pip install -e . --no-deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4318c538",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from einops import rearrange\n",
    "from flash_attn import flash_attn_func as flash_attn_func_v2\n",
    "from functools import partial\n",
    "from huggingface_hub import PyTorchModelHubMixin\n",
    "from inspect import signature\n",
    "from liger_kernel.ops.rms_norm import LigerRMSNormFunction\n",
    "from liger_kernel.ops.rope import LigerRopeFunction\n",
    "from omegaconf import MISSING, OmegaConf\n",
    "from torch import Tensor, nn\n",
    "from torch.nn.modules.batchnorm import _BatchNorm\n",
    "from typing import Any, Callable, Optional, Union, Tuple\n",
    "import diffusers\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "from mmengine.config import Config\n",
    "import ast\n",
    "\n",
    "try:\n",
    "    from flash_attn_interface import flash_attn_func as flash_attn_func_v3\n",
    "    SUPPORT_FA3 = True\n",
    "except:\n",
    "    SUPPORT_FA3 = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8a3051",
   "metadata": {},
   "source": [
    "## ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8652538",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS_DIR = os.path.join(WORK_DIR, \"datasets\")\n",
    "os.makedirs(DATASETS_DIR, exist_ok=True)\n",
    "\n",
    "PEXELS_45K_NECESSARY_PATH = os.path.join(DATASETS_DIR, \"pexels_45k_necessary.csv\")\n",
    "PEXELS_45K_SCORE_PATH = os.path.join(DATASETS_DIR, \"pexels_45k_score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61fc264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pexels_45k_score_df = pd.read_csv(PEXELS_45K_SCORE_PATH)\n",
    "pexels_45k_score_df.head()\n",
    "\n",
    "# sort by duration\n",
    "pexels_45k_score_df = pexels_45k_score_df.sort_values(by=[\"filesize\"])\n",
    "pexels_45k_score_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383be136",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pexels_45k_necessary = pd.read_csv(PEXELS_45K_NECESSARY_PATH)\n",
    "\n",
    "# Take first 10 samples and save as csv\n",
    "pexels_45k_necessary.sort_values(by=[\"num_frames\"]).head(10).to_csv(\"pexels_45k_necessary_top10.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd75697f",
   "metadata": {},
   "source": [
    "## CLIãƒ‘ãƒ¼ã‚µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45c0e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args(args) -> tuple[str, argparse.Namespace]:\n",
    "    \"\"\"\n",
    "    This function parses the command line arguments.\n",
    "\n",
    "    Returns:\n",
    "        tuple[str, argparse.Namespace]: The path to the configuration file and the command line arguments.\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"config\", type=str, help=\"model config file path\")\n",
    "    args, unknown_args = parser.parse_known_args(args)\n",
    "    return args.config, unknown_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4e518b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_config(config_path: str) -> Config:\n",
    "    \"\"\"\n",
    "    This function reads the configuration file.\n",
    "\n",
    "    Args:\n",
    "        config_path (str): The path to the configuration file.\n",
    "\n",
    "    Returns:\n",
    "        Config: The configuration object.\n",
    "    \"\"\"\n",
    "    cfg = Config.fromfile(config_path)\n",
    "    return cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80074784",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_convert(value: str) -> int | float | bool | list | dict | None:\n",
    "    \"\"\"\n",
    "    Automatically convert a string to the appropriate Python data type,\n",
    "    including int, float, bool, list, dict, etc.\n",
    "\n",
    "    Args:\n",
    "        value (str): The string to convert.\n",
    "\n",
    "    Returns:\n",
    "        int, float, bool, list |  dict: The converted value.\n",
    "    \"\"\"\n",
    "    # Handle empty string\n",
    "    if value == \"\":\n",
    "        return value\n",
    "\n",
    "    # Handle None\n",
    "    if value.lower() == \"none\":\n",
    "        return None\n",
    "\n",
    "    # Handle boolean values\n",
    "    lower_value = value.lower()\n",
    "    if lower_value == \"true\":\n",
    "        return True\n",
    "    elif lower_value == \"false\":\n",
    "        return False\n",
    "\n",
    "    # Try to convert the string to an integer or float\n",
    "    try:\n",
    "        # Try converting to an integer\n",
    "        return int(value)\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        # Try converting to a float\n",
    "        return float(value)\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "    # Try to convert the string to a list, dict, tuple, etc.\n",
    "    try:\n",
    "        return ast.literal_eval(value)\n",
    "    except (ValueError, SyntaxError):\n",
    "        pass\n",
    "\n",
    "    # If all attempts fail, return the original string\n",
    "    return value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7b6093",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_args(cfg: Config, args: argparse.Namespace) -> Config:\n",
    "    \"\"\"\n",
    "    This function merges the configuration file and command line arguments.\n",
    "\n",
    "    Args:\n",
    "        cfg (Config): The configuration object.\n",
    "        args (argparse.Namespace): The command line arguments.\n",
    "\n",
    "    Returns:\n",
    "        Config: The configuration object.\n",
    "    \"\"\"\n",
    "    for k, v in zip(args[::2], args[1::2]):\n",
    "        assert k.startswith(\"--\"), f\"Invalid argument: {k}\"\n",
    "        k = k[2:].replace(\"-\", \"_\")\n",
    "        k_split = k.split(\".\")\n",
    "        target = cfg\n",
    "        for key in k_split[:-1]:\n",
    "            assert key in cfg, f\"Key {key} not found in config\"\n",
    "            target = target[key]\n",
    "        if v.lower() == \"none\":\n",
    "            v = None\n",
    "        elif k in target:\n",
    "            v_type = type(target[k])\n",
    "            if v_type == bool:\n",
    "                v = auto_convert(v)\n",
    "            else:\n",
    "                v = type(target[k])(v)\n",
    "        else:\n",
    "            v = auto_convert(v)\n",
    "        target[k_split[-1]] = v\n",
    "    return cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f075d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_configs(args) -> Config:\n",
    "    \"\"\"\n",
    "    This function parses the configuration file and command line arguments.\n",
    "\n",
    "    Returns:\n",
    "        Config: The configuration object.\n",
    "    \"\"\"\n",
    "    config, args = parse_args(args)\n",
    "    cfg = read_config(config)\n",
    "    cfg = merge_args(cfg, args)\n",
    "    cfg.config_path = config\n",
    "\n",
    "    # hard-coded for spatial compression\n",
    "    if cfg.get(\"ae_spatial_compression\", None) is not None:\n",
    "        os.environ[\"AE_SPATIAL_COMPRESSION\"] = str(cfg.ae_spatial_compression)\n",
    "\n",
    "    return cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f46383",
   "metadata": {},
   "source": [
    "## DC-AEã®è¨“ç·´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfe17fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DC-AEè¨“ç·´\n",
    "\n",
    "# https://github.com/hpcaitech/Open-Sora/blob/main/docs/hcae.md\n",
    "\n",
    "# torchrun --nproc_per_node 8 scripts/vae/train.py configs/vae/train/video_dc_ae.py\n",
    "\n",
    "dcae_cfg = parse_configs([\n",
    "    \"configs/vae/train/video_dc_ae.py\",\n",
    "])\n",
    "dcae_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1842d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import random\n",
    "import subprocess\n",
    "import warnings\n",
    "from contextlib import nullcontext\n",
    "from copy import deepcopy\n",
    "from pprint import pformat\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "gc.disable()\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "from colossalai.booster import Booster\n",
    "from colossalai.utils import set_seed\n",
    "from torch.profiler import ProfilerActivity, profile, schedule\n",
    "from tqdm import tqdm\n",
    "\n",
    "import wandb\n",
    "from opensora.acceleration.checkpoint import set_grad_checkpoint\n",
    "from opensora.acceleration.parallel_states import get_data_parallel_group\n",
    "from opensora.datasets.dataloader import prepare_dataloader\n",
    "from opensora.datasets.pin_memory_cache import PinMemoryCache\n",
    "from opensora.models.vae.losses import DiscriminatorLoss, GeneratorLoss, VAELoss\n",
    "from opensora.registry import DATASETS, MODELS, build_module\n",
    "from opensora.utils.ckpt import CheckpointIO, model_sharding, record_model_param_shape, rm_checkpoints\n",
    "# from opensora.utils.config import config_to_name, create_experiment_workspace, parse_configs\n",
    "from opensora.utils.config import config_to_name, create_experiment_workspace\n",
    "from opensora.utils.logger import create_logger\n",
    "from opensora.utils.misc import (\n",
    "    Timer,\n",
    "    all_reduce_sum,\n",
    "    create_tensorboard_writer,\n",
    "    is_log_process,\n",
    "    log_model_params,\n",
    "    to_torch_dtype,\n",
    ")\n",
    "from opensora.utils.optimizer import create_lr_scheduler, create_optimizer\n",
    "from opensora.utils.train import create_colossalai_plugin, set_lr, set_warmup_steps, setup_device, update_ema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9809ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "WAIT = 1\n",
    "WARMUP = 10\n",
    "ACTIVE = 20\n",
    "\n",
    "my_schedule = schedule(\n",
    "    wait=WAIT,  # number of warmup steps\n",
    "    warmup=WARMUP,  # number of warmup steps with profiling\n",
    "    active=ACTIVE,  # number of active steps with profiling\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc13ff7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================\n",
    "# 1. configs & runtime variables\n",
    "# ======================================================\n",
    "# == parse configs ==\n",
    "# cfg = parse_configs()\n",
    "cfg = parse_configs([\n",
    "    \"configs/vae/train/video_dc_ae.py\",\n",
    "])\n",
    "\n",
    "cfg.bucket_config = {\n",
    "    \"256px_ar1:1\": {\n",
    "        8: (1.0, 1),\n",
    "        32: (0.0, 1),\n",
    "    }\n",
    "}\n",
    "cfg.epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250b4dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# == get dtype & device ==\n",
    "dtype = to_torch_dtype(cfg.get(\"dtype\", \"bf16\"))\n",
    "\n",
    "os.environ['RANK'] = '0'\n",
    "os.environ['WORLD_SIZE'] = '1'\n",
    "os.environ['MASTER_ADDR'] = 'localhost'\n",
    "os.environ['MASTER_PORT'] = '12345'\n",
    "\n",
    "device, coordinator = setup_device()\n",
    "checkpoint_io = CheckpointIO()\n",
    "set_seed(cfg.get(\"seed\", 1024))\n",
    "PinMemoryCache.force_dtype = dtype\n",
    "pin_memory_cache_pre_alloc_numels = cfg.get(\"pin_memory_cache_pre_alloc_numels\", None)\n",
    "PinMemoryCache.pre_alloc_numels = pin_memory_cache_pre_alloc_numels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d544b486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# == init ColossalAI booster ==\n",
    "plugin_type = cfg.get(\"plugin\", \"zero2\")\n",
    "plugin_config = cfg.get(\"plugin_config\", {})\n",
    "plugin = (\n",
    "    create_colossalai_plugin(\n",
    "        plugin=plugin_type,\n",
    "        dtype=cfg.get(\"dtype\", \"bf16\"),\n",
    "        grad_clip=cfg.get(\"grad_clip\", 0),\n",
    "        **plugin_config,\n",
    "    )\n",
    "    if plugin_type != \"none\"\n",
    "    else None\n",
    ")\n",
    "booster = Booster(plugin=plugin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49473b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# == init exp_dir ==\n",
    "exp_name, exp_dir = create_experiment_workspace(\n",
    "    cfg.get(\"outputs\", \"./outputs\"),\n",
    "    model_name=config_to_name(cfg),\n",
    "    config=cfg.to_dict(),\n",
    ")\n",
    "if is_log_process(plugin_type, plugin_config):\n",
    "    print(f\"changing {exp_dir} to share\")\n",
    "    os.system(f\"chgrp -R share {exp_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab51d1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# == init logger, tensorboard & wandb ==\n",
    "logger = create_logger(exp_dir)\n",
    "logger.info(\"Training configuration:\\n %s\", pformat(cfg.to_dict()))\n",
    "tb_writer = None\n",
    "if coordinator.is_master():\n",
    "    tb_writer = create_tensorboard_writer(exp_dir)\n",
    "    if cfg.get(\"wandb\", False):\n",
    "        wandb.init(\n",
    "            project=cfg.get(\"wandb_project\", \"Open-Sora\"),\n",
    "            name=cfg.get(\"wandb_expr_name\", exp_name),\n",
    "            config=cfg.to_dict(),\n",
    "            dir=exp_dir,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccabf78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================\n",
    "# 2. build dataset and dataloader\n",
    "# ======================================================\n",
    "logger.info(f\"Building dataset... {cfg.dataset=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4743fc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: pexels_45k_necessary.csvã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
    "\n",
    "assert os.path.join(WORK_DIR, cfg.dataset.data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13016093",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe57d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# == build dataset ==\n",
    "\n",
    "# VideoTextDatasetã‚’å®Ÿä½“åŒ–\n",
    "dataset = build_module(cfg.dataset, DATASETS)\n",
    "logger.info(\"Dataset contains %s samples.\", len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07538605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# == build dataloader ==\n",
    "cache_pin_memory = pin_memory_cache_pre_alloc_numels is not None\n",
    "dataloader_args = dict(\n",
    "    dataset=dataset,\n",
    "    batch_size=cfg.get(\"batch_size\", None),\n",
    "    num_workers=cfg.get(\"num_workers\", 4),\n",
    "    seed=cfg.get(\"seed\", 1024),\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    pin_memory=True,\n",
    "    process_group=get_data_parallel_group(),\n",
    "    prefetch_factor=cfg.get(\"prefetch_factor\", None),\n",
    "    cache_pin_memory=cache_pin_memory,\n",
    ")\n",
    "dataloader, sampler = prepare_dataloader(\n",
    "    bucket_config=cfg.get(\"bucket_config\", None),\n",
    "    num_bucket_build_workers=cfg.get(\"num_bucket_build_workers\", 1),\n",
    "    **dataloader_args,\n",
    ")\n",
    "num_steps_per_epoch = len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a5af0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_batch = next(iter(dataloader))\n",
    "first_batch[\"sampling_interval\"], first_batch[\"video\"].shape, first_batch[\"path\"], first_batch[\"index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471580c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_frame = first_batch[\"video\"][:, :, 0].to(device=device, dtype=torch.float32)\n",
    "first_frame.shape\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(first_frame[0].permute(1, 2, 0).cpu().numpy())\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ee1c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================\n",
    "# 3. build model\n",
    "# ======================================================\n",
    "logger.info(\"Building models...\")\n",
    "\n",
    "# == build vae model ==\n",
    "model = build_module(cfg.model, MODELS, device_map=device, torch_dtype=dtype).train()\n",
    "log_model_params(model)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e257a57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg.get(\"grad_checkpoint\", False):\n",
    "    set_grad_checkpoint(model)\n",
    "\n",
    "vae_loss_fn = VAELoss(**cfg.vae_loss_config, device=device, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc340ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# == build EMA model ==\n",
    "if cfg.get(\"ema_decay\", None) is not None:\n",
    "    ema = deepcopy(model).cpu().eval().requires_grad_(False)\n",
    "    ema_shape_dict = record_model_param_shape(ema)\n",
    "    logger.info(\"EMA model created.\")\n",
    "else:\n",
    "    ema = ema_shape_dict = None\n",
    "    logger.info(\"No EMA model created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a32a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# == build discriminator model ==\n",
    "use_discriminator = cfg.get(\"discriminator\", None) is not None\n",
    "if use_discriminator:\n",
    "    discriminator = build_module(cfg.discriminator, MODELS).to(device, dtype).train()\n",
    "    log_model_params(discriminator)\n",
    "    generator_loss_fn = GeneratorLoss(**cfg.gen_loss_config)\n",
    "    discriminator_loss_fn = DiscriminatorLoss(**cfg.disc_loss_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b7f953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# == setup optimizer ==\n",
    "optimizer = create_optimizer(model, cfg.optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26438bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# == setup lr scheduler ==\n",
    "lr_scheduler = create_lr_scheduler(\n",
    "    optimizer=optimizer, num_steps_per_epoch=num_steps_per_epoch, epochs=cfg.get(\"epochs\", 1000), **cfg.lr_scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1f0e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# == setup discriminator optimizer ==\n",
    "if use_discriminator:\n",
    "    disc_optimizer = create_optimizer(discriminator, cfg.optim_discriminator)\n",
    "    disc_lr_scheduler = create_lr_scheduler(\n",
    "        optimizer=disc_optimizer,\n",
    "        num_steps_per_epoch=num_steps_per_epoch,\n",
    "        epochs=cfg.get(\"epochs\", 1000),\n",
    "        **cfg.disc_lr_scheduler,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319e1931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================\n",
    "# 4. distributed training preparation with colossalai\n",
    "# =======================================================\n",
    "logger.info(\"Preparing for distributed training...\")\n",
    "# == boosting ==\n",
    "torch.set_default_dtype(dtype)\n",
    "model, optimizer, _, dataloader, lr_scheduler = booster.boost(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    lr_scheduler=lr_scheduler,\n",
    "    dataloader=dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73f47b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_discriminator:\n",
    "    discriminator, disc_optimizer, _, _, disc_lr_scheduler = booster.boost(\n",
    "        model=discriminator,\n",
    "        optimizer=disc_optimizer,\n",
    "        lr_scheduler=disc_lr_scheduler,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2a9344",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float)\n",
    "logger.info(\"Boosted model for distributed training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d6fab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# == global variables ==\n",
    "cfg_epochs = cfg.get(\"epochs\", 1000)\n",
    "mixed_strategy = cfg.get(\"mixed_strategy\", None)\n",
    "mixed_image_ratio = cfg.get(\"mixed_image_ratio\", 0.0)\n",
    "# modulate mixed image ratio since we force rank 0 to be video\n",
    "num_ranks = dist.get_world_size()\n",
    "modulated_mixed_image_ratio = (\n",
    "    num_ranks * mixed_image_ratio / (num_ranks - 1) if num_ranks > 1 else mixed_image_ratio\n",
    ")\n",
    "if is_log_process(plugin_type, plugin_config):\n",
    "    print(\"modulated mixed image ratio:\", modulated_mixed_image_ratio)\n",
    "\n",
    "start_epoch = start_step = log_step = acc_step = 0\n",
    "running_loss = dict(  # loss accumulated over config.log_every steps\n",
    "    all=0.0,\n",
    "    nll=0.0,\n",
    "    nll_rec=0.0,\n",
    "    nll_per=0.0,\n",
    "    kl=0.0,\n",
    "    gen=0.0,\n",
    "    gen_w=0.0,\n",
    "    disc=0.0,\n",
    "    debug=0.0,\n",
    ")\n",
    "\n",
    "def log_loss(name, loss, loss_dict, use_video):\n",
    "    # only calculate loss for video\n",
    "    if use_video == 0:\n",
    "        loss.data = torch.tensor(0.0, device=device, dtype=dtype)\n",
    "    all_reduce_sum(loss.data)\n",
    "    num_video = torch.tensor(use_video, device=device, dtype=dtype)\n",
    "    all_reduce_sum(num_video)\n",
    "    loss_item = loss.item() / num_video.item()\n",
    "    loss_dict[name] = loss_item\n",
    "    running_loss[name] += loss_item\n",
    "\n",
    "logger.info(\"Training for %s epochs with %s steps per epoch\", cfg_epochs, num_steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26bb06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# == sharding EMA model ==\n",
    "if ema is not None:\n",
    "    model_sharding(ema)\n",
    "    ema = ema.to(device)\n",
    "\n",
    "if cfg.get(\"freeze_layers\", None) == \"all\":\n",
    "    for param in model.module.parameters():\n",
    "        param.requires_grad = False\n",
    "    print(\"all layers frozen\")\n",
    "\n",
    "# model.module.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73b9521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# == resume ==\n",
    "if cfg.get(\"load\", None) is not None:\n",
    "    logger.info(\"Loading checkpoint from %s\", cfg.load)\n",
    "    start_epoch = cfg.get(\"start_epoch\", None)\n",
    "    start_step = cfg.get(\"start_step\", None)\n",
    "    ret = checkpoint_io.load(\n",
    "        booster,\n",
    "        cfg.load,\n",
    "        model=model,\n",
    "        ema=ema,\n",
    "        optimizer=optimizer,\n",
    "        lr_scheduler=lr_scheduler,\n",
    "        sampler=(\n",
    "            None if start_step is not None else sampler\n",
    "        ),  # if specify start step, set last_micro_batch_access_index of a new sampler instead\n",
    "    )\n",
    "    if start_step is not None:\n",
    "        # if start step exceeds data length, go to next epoch\n",
    "        if start_step > num_steps_per_epoch:\n",
    "            start_epoch = (\n",
    "                start_epoch + start_step // num_steps_per_epoch\n",
    "                if start_epoch is not None\n",
    "                else start_step // num_steps_per_epoch\n",
    "            )\n",
    "            start_step = start_step % num_steps_per_epoch\n",
    "        sampler.set_step(start_step)\n",
    "\n",
    "    start_epoch = start_epoch if start_epoch is not None else ret[0]\n",
    "    start_step = start_step if start_step is not None else ret[1]\n",
    "\n",
    "    if (\n",
    "        use_discriminator\n",
    "        and os.path.exists(os.path.join(cfg.load, \"discriminator\"))\n",
    "        and not cfg.get(\"restart_disc\", False)\n",
    "    ):\n",
    "        booster.load_model(discriminator, os.path.join(cfg.load, \"discriminator\"))\n",
    "        if cfg.get(\"load_optimizer\", True):\n",
    "            booster.load_optimizer(disc_optimizer, os.path.join(cfg.load, \"disc_optimizer\"))\n",
    "            if disc_lr_scheduler is not None:\n",
    "                booster.load_lr_scheduler(disc_lr_scheduler, os.path.join(cfg.load, \"disc_lr_scheduler\"))\n",
    "            if cfg.get(\"disc_lr\", None) is not None:\n",
    "                set_lr(disc_optimizer, disc_lr_scheduler, cfg.disc_lr)\n",
    "\n",
    "    logger.info(\"Loaded checkpoint %s at epoch %s step %s\", cfg.load, start_epoch, start_step)\n",
    "\n",
    "    if cfg.get(\"lr\", None) is not None:\n",
    "        set_lr(optimizer, lr_scheduler, cfg.lr, cfg.get(\"initial_lr\", None))\n",
    "\n",
    "    if cfg.get(\"update_warmup_steps\", False):\n",
    "        assert (\n",
    "            cfg.lr_scheduler.get(\"warmup_steps\", None) is not None\n",
    "        ), \"you need to set lr_scheduler.warmup_steps in order to pass --update-warmup-steps True\"\n",
    "        set_warmup_steps(lr_scheduler, cfg.lr_scheduler.warmup_steps)\n",
    "        if use_discriminator:\n",
    "            assert (\n",
    "                cfg.disc_lr_scheduler.get(\"warmup_steps\", None) is not None\n",
    "            ), \"you need to set disc_lr_scheduler.warmup_steps in order to pass --update-warmup-steps True\"\n",
    "            set_warmup_steps(disc_lr_scheduler, cfg.disc_lr_scheduler.warmup_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e12596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================\n",
    "# 5. training loop\n",
    "# =======================================================\n",
    "dist.barrier()\n",
    "\n",
    "cfg[\"accumulation_steps\"] = 128\n",
    "accumulation_steps = int(cfg.get(\"accumulation_steps\", 1))\n",
    "logger.info(\"Using gradient accumulation steps: %s\", accumulation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7127104",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for epoch in range(start_epoch, cfg_epochs):\n",
    "    # == set dataloader to new epoch ==\n",
    "    sampler.set_epoch(epoch)\n",
    "    dataiter = iter(dataloader)\n",
    "    logger.info(\"Beginning epoch %s...\", epoch)\n",
    "    random.seed(1024 + dist.get_rank())  # load vid/img for each rank\n",
    "\n",
    "    # == training loop in an epoch ==\n",
    "    with tqdm(\n",
    "        enumerate(dataiter, start=start_step),\n",
    "        desc=f\"Epoch {epoch}\",\n",
    "        disable=not coordinator.is_master(),\n",
    "        total=num_steps_per_epoch,\n",
    "        initial=start_step,\n",
    "    ) as pbar:\n",
    "        pbar_iter = iter(pbar)\n",
    "\n",
    "        def fetch_data():\n",
    "            step, batch = next(pbar_iter)\n",
    "            pinned_video = batch[\"video\"]\n",
    "            batch[\"video\"] = pinned_video.to(device, dtype, non_blocking=True)\n",
    "            return batch, step, pinned_video\n",
    "\n",
    "        batch_, step_, pinned_video_ = fetch_data()\n",
    "\n",
    "        profiler_ctxt = (\n",
    "            profile(\n",
    "                activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
    "                schedule=my_schedule,\n",
    "                on_trace_ready=torch.profiler.tensorboard_trace_handler(\"./log/profile\"),\n",
    "                record_shapes=True,\n",
    "                profile_memory=True,\n",
    "                with_stack=True,\n",
    "            )\n",
    "            if cfg.get(\"profile\", False)\n",
    "            else nullcontext()\n",
    "        )\n",
    "\n",
    "        with profiler_ctxt:\n",
    "            for _ in range(start_step, num_steps_per_epoch):\n",
    "                if cfg.get(\"profile\", False) and _ == WARMUP + ACTIVE + WAIT + 3:\n",
    "                    break\n",
    "\n",
    "                # == load data ===\n",
    "                batch, step, pinned_video = batch_, step_, pinned_video_\n",
    "                if step + 1 < num_steps_per_epoch:\n",
    "                    batch_, step_, pinned_video_ = fetch_data()\n",
    "\n",
    "                # == log config ==\n",
    "                global_step = epoch * num_steps_per_epoch + step\n",
    "                actual_update_step = (global_step + 1) // accumulation_steps\n",
    "                log_step += 1\n",
    "                acc_step += 1\n",
    "\n",
    "                # == mixed strategy ==\n",
    "                x = batch[\"video\"]\n",
    "                t_length = x.size(2)\n",
    "                use_video = 1\n",
    "                if mixed_strategy == \"mixed_video_image\":\n",
    "                    if random.random() < modulated_mixed_image_ratio and dist.get_rank() != 0:\n",
    "                        # NOTE: enable the first rank to use video\n",
    "                        t_length = 1\n",
    "                        use_video = 0\n",
    "                elif mixed_strategy == \"mixed_video_random\":\n",
    "                    t_length = random.randint(1, x.size(2))\n",
    "                x = x[:, :, :t_length, :, :]\n",
    "\n",
    "                with Timer(\"model\", log=True) if cfg.get(\"profile\", False) else nullcontext():\n",
    "                    # == forward pass ==\n",
    "                    x_rec, posterior, z = model(x)\n",
    "\n",
    "                    if cfg.get(\"profile\", False):\n",
    "                        profiler_ctxt.step()\n",
    "\n",
    "                    if cache_pin_memory:\n",
    "                        dataiter.remove_cache(pinned_video)\n",
    "\n",
    "                    # == loss initialization ==\n",
    "                    vae_loss = torch.tensor(0.0, device=device, dtype=dtype)\n",
    "                    loss_dict = {}  # loss at every step\n",
    "\n",
    "                    # == reconstruction loss ==\n",
    "                    ret = vae_loss_fn(x, x_rec, posterior)\n",
    "                    nll_loss = ret[\"nll_loss\"]\n",
    "                    kl_loss = ret[\"kl_loss\"]\n",
    "                    recon_loss = ret[\"recon_loss\"]\n",
    "                    perceptual_loss = ret[\"perceptual_loss\"]\n",
    "                    vae_loss += nll_loss + kl_loss\n",
    "\n",
    "                    # == generator loss ==\n",
    "                    if use_discriminator:\n",
    "                        # turn off grad update for disc\n",
    "                        discriminator.requires_grad_(False)\n",
    "                        fake_logits = discriminator(x_rec.contiguous())\n",
    "\n",
    "                        generator_loss, g_loss = generator_loss_fn(\n",
    "                            fake_logits,\n",
    "                            nll_loss,\n",
    "                            model.module.get_last_layer(),\n",
    "                            actual_update_step,\n",
    "                            is_training=model.training,\n",
    "                        )\n",
    "                        # print(f\"generator_loss: {generator_loss}, recon_loss: {recon_loss}, perceptual_loss: {perceptual_loss}\")\n",
    "\n",
    "                        vae_loss += generator_loss\n",
    "                        # turn on disc training\n",
    "                        discriminator.requires_grad_(True)\n",
    "\n",
    "                    # == generator backward & update ==\n",
    "                    ctx = (\n",
    "                        booster.no_sync(model, optimizer)\n",
    "                        if cfg.get(\"plugin\", \"zero2\") in (\"zero1\", \"zero1-seq\")\n",
    "                        and (step + 1) % accumulation_steps != 0\n",
    "                        else nullcontext()\n",
    "                    )\n",
    "                    with Timer(\"backward\", log=True) if cfg.get(\"profile\", False) else nullcontext():\n",
    "                        with ctx:\n",
    "                            booster.backward(loss=vae_loss / accumulation_steps, optimizer=optimizer)\n",
    "\n",
    "                    with Timer(\"optimizer\", log=True) if cfg.get(\"profile\", False) else nullcontext():\n",
    "                        if (step + 1) % accumulation_steps == 0:\n",
    "                            optimizer.step()\n",
    "                            optimizer.zero_grad()\n",
    "                            if lr_scheduler is not None:\n",
    "                                lr_scheduler.step(\n",
    "                                    actual_update_step,\n",
    "                                )\n",
    "                            # == update EMA ==\n",
    "                            if ema is not None:\n",
    "                                update_ema(\n",
    "                                    ema,\n",
    "                                    model.unwrap(),\n",
    "                                    optimizer=optimizer,\n",
    "                                    decay=cfg.get(\"ema_decay\", 0.9999),\n",
    "                                )\n",
    "\n",
    "                # == logging ==\n",
    "                log_loss(\"all\", vae_loss, loss_dict, use_video)\n",
    "                log_loss(\"nll\", nll_loss, loss_dict, use_video)\n",
    "                log_loss(\"nll_rec\", recon_loss, loss_dict, use_video)\n",
    "                log_loss(\"nll_per\", perceptual_loss, loss_dict, use_video)\n",
    "                log_loss(\"kl\", kl_loss, loss_dict, use_video)\n",
    "                if use_discriminator:\n",
    "                    log_loss(\"gen_w\", generator_loss, loss_dict, use_video)\n",
    "                    log_loss(\"gen\", g_loss, loss_dict, use_video)\n",
    "\n",
    "                # == loss: discriminator adversarial ==\n",
    "                if use_discriminator:\n",
    "                    real_logits = discriminator(x.detach().contiguous())\n",
    "                    fake_logits = discriminator(x_rec.detach().contiguous())\n",
    "                    disc_loss = discriminator_loss_fn(\n",
    "                        real_logits,\n",
    "                        fake_logits,\n",
    "                        actual_update_step,\n",
    "                    )\n",
    "\n",
    "                    # == discriminator backward & update ==\n",
    "                    ctx = (\n",
    "                        booster.no_sync(discriminator, disc_optimizer)\n",
    "                        if cfg.get(\"plugin\", \"zero2\") in (\"zero1\", \"zero1-seq\")\n",
    "                        and (step + 1) % accumulation_steps != 0\n",
    "                        else nullcontext()\n",
    "                    )\n",
    "                    with ctx:\n",
    "                        booster.backward(loss=disc_loss / accumulation_steps, optimizer=disc_optimizer)\n",
    "                    if (step + 1) % accumulation_steps == 0:\n",
    "                        disc_optimizer.step()\n",
    "                        disc_optimizer.zero_grad()\n",
    "                        if disc_lr_scheduler is not None:\n",
    "                            disc_lr_scheduler.step(actual_update_step)\n",
    "\n",
    "                    # log\n",
    "                    log_loss(\"disc\", disc_loss, loss_dict, use_video)\n",
    "\n",
    "                # == logging ==\n",
    "                if (global_step + 1) % accumulation_steps == 0:\n",
    "                    if coordinator.is_master() and actual_update_step % cfg.get(\"log_every\", 1) == 0:\n",
    "                        avg_loss = {k: v / log_step for k, v in running_loss.items()}\n",
    "                        # progress bar\n",
    "                        pbar.set_postfix(\n",
    "                            {\n",
    "                                # \"step\": step,\n",
    "                                # \"global_step\": global_step,\n",
    "                                # \"actual_update_step\": actual_update_step,\n",
    "                                # \"lr\": optimizer.param_groups[0][\"lr\"],\n",
    "                                **{k: f\"{v:.2f}\" for k, v in avg_loss.items()},\n",
    "                            }\n",
    "                        )\n",
    "                        # tensorboard\n",
    "                        tb_writer.add_scalar(\"loss\", vae_loss.item(), actual_update_step)\n",
    "                        # wandb\n",
    "                        if cfg.get(\"wandb\", False):\n",
    "                            wandb.log(\n",
    "                                {\n",
    "                                    \"iter\": global_step,\n",
    "                                    \"epoch\": epoch,\n",
    "                                    \"lr\": optimizer.param_groups[0][\"lr\"],\n",
    "                                    \"avg_loss_\": avg_loss,\n",
    "                                    \"avg_loss\": avg_loss[\"all\"],\n",
    "                                    \"loss_\": loss_dict,\n",
    "                                    \"loss\": vae_loss.item(),\n",
    "                                    \"global_grad_norm\": optimizer.get_grad_norm(),\n",
    "                                },\n",
    "                                step=actual_update_step,\n",
    "                            )\n",
    "\n",
    "                        running_loss = {k: 0.0 for k in running_loss}\n",
    "                        log_step = 0\n",
    "\n",
    "                    # == checkpoint saving ==\n",
    "                    ckpt_every = cfg.get(\"ckpt_every\", 0)\n",
    "                    if ckpt_every > 0 and actual_update_step % ckpt_every == 0 and coordinator.is_master():\n",
    "                        subprocess.run(\"sudo drop_cache\", shell=True)\n",
    "\n",
    "                    if ckpt_every > 0 and actual_update_step % ckpt_every == 0:\n",
    "                        # mannually garbage collection\n",
    "                        gc.collect()\n",
    "\n",
    "                        save_dir = checkpoint_io.save(\n",
    "                            booster,\n",
    "                            exp_dir,\n",
    "                            model=model,\n",
    "                            ema=ema,\n",
    "                            optimizer=optimizer,\n",
    "                            lr_scheduler=lr_scheduler,\n",
    "                            sampler=sampler,\n",
    "                            epoch=epoch,\n",
    "                            step=step + 1,\n",
    "                            global_step=global_step + 1,\n",
    "                            batch_size=cfg.get(\"batch_size\", None),\n",
    "                            actual_update_step=actual_update_step,\n",
    "                            ema_shape_dict=ema_shape_dict,\n",
    "                            async_io=True,\n",
    "                        )\n",
    "\n",
    "                        if is_log_process(plugin_type, plugin_config):\n",
    "                            os.system(f\"chgrp -R share {save_dir}\")\n",
    "\n",
    "                        if use_discriminator:\n",
    "                            booster.save_model(discriminator, os.path.join(save_dir, \"discriminator\"), shard=True)\n",
    "                            booster.save_optimizer(\n",
    "                                disc_optimizer,\n",
    "                                os.path.join(save_dir, \"disc_optimizer\"),\n",
    "                                shard=True,\n",
    "                                size_per_shard=4096,\n",
    "                            )\n",
    "                            if disc_lr_scheduler is not None:\n",
    "                                booster.save_lr_scheduler(\n",
    "                                    disc_lr_scheduler, os.path.join(save_dir, \"disc_lr_scheduler\")\n",
    "                                )\n",
    "                        dist.barrier()\n",
    "\n",
    "                        logger.info(\n",
    "                            \"Saved checkpoint at epoch %s, step %s, global_step %s to %s\",\n",
    "                            epoch,\n",
    "                            step + 1,\n",
    "                            actual_update_step,\n",
    "                            save_dir,\n",
    "                        )\n",
    "\n",
    "                        # remove old checkpoints\n",
    "                        rm_checkpoints(exp_dir, keep_n_latest=cfg.get(\"keep_n_latest\", -1))\n",
    "                        logger.info(\n",
    "                            \"Removed old checkpoints and kept %s latest ones.\", cfg.get(\"keep_n_latest\", -1)\n",
    "                        )\n",
    "\n",
    "        if cfg.get(\"profile\", False):\n",
    "            profiler_ctxt.export_chrome_trace(\"./log/profile/trace.json\")\n",
    "\n",
    "    sampler.reset()\n",
    "    start_step = 0\n",
    "\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
